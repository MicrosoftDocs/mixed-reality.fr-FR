---
title: Applications de Vision informatiques atelier casques de réalité mixte à CVPR 2019
description: Vue d’ensemble et la planification de la Vision des Applications pour ordinateurs à l’atelier des casques de réalité mixte, doit être livré à la conférence CVPR sur juin 2019.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: événement research, cvpr, vision par ordinateur, le mode research, HoloLens
ms.openlocfilehash: 89d79bcef77043564e51faada940d2c71a6005e4
ms.sourcegitcommit: 2f600e5ad00cd447b180b0f89192b4b9d86bbc7e
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 06/15/2019
ms.locfileid: "67148711"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="8b2cc-104">Applications de vision par ordinateur pour les casques de réalité mixte</span><span class="sxs-lookup"><span data-stu-id="8b2cc-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="8b2cc-105">Organisées en conjonction avec [CVPR 2019](http://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="8b2cc-105">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="8b2cc-106">Long Beach (CA)</span><span class="sxs-lookup"><span data-stu-id="8b2cc-106">Long Beach (CA)</span></span>

<span data-ttu-id="8b2cc-107">Juin 17, 2019 après-midi) - Hyatt Regency F</span><span class="sxs-lookup"><span data-stu-id="8b2cc-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="8b2cc-108">Organisateurs</span><span class="sxs-lookup"><span data-stu-id="8b2cc-108">Organizers</span></span>
* <span data-ttu-id="8b2cc-109">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="8b2cc-109">Marc Pollefeys</span></span>
* <span data-ttu-id="8b2cc-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="8b2cc-110">Federica Bogo</span></span>
* <span data-ttu-id="8b2cc-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="8b2cc-111">Johannes Schönberger</span></span>
* <span data-ttu-id="8b2cc-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="8b2cc-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="8b2cc-113">Vue d'ensemble</span><span class="sxs-lookup"><span data-stu-id="8b2cc-113">Overview</span></span>

![Image d’aperçu](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="8b2cc-115">Les casques de réalité mixte tels que le Microsoft HoloLens deviennent des plateformes puissants pour développer des applications de vision par ordinateur.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="8b2cc-116">Mode de recherche de HoloLens permet de recherche de vision par ordinateur sur l’appareil en fournissant un accès à tous les flux de capteur brutes image--, y compris la profondeur et runtime d’intégration.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="8b2cc-117">Comme le Mode de recherche est désormais disponible depuis mai 2018, nous avons commencé à voir plusieurs démonstrations et des applications en cours de développement pour HoloLens intéressantes.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="8b2cc-118">L’objectif de cet atelier consiste à rassembler les étudiants et chercheurs intéressés de vision par ordinateur pour les applications de réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="8b2cc-119">L’atelier fournira un lieu pour partager des démonstrations et des applications et apprendre à partir d’autres pour créer ou porter les applications à une réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="8b2cc-120">Nous encourageons les envois sur les rubriques de la reconnaissance d’objet (auto-centric), main et de suivi utilisateur, reconnaissance d’activité, claquement, reconstruction en 3D, présentation de la scène, localisation basée sur le capteur, navigation et bien plus encore.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="8b2cc-121">Soumission de papier</span><span class="sxs-lookup"><span data-stu-id="8b2cc-121">Paper Submission</span></span>
* <span data-ttu-id="8b2cc-122">Date d’échéance livre : Le 17 mai</span><span class="sxs-lookup"><span data-stu-id="8b2cc-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="8b2cc-123">Notification aux auteurs : Le 24 mai</span><span class="sxs-lookup"><span data-stu-id="8b2cc-123">Notification to authors: May 24</span></span>

<span data-ttu-id="8b2cc-124">Les soumissions de papier doivent utiliser le modèle CVPR et sont limitées à 4 de pages plus de références.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="8b2cc-125">En outre, nous encourageons les auteurs pour soumettre une vidéo présentant leur application.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="8b2cc-126">Notez que les envois de travail précédemment publiés sont autorisées (y compris le travail accepté à la conférence CVPR 2019 principale).</span><span class="sxs-lookup"><span data-stu-id="8b2cc-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="8b2cc-127">Envois peuvent être téléchargés sur le CMT : https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="8b2cc-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="8b2cc-128">Un sous-ensemble de livres sera sélectionné pour la présentation orale à l’atelier.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="8b2cc-129">Toutefois, nous encourageons vivement tous les auteurs à présenter leur travail pendant la session de démonstration.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="8b2cc-130">Planification</span><span class="sxs-lookup"><span data-stu-id="8b2cc-130">Schedule</span></span>
* <span data-ttu-id="8b2cc-131">13:30-13:45: Remarques d’ouverture et de bienvenue.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="8b2cc-132">13:45-14:15: **Discours talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-132">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="8b2cc-133">titre : Vision ordinateur EGOCENTRIQUE sur HoloLens.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="8b2cc-134">14:15-14:45: **Discours talk**: Prof. Kris Kitani, Carnegie Mellon University.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-134">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="8b2cc-135">titre : Activité EGOCENTRIQUE et Pose de prévision.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="8b2cc-136">14:45-15:15: **Discours talk**: Récupération d’urgence. YANG Liu, Californie Institute of Technology.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-136">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="8b2cc-137">titre : Mise sous tension d’un Assistant Cognitive for the Blind avec réalité augmentée.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="8b2cc-138">15:15-16:15: Pause café et démonstrations.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="8b2cc-139">16:15-16:45: **Discours talk**: Prof. Kristen Grauman, Université du Texas à Austin/Facebook AI Research.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-139">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="8b2cc-140">titre : Interaction homme-object dans la vidéo de la première personne.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-140">Title: Human-object interaction in first-person video.</span></span>
* <span data-ttu-id="8b2cc-141">16:45-17:15: Oralement des :</span><span class="sxs-lookup"><span data-stu-id="8b2cc-141">16:45-17:15: Oral presentations:</span></span>
    * <span data-ttu-id="8b2cc-142">Inscription facilitée - navigation orthopédique autonome avec HoloLens.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-142">Registration made easy - standalone orthopedic navigation with HoloLens.</span></span> <span data-ttu-id="8b2cc-143">F.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-143">F.</span></span> <span data-ttu-id="8b2cc-144">Liebmann, Roner S., M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, Scaramuzza de D., R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span></span>
    * <span data-ttu-id="8b2cc-145">Apprentissage stéréo en parcourant avec un HoloLens.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-145">Learning stereo by walking around with a HoloLens.</span></span> <span data-ttu-id="8b2cc-146">H.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-146">H.</span></span> <span data-ttu-id="8b2cc-147">Zhan, Y. Pekelny, O. Ulusoy.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-147">Zhan, Y. Pekelny, O. Ulusoy.</span></span>
* <span data-ttu-id="8b2cc-148">17:15-17:30: Remarques finales.</span><span class="sxs-lookup"><span data-stu-id="8b2cc-148">17:15-17:30: Final Remarks.</span></span>
