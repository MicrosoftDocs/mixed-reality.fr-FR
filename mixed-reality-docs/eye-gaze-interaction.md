---
title: Interaction par pointage du regard
description: HoloLens 2 permet d’accéder à un nouveau niveau de compréhension contextuelle et humaine au sein de l’expérience holographique en offrant aux développeurs la capacité d’utiliser des informations sur ce que les utilisateurs regardent. Cette page traite des recommandations de conception pour les développeurs qui souhaitent utiliser des yeux oculaires comme entrée.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Suivi oculaire, réalité mixte, entrée, point de regard
ms.openlocfilehash: 2ae7723f116771986edc757f1c9d4f454b0a256f
ms.sourcegitcommit: b0d15083ec1095e08c9d776e5bae66b4449383bb
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 05/27/2020
ms.locfileid: "84111036"
---
# <a name="eye-gaze-based-interaction-on-hololens-2"></a><span data-ttu-id="f291b-105">Interaction Eye-orientée vers le regard de HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="f291b-105">Eye-gaze-based interaction on HoloLens 2</span></span>

![Démonstration du suivi oculaire dans MRTK](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="f291b-107">L’une de nos nouvelles fonctionnalités passionnantes sur HoloLens 2 est le suivi oculaire.</span><span class="sxs-lookup"><span data-stu-id="f291b-107">One of our exciting new capabilities on HoloLens 2 is eye tracking.</span></span>
<span data-ttu-id="f291b-108">Sur notre [suivi oculaire sur la page HoloLens 2](eye-tracking.md) , nous avons mentionné la nécessité pour chaque utilisateur de passer par un [étalonnage](https://docs.microsoft.com/hololens/hololens-calibration), à condition que des conseils pour les développeurs et des cas d’utilisation en surbrillance pour le suivi oculaire.</span><span class="sxs-lookup"><span data-stu-id="f291b-108">On our [Eye tracking on HoloLens 2](eye-tracking.md) page, we mentioned the need for each user to go through a [Calibration](https://docs.microsoft.com/hololens/hololens-calibration), provided some developer guidance and highlighted use cases for eye tracking.</span></span>
<span data-ttu-id="f291b-109">Le regard de l’oeil est toujours un nouveau type d’entrée utilisateur et il y a beaucoup à apprendre.</span><span class="sxs-lookup"><span data-stu-id="f291b-109">Eye-gaze input is still a pretty new type of user input and there is a lot to learn.</span></span> <span data-ttu-id="f291b-110">Tandis que l’entrée de regard oculaire n’est utilisée que très subtilement dans notre expérience d’interpréteur de commandes holographique (l’interface utilisateur que vous voyez quand vous démarrez votre HoloLens 2), plusieurs applications, telles que la « structure de travail [hololens »](https://www.microsoft.com/p/mr-playground/9nb31lh723s2), présentent des exemples excellents sur la façon dont les entrées de regard oculaire peuvent s’ajouter à la magie de votre expérience holographique.</span><span class="sxs-lookup"><span data-stu-id="f291b-110">While eye-gaze input is only used very subtly in our Holographic Shell experience (the user interface that you see when you start your HoloLens 2), several apps, such as the ["HoloLens Playground"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2), showcase great examples on how eye-gaze input can add to the magic of your holographic experience.</span></span>
<span data-ttu-id="f291b-111">Sur cette page, nous aborderons les considérations relatives à la conception pour l’intégration de l’entrée de regard pour interagir avec vos applications holographiques.</span><span class="sxs-lookup"><span data-stu-id="f291b-111">On this page, we discuss design considerations for integrating eye-gaze input to interact with your holographic applications.</span></span>
<span data-ttu-id="f291b-112">Vous en apprendrez davantage sur les principaux avantages et les défis uniques qui accompagnent les entrées de regard.</span><span class="sxs-lookup"><span data-stu-id="f291b-112">You will learn about key advantages and also unique challenges that come with eye-gaze input.</span></span>  
<span data-ttu-id="f291b-113">Sur la base de ces informations, nous fournissons plusieurs recommandations de conception pour vous aider à créer des interfaces utilisateur compatibles avec le regard.</span><span class="sxs-lookup"><span data-stu-id="f291b-113">Based on these, we provide several design recommendations to help you create satisfying eye-gaze-supported user interfaces.</span></span> 

## <a name="device-support"></a><span data-ttu-id="f291b-114">Prise en charge des appareils</span><span class="sxs-lookup"><span data-stu-id="f291b-114">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="f291b-115"><strong>Fonctionnalité</strong></span><span class="sxs-lookup"><span data-stu-id="f291b-115"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="f291b-116"><a href="hololens-hardware-details.md"><strong>HoloLens (1ère génération)</strong></a></span><span class="sxs-lookup"><span data-stu-id="f291b-116"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="f291b-117"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="f291b-117"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="f291b-118"><a href="immersive-headset-hardware-details.md"><strong>Casques immersifs</strong></a></span><span class="sxs-lookup"><span data-stu-id="f291b-118"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="f291b-119">Œil-point de regard</span><span class="sxs-lookup"><span data-stu-id="f291b-119">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="f291b-120">✔️</span><span class="sxs-lookup"><span data-stu-id="f291b-120">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>


## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="f291b-121">Conseils pour la conception d’entrées de regard</span><span class="sxs-lookup"><span data-stu-id="f291b-121">Eye-gaze input design guidelines</span></span>
<span data-ttu-id="f291b-122">La création d’une interaction qui tire parti du ciblage visuel à déplacement rapide peut être difficile.</span><span class="sxs-lookup"><span data-stu-id="f291b-122">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="f291b-123">Dans cette section, nous résumerons les principaux avantages et défis à prendre en compte lors de la conception de votre application.</span><span class="sxs-lookup"><span data-stu-id="f291b-123">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="f291b-124">Avantages de l’entrée en regard des yeux</span><span class="sxs-lookup"><span data-stu-id="f291b-124">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="f291b-125">**Pointage à haute vitesse.**</span><span class="sxs-lookup"><span data-stu-id="f291b-125">**High speed pointing.**</span></span> <span data-ttu-id="f291b-126">Le muscle oculaire est le muscle le plus rapide dans le corps humain.</span><span class="sxs-lookup"><span data-stu-id="f291b-126">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="f291b-127">**Faible effort.**</span><span class="sxs-lookup"><span data-stu-id="f291b-127">**Low effort.**</span></span> <span data-ttu-id="f291b-128">Pratiquement aucun mouvement physique n’est nécessaire.</span><span class="sxs-lookup"><span data-stu-id="f291b-128">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="f291b-129">**Implicite.**</span><span class="sxs-lookup"><span data-stu-id="f291b-129">**Implicitness.**</span></span> <span data-ttu-id="f291b-130">Souvent décrits par les utilisateurs comme « sens de lecture », les informations relatives aux mouvements oculaires d’un utilisateur permettent au système de savoir à quelle cible l’utilisateur envisage de s’impliquer.</span><span class="sxs-lookup"><span data-stu-id="f291b-130">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="f291b-131">**Autre canal d’entrée.**</span><span class="sxs-lookup"><span data-stu-id="f291b-131">**Alternative input channel.**</span></span> <span data-ttu-id="f291b-132">L’œil-point de vue peut fournir une entrée de prise en charge puissante pour les entrées de main et vocales, basées sur des années d’expérience des utilisateurs en fonction de leur coordination manuelle.</span><span class="sxs-lookup"><span data-stu-id="f291b-132">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="f291b-133">**Attention visuelle.**</span><span class="sxs-lookup"><span data-stu-id="f291b-133">**Visual attention.**</span></span> <span data-ttu-id="f291b-134">Un autre avantage important est la possibilité de déduire ce à quoi un utilisateur fait attention.</span><span class="sxs-lookup"><span data-stu-id="f291b-134">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="f291b-135">Cela peut aider dans différents domaines d’application, allant de l’évaluation plus efficace de conceptions différentes à l’aide d’interfaces utilisateur plus intelligentes et de signaux sociaux améliorés pour la communication à distance.</span><span class="sxs-lookup"><span data-stu-id="f291b-135">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="f291b-136">Pour résumer, l’utilisation de la forme œil-point d’entrée offre un signal d’entrée contextuel rapide et sans effort.</span><span class="sxs-lookup"><span data-stu-id="f291b-136">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual input signal.</span></span> <span data-ttu-id="f291b-137">Cela est particulièrement puissant lorsqu’il est combiné à d’autres entrées, telles que la *voix* et l’entrée *manuelle* , pour confirmer l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="f291b-137">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="f291b-138">Défis de l’entrée</span><span class="sxs-lookup"><span data-stu-id="f291b-138">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="f291b-139">Avec un grand nombre d’énergie, la responsabilité est importante.</span><span class="sxs-lookup"><span data-stu-id="f291b-139">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="f291b-140">Bien qu’il soit possible d’utiliser des points de vue oculaire pour créer des expériences utilisateur satisfaisantes, il est également important de savoir ce qu’il n’est pas judicieux de prendre en compte.</span><span class="sxs-lookup"><span data-stu-id="f291b-140">While eye-gaze can be used to create satisfying user experiences which make you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="f291b-141">Ce qui suit présente certains *défis* à prendre en compte et comment les résoudre quand vous travaillez avec des entrées de regard :</span><span class="sxs-lookup"><span data-stu-id="f291b-141">The following discusses some *challenges* to consider and how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="f291b-142">**Votre regard est « Always on »** Le moment où vous ouvrez vos couvercles oculaires, vos yeux commencent que sur les choses de l’environnement.</span><span class="sxs-lookup"><span data-stu-id="f291b-142">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="f291b-143">En réagissant à chaque aspect que vous effectuez et en émettant accidentellement des actions, parce que vous avez examiné un peu trop de temps, vous risquez d’avoir une expérience insuffisante.</span><span class="sxs-lookup"><span data-stu-id="f291b-143">Reacting to every look you make and accidentally issuing actions, because you looked at something for too long, would result in an unsatisfying experience.</span></span>
<span data-ttu-id="f291b-144">Par conséquent, nous vous recommandons de combiner les yeux oculaires avec une *commande vocale*, un *mouvement manuel*, un *clic de bouton* ou un logement étendu pour déclencher la sélection d’une cible (pour plus d’informations, consultez [regard et validation](gaze-and-commit-eyes.md)).</span><span class="sxs-lookup"><span data-stu-id="f291b-144">Therefore, we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target (for more information see [eye-gaze and commit](gaze-and-commit-eyes.md)).</span></span>
<span data-ttu-id="f291b-145">Cette solution permet également à un mode dans lequel l’utilisateur peut effectuer des recherches librement sans être submergé par le déclenchement involontaire d’un événement.</span><span class="sxs-lookup"><span data-stu-id="f291b-145">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="f291b-146">Ce problème doit également être pris en compte lors de la conception de commentaires visuels et auditifs lors de la recherche d’une cible.</span><span class="sxs-lookup"><span data-stu-id="f291b-146">This issue should also be considered when designing visual and auditory feedback when looking at a target.</span></span>
<span data-ttu-id="f291b-147">Essayez de ne pas saturer l’utilisateur avec des effets de fenêtres instantanées ou des sons de survol.</span><span class="sxs-lookup"><span data-stu-id="f291b-147">Try not to overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="f291b-148">La subtilité est essentielle.</span><span class="sxs-lookup"><span data-stu-id="f291b-148">Subtlety is key.</span></span> <span data-ttu-id="f291b-149">Nous étudierons quelques-unes des meilleures pratiques ci-dessous lorsque vous parlerez des [recommandations de conception](eye-gaze-interaction.md#design-recommendations).</span><span class="sxs-lookup"><span data-stu-id="f291b-149">We will discuss some best practices for this further below when talking about [design recommendations](eye-gaze-interaction.md#design-recommendations).</span></span>

- <span data-ttu-id="f291b-150">**Observation et contrôle** Imaginez que vous souhaitez redresser précisément une photographie sur votre mur.</span><span class="sxs-lookup"><span data-stu-id="f291b-150">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="f291b-151">Vous regardez les bords de la photo et ce qui se trouve à proximité pour voir si elle est bien alignée.</span><span class="sxs-lookup"><span data-stu-id="f291b-151">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="f291b-152">Imaginez maintenant comment procéder lorsque vous souhaitez utiliser le point de vue de l’œil pour déplacer l’image.</span><span class="sxs-lookup"><span data-stu-id="f291b-152">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="f291b-153">Difficile, n’est-ce pas ?</span><span class="sxs-lookup"><span data-stu-id="f291b-153">Difficult, isn't it?</span></span> <span data-ttu-id="f291b-154">Cela décrit le double rôle de regard pour les entrées et les contrôles.</span><span class="sxs-lookup"><span data-stu-id="f291b-154">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="f291b-155">**Conserver avant de cliquer :** Pour les sélections de cibles rapides, la recherche a montré que le point de regard de l’utilisateur peut se déplacer avant de conclure un clic manuel (par exemple, un robinet air).</span><span class="sxs-lookup"><span data-stu-id="f291b-155">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an air tap).</span></span> <span data-ttu-id="f291b-156">Par conséquent, une attention particulière doit être accordée à la synchronisation du signal rapide oeil-regard avec une entrée de contrôle plus lente (par exemple, voix, mains, contrôleur).</span><span class="sxs-lookup"><span data-stu-id="f291b-156">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="f291b-157">**Petites cibles :** Savez-vous le sentiment quand vous essayez de lire du texte qui est un peu trop petit pour le lire confortablement ?</span><span class="sxs-lookup"><span data-stu-id="f291b-157">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="f291b-158">Ce sentiment de distraction sur vos yeux peut vous amener à vous sentir fatigué et à être usé, car vous essayez de réajuster vos yeux pour mieux vous concentrer.</span><span class="sxs-lookup"><span data-stu-id="f291b-158">This straining feeling on your eyes can cause you to feel tired and worn out, because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="f291b-159">C’est un sentiment que vous pouvez appeler dans vos utilisateurs en les forçant à sélectionner des cibles qui sont trop petites dans votre application à l’aide d’un ciblage oculaire.</span><span class="sxs-lookup"><span data-stu-id="f291b-159">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="f291b-160">Durant la conception, si vous souhaitez créer une expérience utilisateur agréable et confortable, nous vous recommandons de privilégier des cibles ayant un angle de vue d’au moins 2°, sinon plus de préférence.</span><span class="sxs-lookup"><span data-stu-id="f291b-160">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="f291b-161">**Mouvements de regard en œil irrégulier** Nos yeux effectuent des mouvements rapides de la fixation à la fixation.</span><span class="sxs-lookup"><span data-stu-id="f291b-161">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="f291b-162">Si vous examinez un enregistrement des mouvements oculaires, vous pouvez voir qu’ils sont irréguliers.</span><span class="sxs-lookup"><span data-stu-id="f291b-162">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="f291b-163">Vos yeux se déplacent rapidement et dans des passages spontanés par rapport aux mouvements du point de vue de la *main*ou du *regard* .</span><span class="sxs-lookup"><span data-stu-id="f291b-163">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="f291b-164">**Suivi de la fiabilité :** La précision du suivi des yeux peut être légèrement dégradée lorsque vos yeux évoluent en fonction des nouvelles conditions.</span><span class="sxs-lookup"><span data-stu-id="f291b-164">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eyes adjust to the new conditions.</span></span>
<span data-ttu-id="f291b-165">Même si cela ne doit pas nécessairement affecter la conception de votre application, car la précision doit être comprise dans la limite de 2 °, il peut être nécessaire que l’utilisateur l’étalonne à nouveau.</span><span class="sxs-lookup"><span data-stu-id="f291b-165">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, it may be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="f291b-166">Recommandations de conception</span><span class="sxs-lookup"><span data-stu-id="f291b-166">Design recommendations</span></span>
<span data-ttu-id="f291b-167">La liste suivante répertorie les recommandations de conception spécifiques en fonction des avantages et des défis décrits pour les entrées de regard :</span><span class="sxs-lookup"><span data-stu-id="f291b-167">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="f291b-168">**L’œil-point de regard n’est pas le même que le point de regard :**</span><span class="sxs-lookup"><span data-stu-id="f291b-168">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="f291b-169">**Déterminez si les mouvements oculaires rapides mais irréguliers s’adaptent à votre tâche d’entrée :** Si nos mouvements oculaires rapides et irréguliers sont très utiles pour sélectionner rapidement des cibles dans notre champ de vue, elles sont moins applicables aux tâches qui nécessitent des trajectoires d’entrée lisses (par exemple, des annotations de dessin ou de cercle).</span><span class="sxs-lookup"><span data-stu-id="f291b-169">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="f291b-170">Dans ce cas, le pointage à la main ou avec la tête est préférable.</span><span class="sxs-lookup"><span data-stu-id="f291b-170">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="f291b-171">**Évitez de joindre un texte directement à l’oeil de l’utilisateur (par exemple, un curseur ou un curseur).**</span><span class="sxs-lookup"><span data-stu-id="f291b-171">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="f291b-172">Dans le cas d’un curseur, cela peut entraîner un effet de curseur « Fleeing » en raison de légers décalages dans le signal de point de regard projeté.</span><span class="sxs-lookup"><span data-stu-id="f291b-172">In case of a cursor, this may result in a "fleeing cursor" effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="f291b-173">Dans le cas d’un curseur, il peut entrer en conflit avec le double rôle de contrôle du curseur avec vos yeux, tout en souhaitant vérifier si l’objet se trouve à l’emplacement approprié.</span><span class="sxs-lookup"><span data-stu-id="f291b-173">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="f291b-174">Pour l’exemple du curseur, il est plus judicieux d’utiliser une combinaison œil-regard avec les gestes manuels.</span><span class="sxs-lookup"><span data-stu-id="f291b-174">For the example of the slider, it makes more sense to use eye-gaze in combination with hand gestures.</span></span> <span data-ttu-id="f291b-175">Cela signifie que l’utilisateur peut basculer rapidement et facilement entre un certain nombre de curseurs, en augmentant leur main et en pinceant leur Thumb et leur doigt d’index pour les saisir et les déplacer.</span><span class="sxs-lookup"><span data-stu-id="f291b-175">This means that the user could quickly and effortlessly switch among a number of sliders, raising up their hand and pinching their thumb and index finger to grab and move it.</span></span> <span data-ttu-id="f291b-176">Quand le pincement est relâché, le curseur cesse de se déplacer.</span><span class="sxs-lookup"><span data-stu-id="f291b-176">When the pinch is released, the slider stops moving.</span></span> <span data-ttu-id="f291b-177">Pour résumer, les utilisateurs peuvent devenir submergés et perturbés, en particulier si le signal n’est pas précis pour cet utilisateur.</span><span class="sxs-lookup"><span data-stu-id="f291b-177">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="f291b-178">**Combinez les yeux avec d’autres entrées :** L’intégration du suivi oculaire avec d’autres entrées, telles que les gestes à main, les commandes vocales ou les enfoncements de bouton, offre plusieurs avantages :</span><span class="sxs-lookup"><span data-stu-id="f291b-178">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, provides several advantages:</span></span>
    - <span data-ttu-id="f291b-179">**Autoriser l’observation gratuite :** Étant donné que le rôle principal de nos yeux est d’observer notre environnement, il est important que les utilisateurs soient autorisés à regarder sans déclencher des commentaires ou des actions (visuel, audit, etc.).</span><span class="sxs-lookup"><span data-stu-id="f291b-179">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important that users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="f291b-180">La combinaison du suivi oculaire et d’un autre contrôle d’entrée permet une transition sans heurts entre l’observation du suivi oculaire et les modes de contrôle d’entrée.</span><span class="sxs-lookup"><span data-stu-id="f291b-180">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="f291b-181">**Fournisseur de contexte puissant :** À l’aide d’informations sur l’emplacement et le rôle de l’utilisateur, tout en disant une commande vocale ou en effectuant un mouvement manuel, vous permet de canaliser en toute transparence l’entrée dans le champ de la vue.</span><span class="sxs-lookup"><span data-stu-id="f291b-181">**Powerful context provider:** Using information about where and what the user is looking at while saying a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="f291b-182">Par exemple : _« Placez_ -le » pour sélectionner et positionner rapidement et de façon Fluent un hologramme sur la scène en examinant simplement une cible et sa destination prévue.</span><span class="sxs-lookup"><span data-stu-id="f291b-182">For example: Say _"put that there"_ to quickly and fluently select and position a hologram across the scene by simply looking at a target and its intended destination.</span></span> 

    - <span data-ttu-id="f291b-183">**Nécessité de synchroniser les entrées multimodales :** La combinaison rapide de mouvements oculaires avec des entrées supplémentaires plus complexes, telles que des commandes vocales longues ou des gestes à la main, risque de voir que l’utilisateur continue à rechercher avant la fin et la reconnaissance de la commande d’entrée supplémentaire.</span><span class="sxs-lookup"><span data-stu-id="f291b-183">**Need for synchronizing multimodal inputs:** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk that the user already continues to look around before the additional input command is finished and recognized.</span></span> <span data-ttu-id="f291b-184">Par conséquent, si vous créez vos propres contrôles d’entrée (par exemple, des gestes personnalisés), veillez à consigner le début de cette entrée ou la durée approximative pour la corréler avec ce qu’un utilisateur a regardé dans le passé.</span><span class="sxs-lookup"><span data-stu-id="f291b-184">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="f291b-185">**Commentaires subtils pour l’entrée de suivi oculaire :** Il est utile de fournir des commentaires lorsqu’une cible est examinée pour indiquer que le système fonctionne comme prévu, mais qu’il doit rester discret.</span><span class="sxs-lookup"><span data-stu-id="f291b-185">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="f291b-186">Cela peut inclure la fusion lente, l’in et l’extraction, les surbrillances visuelles ou l’exécution d’autres comportements de cible subtils, tels que des mouvements lents, tels que l’amélioration légèrement de la taille cible, pour indiquer que le système a détecté correctement que l’utilisateur examine une cible sans inutilement interrompre le flux de travail actuel de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="f291b-186">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="f291b-187">**Évitez d’appliquer des mouvements oculaires innaturels comme entrée :** Ne forcez pas les utilisateurs à effectuer des mouvements d’oeil spécifiques (mouvements de regard) pour déclencher des actions dans votre application.</span><span class="sxs-lookup"><span data-stu-id="f291b-187">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="f291b-188">**Compte pour les imprécisions :** Nous distingueons deux types d’imprécisions qui sont perceptibles pour les utilisateurs : décalage et instabilité.</span><span class="sxs-lookup"><span data-stu-id="f291b-188">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="f291b-189">Le moyen le plus simple de traiter un décalage consiste à fournir des cibles suffisamment volumineuses pour interagir avec.</span><span class="sxs-lookup"><span data-stu-id="f291b-189">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="f291b-190">Il est recommandé d’utiliser un angle visuel supérieur à 2 ° comme référence.</span><span class="sxs-lookup"><span data-stu-id="f291b-190">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="f291b-191">Par exemple, votre miniature est d’environ 2 ° dans l’angle visuel lorsque vous étirez votre bras.</span><span class="sxs-lookup"><span data-stu-id="f291b-191">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="f291b-192">Il en résulte les conseils d’aide suivants :</span><span class="sxs-lookup"><span data-stu-id="f291b-192">This leads to the following guidance:</span></span>
    - <span data-ttu-id="f291b-193">Ne forcez pas les utilisateurs à sélectionner des cibles minuscules.</span><span class="sxs-lookup"><span data-stu-id="f291b-193">Do not force users to select tiny targets.</span></span> <span data-ttu-id="f291b-194">La recherche a montré que si les cibles sont suffisamment volumineuses et que le système est bien conçu, les utilisateurs décrivent leurs interactions sans effort et magique.</span><span class="sxs-lookup"><span data-stu-id="f291b-194">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="f291b-195">Si les cibles deviennent trop petites, les utilisateurs décrivent l’expérience comme étant fatigante et frustrante.</span><span class="sxs-lookup"><span data-stu-id="f291b-195">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
<br>

<span data-ttu-id="f291b-196">Cette page vous a fourni une bonne présentation pour vous aider à comprendre les regards oculaires en tant qu’entrée dans la réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="f291b-196">This page provided you with a good overview to get you started understanding eye-gaze as an input in mixed reality.</span></span> <span data-ttu-id="f291b-197">Pour commencer à développer, consultez les informations sur les [yeux](https://aka.ms/mrtk-eyes) et les [yeux dans DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="f291b-197">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="f291b-198">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="f291b-198">See also</span></span>
* [<span data-ttu-id="f291b-199">Confort</span><span class="sxs-lookup"><span data-stu-id="f291b-199">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="f291b-200">Œil-point de regard sur DirectX</span><span class="sxs-lookup"><span data-stu-id="f291b-200">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="f291b-201">Œil-point d’interfaut</span><span class="sxs-lookup"><span data-stu-id="f291b-201">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="f291b-202">Suivi oculaire sur HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="f291b-202">Eye tracking on HoloLens 2</span></span>](eye-tracking.md)
* [<span data-ttu-id="f291b-203">Pointer et valider</span><span class="sxs-lookup"><span data-stu-id="f291b-203">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="f291b-204">Pointer du regard et fixer</span><span class="sxs-lookup"><span data-stu-id="f291b-204">Gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="f291b-205">Entrée vocale</span><span class="sxs-lookup"><span data-stu-id="f291b-205">Voice input</span></span>](voice-design.md)
