---
title: Vue d’ensemble de l’interaction multimodale
description: Vue d’ensemble de l’interaction multimodale
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixte réalité, les regards, les regards ciblant, interaction, concevez, hololens, MMR, multimodale
ms.openlocfilehash: d018179e20d26ee8b7b24bc74d7c1711bc788282
ms.sourcegitcommit: aba33a8ad1416f7598048ac35ae9ab1734bd5c37
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 05/28/2019
ms.locfileid: "66270385"
---
# <a name="introducing-instinctual-interactions"></a><span data-ttu-id="163c6-104">Présentation des interactions instinctual</span><span class="sxs-lookup"><span data-stu-id="163c6-104">Introducing instinctual interactions</span></span>

<span data-ttu-id="163c6-105">La philosophie d’interactions simples, instinctual nouée tout au long de la plateforme Microsoft mixte réalité (MMR), du matériel au logiciel.</span><span class="sxs-lookup"><span data-stu-id="163c6-105">The philosophy of simple, instinctual interactions is woven throughout the Microsoft Mixed Reality (MMR) platform, from hardware to software.</span></span>

<span data-ttu-id="163c6-106">Ces interactions instinctual utilisent toutes les technologies de d’entrée disponibles, y compris à l’intérieur de suivi main suivi, suivi de le œil et d’extraction du langage naturel, dans les modèles d’interaction multimodale transparente.</span><span class="sxs-lookup"><span data-stu-id="163c6-106">These instinctual interactions utilize all available input technologies, including inside-out tracking, hand tracking, eye tracking, and natural language, in seamless multimodal interaction models.</span></span> <span data-ttu-id="163c6-107">Selon nos recherches, conception et développement multimodals et non pas sur les entrées uniques, sont essentiel lors de la création d’expériences instinctive.</span><span class="sxs-lookup"><span data-stu-id="163c6-107">Based on our research, designing and developing multimodals, and not based on single inputs, is critical when creating instinctive experiences.</span></span>

<span data-ttu-id="163c6-108">Les modèles d’Interaction Instinctual alignent également naturellement dans les types d’appareils.</span><span class="sxs-lookup"><span data-stu-id="163c6-108">The Instinctual Interaction models also naturally align across device types.</span></span>  <span data-ttu-id="163c6-109">Par exemple, une interaction lointain sur un casque immersive avec un 6 degrés de contrôleur de liberté (DDL) et l’interaction lointain 2 HoloLens utiliser l’intuitivité de même, les modèles et les comportements.</span><span class="sxs-lookup"><span data-stu-id="163c6-109">For example, far interaction on an immersive headset with a 6 degrees of freedom (DoF) controller and far interaction on a HoloLens 2 use the same affordances, patterns, and behaviors.</span></span>  <span data-ttu-id="163c6-110">Est non seulement ce pratique pour les développeurs et concepteurs, mais il a l’air normal pour les utilisateurs finaux.</span><span class="sxs-lookup"><span data-stu-id="163c6-110">Not only is this convenient for developers and designers, but it feels natural to end users.</span></span>


<span data-ttu-id="163c6-111">Enfin, alors que nous reconnaissons qu’il existe des milliers d’effective, attrayantes et interactions magiques possibles dans MR, nous avons trouvé cette intentionnellement utilisant un modèle d’interaction unique bout en bout dans une application est la meilleure façon de garantir aux utilisateurs réussissent et offrir une bonne expérience.</span><span class="sxs-lookup"><span data-stu-id="163c6-111">Lastly, while we recognize that there are thousands of effective, engaging, and magical interactions possible in MR, we have found that intentionally employing a single interaction model end to end in an application is the best way to ensure users are successful and have a great experience.</span></span>  <span data-ttu-id="163c6-112">À cette fin, nous avons inclus les trois choses dans ce guide de l’interaction :</span><span class="sxs-lookup"><span data-stu-id="163c6-112">To that end, we've included three things in this interaction guidance:</span></span>
* <span data-ttu-id="163c6-113">Nous avons structuré ce guide autour de trois modèles d’interaction principal et les composants et les modèles requis pour chaque</span><span class="sxs-lookup"><span data-stu-id="163c6-113">We've structured this guidance around the three primary interaction models and the components and patterns required for each</span></span>
* <span data-ttu-id="163c6-114">Nous avons inclus des conseils supplémentaires sur les autres avantages offerts par notre plateforme</span><span class="sxs-lookup"><span data-stu-id="163c6-114">We've included supplemental guidance on other benefits that our platform provides</span></span>
* <span data-ttu-id="163c6-115">Nous avons inclus des conseils pour aider à sélectionner le modèle d’interaction approprié pour votre scénario</span><span class="sxs-lookup"><span data-stu-id="163c6-115">We've included guidance to help select the appropriate interaction model for your scenario</span></span>

## <a name="multimodal-interaction-models"></a><span data-ttu-id="163c6-116">Modèles d’interaction multimodale</span><span class="sxs-lookup"><span data-stu-id="163c6-116">Multimodal interaction models</span></span>

<span data-ttu-id="163c6-117">Selon notre recherche et la collaboration avec les clients à ce jour, nous avons découvert les trois modèles d’interaction principal qui convient à la majorité des expériences de réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="163c6-117">Based on our research and work with customers to date, we've discovered three primary interaction models that suit the majority of Mixed Reality experiences.</span></span>  

<span data-ttu-id="163c6-118">Considérez ces modèles d’interaction comme modèle mental de l’utilisateur pour l’exécution de leurs flux.</span><span class="sxs-lookup"><span data-stu-id="163c6-118">Think of these interaction models as the user's mental model for completing their flows.</span></span>

<span data-ttu-id="163c6-119">Chacun de ces modèles d’interaction est pratique, puissant et utilisable à part entière, et tous sont optimisés pour un ensemble de besoins des clients.</span><span class="sxs-lookup"><span data-stu-id="163c6-119">Each of these interaction models is convenient, powerful, and usable in its own right, and all are optimized for a set of customer needs.</span></span> <span data-ttu-id="163c6-120">Afficher le graphique ci-dessous, pour des scénarios, des exemples et des avantages de chaque modèle d’interaction.</span><span class="sxs-lookup"><span data-stu-id="163c6-120">View the chart below, for scenarios, examples, and benefits of each interaction model.</span></span>  

<span data-ttu-id="163c6-121">**Modèle**</span><span class="sxs-lookup"><span data-stu-id="163c6-121">**Model**</span></span> | <span data-ttu-id="163c6-122">**[Mains et contrôleurs de mouvement](hands-and-tools.md)**</span><span class="sxs-lookup"><span data-stu-id="163c6-122">**[Hands and motion controllers](hands-and-tools.md)**</span></span> | <span data-ttu-id="163c6-123">**[Mains libres](hands-free.md)**</span><span class="sxs-lookup"><span data-stu-id="163c6-123">**[Hands free](hands-free.md)**</span></span> | <span data-ttu-id="163c6-124">**[Regards de tête et de validation](gaze-and-commit.md)**</span><span class="sxs-lookup"><span data-stu-id="163c6-124">**[Head-gaze and commit](gaze-and-commit.md)**</span></span>
|--------- | --------------| ------------| ---------|
<span data-ttu-id="163c6-125">**Exemples de scénarios**</span><span class="sxs-lookup"><span data-stu-id="163c6-125">**Example Scenarios**</span></span> | <span data-ttu-id="163c6-126">Du contenu 3D expériences spatiales, par exemple spatiale disposition et conception, de manipulation ou de simulation</span><span class="sxs-lookup"><span data-stu-id="163c6-126">3D spatial experiences, e.g. spatial layout and design, content manipulation, or simulation</span></span> | <span data-ttu-id="163c6-127">Expériences contextuelles, où les mains d’un utilisateur sont occupés, par exemple, sur le travail d’apprentissage, de maintenance</span><span class="sxs-lookup"><span data-stu-id="163c6-127">Contextual experiences where a user's hands are occupied, e.g. on the-job learning, maintenance</span></span>| <span data-ttu-id="163c6-128">Clic des expériences, par exemple, des présentations 3D, des démonstrations</span><span class="sxs-lookup"><span data-stu-id="163c6-128">Click-through experiences, e.g. 3D presentations, demos</span></span>
<span data-ttu-id="163c6-129">**Fit**</span><span class="sxs-lookup"><span data-stu-id="163c6-129">**Fit**</span></span> | <span data-ttu-id="163c6-130">Idéal pour les nouveaux utilisateurs, voix couplée wit, des yeux regards suivi ou principal.</span><span class="sxs-lookup"><span data-stu-id="163c6-130">Great for new users, coupled wit voice, eye tracking or head gaze.</span></span> <span data-ttu-id="163c6-131">Courbe d’apprentissage basse.</span><span class="sxs-lookup"><span data-stu-id="163c6-131">Low learning curve.</span></span> <span data-ttu-id="163c6-132">Expérience utilisateur cohérente entre main suivi et 6 contrôleurs DDL.</span><span class="sxs-lookup"><span data-stu-id="163c6-132">Consistent UX across hand tracking and 6 DoF controllers.</span></span> | <span data-ttu-id="163c6-133">Certains d’apprentissage nécessaire.</span><span class="sxs-lookup"><span data-stu-id="163c6-133">Some learning required.</span></span> <span data-ttu-id="163c6-134">Si les mains sont des paires indisponibles bien avec la voix et de langage naturel</span><span class="sxs-lookup"><span data-stu-id="163c6-134">If hands are unavailable pairs well with voice and natural language</span></span> | <span data-ttu-id="163c6-135">Nécessite une formation sur HMDs, mais pas sur mobile.</span><span class="sxs-lookup"><span data-stu-id="163c6-135">Requires training on HMDs but not on mobile.</span></span> <span data-ttu-id="163c6-136">Idéal pour les contrôleurs accessibles.</span><span class="sxs-lookup"><span data-stu-id="163c6-136">Best for accessible controllers.</span></span> <span data-ttu-id="163c6-137">Idéal pour HoloLens (1er gen).</span><span class="sxs-lookup"><span data-stu-id="163c6-137">Best for HoloLens (1st gen).</span></span> |
<span data-ttu-id="163c6-138">**Matériel**</span><span class="sxs-lookup"><span data-stu-id="163c6-138">**Hardware**</span></span> | <span data-ttu-id="163c6-139">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="163c6-139">HoloLens 2</span></span> <br><span data-ttu-id="163c6-140">Casques immersifs</span><span class="sxs-lookup"><span data-stu-id="163c6-140">Immersive headsets</span></span> | <span data-ttu-id="163c6-141">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="163c6-141">HoloLens 2</span></span> <br><span data-ttu-id="163c6-142">HoloLens (1er gen)</span><span class="sxs-lookup"><span data-stu-id="163c6-142">HoloLens (1st gen)</span></span> <br><span data-ttu-id="163c6-143">Casques immersifs</span><span class="sxs-lookup"><span data-stu-id="163c6-143">Immersive headsets</span></span> | <span data-ttu-id="163c6-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="163c6-144">HoloLens 2</span></span> <br><span data-ttu-id="163c6-145">Casques immersifs</span><span class="sxs-lookup"><span data-stu-id="163c6-145">Immersive headsets</span></span> | <span data-ttu-id="163c6-146">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="163c6-146">HoloLens 2</span></span> <br><span data-ttu-id="163c6-147">HoloLens (1er gen)</span><span class="sxs-lookup"><span data-stu-id="163c6-147">HoloLens (1st gen)</span></span> <br><span data-ttu-id="163c6-148">Casques immersifs</span><span class="sxs-lookup"><span data-stu-id="163c6-148">Immersive headsets</span></span> <br><span data-ttu-id="163c6-149">Mobile AR</span><span class="sxs-lookup"><span data-stu-id="163c6-149">Mobile AR</span></span> |

<span data-ttu-id="163c6-150">Des informations détaillées pour l’utilisation de toutes les entrées disponibles dans chaque modèle d’interaction entre eux se trouve sur les pages qui suivent, ainsi que les illustrations et les liens vers du contenu de l’exemple à partir de notre MRTK Unity.</span><span class="sxs-lookup"><span data-stu-id="163c6-150">Detailed information for using all available inputs seamlessly together in each interaction model is on the pages that follow, as well as illustrations and links to sample content from our Unity MRTK.</span></span>


## <a name="choose-an-interaction-model-for-your-customer"></a><span data-ttu-id="163c6-151">Choisir un modèle d’interaction pour votre client</span><span class="sxs-lookup"><span data-stu-id="163c6-151">Choose an interaction model for your customer</span></span>


<span data-ttu-id="163c6-152">Les développeurs et les créateurs d’également disposent déjà probablement quelques idées à l’esprit des types d’expérience d’interaction qu’ils souhaitent leurs utilisateurs d’avoir.</span><span class="sxs-lookup"><span data-stu-id="163c6-152">Most likely, developers and creators also already have some ideas in mind of the kinds of interaction experience they want their users to have.</span></span>
<span data-ttu-id="163c6-153">Pour encourager une approche axée sur le client pour concevoir, nous vous recommandons de suivre les instructions ci-dessous pour sélectionner le modèle d’interaction qui est optimisé pour votre client.</span><span class="sxs-lookup"><span data-stu-id="163c6-153">To encourage a customer-focused approach to design, we recommend following the guidance below to select the interaction model that's optimized for your customer.</span></span>

### <a name="why-follow-this-guidance"></a><span data-ttu-id="163c6-154">Pourquoi suivre ce guide ?</span><span class="sxs-lookup"><span data-stu-id="163c6-154">Why follow this guidance?</span></span>

* <span data-ttu-id="163c6-155">Nos modèles d’interaction sont testés pour les objectifs et critères subjectifs tels que des efforts physiques et cognitive, intuitiveness et learnability.</span><span class="sxs-lookup"><span data-stu-id="163c6-155">Our interaction models are tested for objective and subjective criteria such as physical and cognitive effort, intuitiveness, and learnability.</span></span> 
* <span data-ttu-id="163c6-156">Car diffère de l’interaction, intuitivité audio et visuelles et comportement des objets peuvent également différer entre les modèles d’interaction.</span><span class="sxs-lookup"><span data-stu-id="163c6-156">Because interaction differs, visual and audio affordances and object behavior may also differ between the interaction models.</span></span>  
* <span data-ttu-id="163c6-157">Combinant des parties de plusieurs modèles d’interaction crée le risque de concurrents intuitivité, telles que des rayons main simultanées et un curseur regards de tête, qui submerger et la confusion chez les utilisateurs.</span><span class="sxs-lookup"><span data-stu-id="163c6-157">Combining parts of multiple interaction models together creates the risk of competing affordances, such as simultaneous hand rays and a head-gaze cursor, which overwhelm and confuse users.</span></span>

<span data-ttu-id="163c6-158">Voici quelques exemples de la façon dont les intuitivité et comportements sont optimisés pour chaque modèle d’interaction.</span><span class="sxs-lookup"><span data-stu-id="163c6-158">Here are some examples of how affordances and behaviors are optimized for each interaction model.</span></span>  <span data-ttu-id="163c6-159">Nous le constatons souvent nouveaux utilisateurs en tant que des questions similaires, tels que « comment savoir si le système fonctionne, comment savoir ce que je peux faire, et comment savoir si elle compris ce que je viens de faire ? »</span><span class="sxs-lookup"><span data-stu-id="163c6-159">We often see new users as similar questions, such as "how do I know the system is working, how do I know what I can do, and how do I know if it understood what I just did?"</span></span>

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="163c6-160"><strong>Modèle</strong></span><span class="sxs-lookup"><span data-stu-id="163c6-160"><strong>Model</strong></span></span></td>
        <td><span data-ttu-id="163c6-161"><strong>Comment savoir qu’il fonctionne ?</strong></span><span class="sxs-lookup"><span data-stu-id="163c6-161"><strong>How do I know it's working?</strong></span></span></td>
        <td><span data-ttu-id="163c6-162"><strong>Comment savoir que puis-je faire ?</strong></span><span class="sxs-lookup"><span data-stu-id="163c6-162"><strong>How do I know what I can do?</strong></span></span></td>
        <td><span data-ttu-id="163c6-163"><strong>Comment savoir ce que je viens de faire ?</strong></span><span class="sxs-lookup"><span data-stu-id="163c6-163"><strong>How do I know what I just did?</strong></span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="163c6-164"><a href="hands-and-tools.md">Mains et contrôleurs de mouvement</a></span><span class="sxs-lookup"><span data-stu-id="163c6-164"><a href="hands-and-tools.md">Hands and motion controllers</a></span></span></td>
        <td><span data-ttu-id="163c6-165">Je vois une main de maillage, je vois un intuitif du bout des doigts ou une main / contrôleur de rayons.</span><span class="sxs-lookup"><span data-stu-id="163c6-165">I see a hand mesh, I see a fingertip affordance or hand/ controller rays.</span></span></td>
        <td><span data-ttu-id="163c6-166">Je vois des handles grabbable ou un rectangle englobant s’affichent lorsque ma main est proche.</span><span class="sxs-lookup"><span data-stu-id="163c6-166">I see grabbable handles or a bounding box appear when my hand is near.</span></span></td>
        <td><span data-ttu-id="163c6-167">J’ai entendre des tonalités sonores et voir les animations sur la manipulation et la mise en production.</span><span class="sxs-lookup"><span data-stu-id="163c6-167">I hear audible tones and see animations on grab and release.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="163c6-168"><a href="gaze-and-commit.md">Suivre de la tête et valider</a></span><span class="sxs-lookup"><span data-stu-id="163c6-168"><a href="gaze-and-commit.md">Head-gaze and commit</a></span></span></td>
        <td><span data-ttu-id="163c6-169">Je vois un curseur dans le centre de mon champ de vision.</span><span class="sxs-lookup"><span data-stu-id="163c6-169">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="163c6-170">Le curseur de tête-regards change d’état lorsque sur certains objets.</span><span class="sxs-lookup"><span data-stu-id="163c6-170">The head-gaze cursor changes state when over certain objects.</span></span></td>
        <td><span data-ttu-id="163c6-171">J’ai consultez / entendre les confirmations et sonores quand prendre des mesures.</span><span class="sxs-lookup"><span data-stu-id="163c6-171">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>   
    <tr>
        <td><span data-ttu-id="163c6-172"><a href="hands-free.md">Mains libres (Head-regards et durée d’affichage)</a></span><span class="sxs-lookup"><span data-stu-id="163c6-172"><a href="hands-free.md">Hands-free (Head-gaze and dwell)</a></span></span></td>
        <td><span data-ttu-id="163c6-173">Je vois un curseur dans le centre de mon champ de vision.</span><span class="sxs-lookup"><span data-stu-id="163c6-173">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="163c6-174">Je vois un indicateur de progression lorsque je m’attarderai pas sur un objet sur.</span><span class="sxs-lookup"><span data-stu-id="163c6-174">I see a progress indicator when I dwell on an interactable object.</span></span></td>
        <td><span data-ttu-id="163c6-175">J’ai consultez / entendre les confirmations et sonores quand prendre des mesures.</span><span class="sxs-lookup"><span data-stu-id="163c6-175">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="163c6-176"><a href="hands-free.md">Mains libres (exécution des commandes vocales)</a></span><span class="sxs-lookup"><span data-stu-id="163c6-176"><a href="hands-free.md">Hands-free (Voice commanding)</a></span></span></td>
        <td><span data-ttu-id="163c6-177">Je vois un indicateur à l’écoute et sous-titres codés qui montrent ce que le système entendu parler.</span><span class="sxs-lookup"><span data-stu-id="163c6-177">I see a listening indicator and captions that show what the system heard.</span></span></td>
        <td><span data-ttu-id="163c6-178">J’obtiens des indicateurs et des invites vocales.</span><span class="sxs-lookup"><span data-stu-id="163c6-178">I get voice prompts and hints.</span></span>  <span data-ttu-id="163c6-179">Lorsque je dis « que puis-je dire ? »</span><span class="sxs-lookup"><span data-stu-id="163c6-179">When I say "what can I say?"</span></span> <span data-ttu-id="163c6-180">Je vois des commentaires.</span><span class="sxs-lookup"><span data-stu-id="163c6-180">I see feedback.</span></span></td>
        <td><span data-ttu-id="163c6-181">J’ai consultez / entendre les confirmations et sonores lorsque j’ai une commande ou obtenir de levée d’ambiguïté l’expérience utilisateur si nécessaire.</span><span class="sxs-lookup"><span data-stu-id="163c6-181">I see/ hear visual and audible confirmations when I give a command, or get disambiguation UX when needed.</span></span></a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a><span data-ttu-id="163c6-182">Voici les questions que nous avons constaté aide les équipes sélectionnez un modèle d’interaction :</span><span class="sxs-lookup"><span data-stu-id="163c6-182">Below are the questions that we've found help teams select an interaction model:</span></span>
 
1.  <span data-ttu-id="163c6-183">Q :  Mes utilisateurs voulez-vous touch hologrammes et effectuer des manipulations de précision HOLOGRAPHIQUE ?</span><span class="sxs-lookup"><span data-stu-id="163c6-183">Q:  Do my users want to touch holograms and perform precision holographic manipulations?</span></span><br><br>
<span data-ttu-id="163c6-184">R :  Dans ce cas, consultez le modèle d’interaction des mains et pour le ciblage de précision et de manipulation avec mains ou contrôleurs de mouvement.</span><span class="sxs-lookup"><span data-stu-id="163c6-184">A:  If so, check out the Hands and tools interaction model for precision targeting and manipulation with hands or motion controllers.</span></span>
 
2.  <span data-ttu-id="163c6-185">Q :  Mes utilisateurs doivent-ils conserver leurs mains gratuits pour les tâches réelles ?</span><span class="sxs-lookup"><span data-stu-id="163c6-185">Q:  Do my users need to keep their hands free, for real-world tasks?</span></span><br><br>
<span data-ttu-id="163c6-186">R :  Dans ce cas, examinons le modèle d’interaction mains-libres, qui fournit une excellente expérience mains libres par le biais du pointage de regard et vocale basée sur les interactions.</span><span class="sxs-lookup"><span data-stu-id="163c6-186">A:  If so, take a look at the Hands-free interaction model, which provides a great hands-free experience through gaze- and voice-based interactions.</span></span>
 
3.  <span data-ttu-id="163c6-187">Q :  Mes utilisateurs doivent-ils disposer les temps d’apprendre les interactions pour mon application de réalité mixte, ou doivent-elles les interactions avec la courbe d’apprentissage la plus basse possible ?</span><span class="sxs-lookup"><span data-stu-id="163c6-187">Q:  Do my users have time to learn interactions for my mixed reality application, or do they need the interactions with the lowest learning curve possible?</span></span><br><br>
<span data-ttu-id="163c6-188">R :  Nous recommandons le modèle des mains et pour la courbe d’apprentissage la plus faible et des interactions plus intuitives, tant que les utilisateurs sont en mesure d’utiliser leurs mains pour l’interaction.</span><span class="sxs-lookup"><span data-stu-id="163c6-188">A:  We recommend the Hands and Tools model for the lowest learning curve and most intuitive interactions, as long as users are able to use their hands for interaction.</span></span>
 
4.  <span data-ttu-id="163c6-189">Q :  Mes utilisateurs utilisent des contrôleurs de mouvement pour pointant et manipulation ?</span><span class="sxs-lookup"><span data-stu-id="163c6-189">Q:  Do my users use motion controllers for pointing and manipulation?</span></span><br><br>
<span data-ttu-id="163c6-190">R :  Le modèle de mains et inclut tous les conseils pour une bonne expérience des contrôleurs de mouvement.</span><span class="sxs-lookup"><span data-stu-id="163c6-190">A:  The Hands and tools model includes all guidance for a great experience with motion controllers.</span></span>
 
5.  <span data-ttu-id="163c6-191">Q :  Mes utilisateurs utilisent-elles un contrôleur d’accessibilité ou un contrôleur Bluetooth courantes, comme un clicker ?</span><span class="sxs-lookup"><span data-stu-id="163c6-191">Q:  Do my users use an accessibility controller or a common Bluetooth controller, such as a clicker?</span></span><br><br>
<span data-ttu-id="163c6-192">R :  Nous recommandons le modèle regards de tête et de validation pour tous les contrôleurs non suivies.</span><span class="sxs-lookup"><span data-stu-id="163c6-192">A:  We recommend the Head-gaze and Commit model for all non-tracked controllers.</span></span>  <span data-ttu-id="163c6-193">Il est conçu pour autoriser un utilisateur à parcourir une expérience entière avec une simple garagiste « cible et validation ».</span><span class="sxs-lookup"><span data-stu-id="163c6-193">It's designed to allow a user to traverse an entire experience with a simple "target and commit" mechanic.</span></span> 
 
6.  <span data-ttu-id="163c6-194">Q : Mes utilisateurs uniquement la progression via une expérience cliquant « via » (par exemple dans un environnement semblable à diaporama 3d), par opposition à la navigation dans les dispositions denses de contrôles d’interface utilisateur ?</span><span class="sxs-lookup"><span data-stu-id="163c6-194">Q: Do my users only progress through an experience by "clicking through" (for example in a 3d slideshow-like environment), as opposed to navigating dense layouts of UI controls?</span></span><br><br>
<span data-ttu-id="163c6-195">R :  Si les utilisateurs n’ont pas besoin de contrôler un grand nombre de l’interface utilisateur, Head-regards et validation offre une option de demande où les utilisateurs n’ont pas à vous soucier de ciblage.</span><span class="sxs-lookup"><span data-stu-id="163c6-195">A:  If users do not need to control a lot of UI, Head-gaze and commit offers a learnable option where users do not have to worry about targeting.</span></span> 
 
7.  <span data-ttu-id="163c6-196">Q :  Mes utilisateurs utilisent-ils les deux HoloLens (1er gen) et HoloLens 2 / Immersive de Windows (casques VR)</span><span class="sxs-lookup"><span data-stu-id="163c6-196">Q:  Do my users use both HoloLens (1st gen) and HoloLens 2/ Windows Immersive (VR headsets)</span></span><br><br>
<span data-ttu-id="163c6-197">R :  Dans la mesure où les regards de tête et de validation est le modèle d’interaction pour HoloLens (1er gen), nous vous recommandons créateurs qui prennent en charge de HoloLens (1er gen) utiliser regards de tête et de validation pour les fonctionnalités ou les modes d’utilisateurs peut se produire sur un HoloLens (1er gen) casque.</span><span class="sxs-lookup"><span data-stu-id="163c6-197">A:  Since Head-gaze and commit is the interaction model for HoloLens (1st gen), we recommend that creators who support HoloLens (1st gen) use Head-gaze and commit for any features or modes that users may experience on a HoloLens (1st gen) headset.</span></span>  <span data-ttu-id="163c6-198">Consultez la section suivante ci-dessous sur *transition des modèles d’interaction* pour plus d’informations sur la création d’une expérience optimale pour plusieurs générations de HoloLens.</span><span class="sxs-lookup"><span data-stu-id="163c6-198">Please see the next section below on *Transitioning interaction models* for details on making a great experience for multiple HoloLens generations.</span></span>
 
8.  <span data-ttu-id="163c6-199">Q : Qu’en est-il pour les utilisateurs qui sont généralement mobiles (couvrant un large espace ou de déplacement entre des espaces), et les utilisateurs qui ont tendance à fonctionner dans un seul espace ?</span><span class="sxs-lookup"><span data-stu-id="163c6-199">Q: What about for users who are generally mobile (covering a large space or moving between spaces), versus users who tend to work in a single space?</span></span><br><br>
<span data-ttu-id="163c6-200">R :  Les modèles d’interaction de fonctionnera pour ces utilisateurs.</span><span class="sxs-lookup"><span data-stu-id="163c6-200">A:  Any of the interaction models will work for these users.</span></span>  

> [!NOTE]
> <span data-ttu-id="163c6-201">Obtenir des instructions spécifiques à la conception d’applications [bientôt](index.md#news-and-notes).</span><span class="sxs-lookup"><span data-stu-id="163c6-201">More guidance specific to app design [coming soon](index.md#news-and-notes).</span></span>


## <a name="transition-interaction-models"></a><span data-ttu-id="163c6-202">Modèles d’interaction de transition</span><span class="sxs-lookup"><span data-stu-id="163c6-202">Transition interaction models</span></span>
<span data-ttu-id="163c6-203">Il existe également des cas où vos cas d’usage peuvent nécessiter qu’utilisant plus d’un modèle d’interaction.</span><span class="sxs-lookup"><span data-stu-id="163c6-203">There are also cases where your use cases may require that utilizing more than one interaction model.</span></span>  <span data-ttu-id="163c6-204">Par exemple, votre flux d’application « création » utilise le modèle d’interaction des mains et, mais que vous souhaitez employer un mode mains libres pour les techniciens du terrain.</span><span class="sxs-lookup"><span data-stu-id="163c6-204">For example, your app's "creation flow" utilizes the Hands and tools interaction model, but you want to employ a Hands-free mode for field technicians.</span></span>  

<span data-ttu-id="163c6-205">Si votre expérience requiert plusieurs modèles d’interaction, nous avons constaté que nombreux utilisateurs finaux peuvent rencontrer des difficultés de transition d’un modèle à un autre, en particulier les utilisateurs finaux qui débutent avec MR.</span><span class="sxs-lookup"><span data-stu-id="163c6-205">If your experience does require multiple interaction models, we've found that many end users may encounter difficulty transitioning from one model to another -- especially end users who are new to MR.</span></span>

> [!Note]
> <span data-ttu-id="163c6-206">Pour aider les concepteurs de guide et les développeurs à travers les choix qui peut s’avérer difficile dans MR, nous travaillons sur plus de conseils pour l’utilisation de plusieurs modèles d’interaction.</span><span class="sxs-lookup"><span data-stu-id="163c6-206">To help guide designers and developers through choices that can be difficult in MR, we're working on more guidance for using multiple interaction models.</span></span>
 

## <a name="see-also"></a><span data-ttu-id="163c6-207">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="163c6-207">See also</span></span>
* [<span data-ttu-id="163c6-208">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="163c6-208">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="163c6-209">Suivre de la tête et stabiliser</span><span class="sxs-lookup"><span data-stu-id="163c6-209">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="163c6-210">Manipulation directe avec les mains</span><span class="sxs-lookup"><span data-stu-id="163c6-210">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="163c6-211">Pointer et valider avec les mains</span><span class="sxs-lookup"><span data-stu-id="163c6-211">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="163c6-212">Mouvements</span><span class="sxs-lookup"><span data-stu-id="163c6-212">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="163c6-213">Commander avec la voix</span><span class="sxs-lookup"><span data-stu-id="163c6-213">Voice commanding</span></span>](voice-design.md)
* [<span data-ttu-id="163c6-214">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="163c6-214">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="163c6-215">Conception du son spatial</span><span class="sxs-lookup"><span data-stu-id="163c6-215">Spatial sound design</span></span>](spatial-sound-design.md)
* [<span data-ttu-id="163c6-216">Conception du mappage spatial</span><span class="sxs-lookup"><span data-stu-id="163c6-216">Spatial mapping design</span></span>](spatial-mapping-design.md)
* [<span data-ttu-id="163c6-217">Confort</span><span class="sxs-lookup"><span data-stu-id="163c6-217">Comfort</span></span>](comfort.md)

