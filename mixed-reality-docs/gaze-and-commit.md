---
title: Regards de tête et de validation
description: Vue d’ensemble du modèle d’entrée du pointage de regard head et validation
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixte réalité, regards, regards ciblant, interaction, concevoir
ms.openlocfilehash: 95f2cef8c10ce3d0d2a218953613fef6f0a00362
ms.sourcegitcommit: 1c0fbee8fa887525af6ed92174edc42c05b25f90
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 05/16/2019
ms.locfileid: "65730822"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="3d7e0-104">Regards de tête et de validation</span><span class="sxs-lookup"><span data-stu-id="3d7e0-104">Head-gaze and commit</span></span>
<span data-ttu-id="3d7e0-105">Regards de tête et de validation est un modèle d’entrée qui implique de cibler un objet avec la direction de votre tête pointant vers l’avant (direction de tête) et en agissant ensuite dessus avec une base de données secondaire d’entrée tels que le mouvement de la main Air appuyez sur ou la voix de commande « Select ».</span><span class="sxs-lookup"><span data-stu-id="3d7e0-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="3d7e0-106">Il est considéré comme un modèle « beaucoup » d’entrée avec manipulation indirecte, ce qui signifie qu’il est particulièrement adapté pour l’interaction avec du contenu qui est au-delà des armes atteindre.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="3d7e0-107">Prise en charge des appareils</span><span class="sxs-lookup"><span data-stu-id="3d7e0-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="3d7e0-108"><strong>Modèle d’entrée</strong></span><span class="sxs-lookup"><span data-stu-id="3d7e0-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="3d7e0-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1er gen)</strong></a></span><span class="sxs-lookup"><span data-stu-id="3d7e0-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="3d7e0-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="3d7e0-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="3d7e0-111"><a href="immersive-headset-hardware-details.md"><strong>Casques IMMERSIFS</strong></a></span><span class="sxs-lookup"><span data-stu-id="3d7e0-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="3d7e0-112">Regards de tête et de validation</span><span class="sxs-lookup"><span data-stu-id="3d7e0-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="3d7e0-113">✔️ Recommandé</span><span class="sxs-lookup"><span data-stu-id="3d7e0-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="3d7e0-114">✔️ Recommandé (troisième choix - <a href="interaction-fundamentals.md">voir les autres options</a>)</span><span class="sxs-lookup"><span data-stu-id="3d7e0-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="3d7e0-115">Option de remplacement ➕</span><span class="sxs-lookup"><span data-stu-id="3d7e0-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="3d7e0-116">Regards de tête</span><span class="sxs-lookup"><span data-stu-id="3d7e0-116">Head-gaze</span></span>
<span data-ttu-id="3d7e0-117">Réalité mixte casques utilisent la position et l’orientation de tête de l’utilisateur pour déterminer leur vecteur de direction principal.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="3d7e0-118">Vous pouvez considérer cela comme une imprimante laser qui pointe directement à l’avance de directement entre les yeux de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="3d7e0-119">Il s’agit d’une assez grossière approximation de recherche où l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="3d7e0-120">Votre application peut se croisent cette ray avec des objets virtuels ou réalistes et dessiner un curseur à cet emplacement pour informer l’utilisateur qu’ils sont actuellement de ciblage.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="3d7e0-121">En plus des regards principal, certains casques de réalité mixte tels que la version 2 HoloLens incluent œil des systèmes qui produisent un vecteur OCULAIRE de suivi.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="3d7e0-122">Cela fournit une mesure précise de recherche où l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="3d7e0-123">Il est possible de générer des regards et valider des interactions à l’aide du pointage de regard yeux, mais il est fourni avec un ensemble très différent des contraintes de conception, qui sera abordée séparément dans le [yeux article](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="3d7e0-124">Validation</span><span class="sxs-lookup"><span data-stu-id="3d7e0-124">Commit</span></span>
<span data-ttu-id="3d7e0-125">Après le ciblage d’un objet ou un élément d’interface utilisateur, l’utilisateur peut interagir ou « click » à l’aide d’une entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="3d7e0-126">Il s’agit en tant que l’étape de validation du modèle.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="3d7e0-127">Les méthodes de validation suivantes sont prises en charge :</span><span class="sxs-lookup"><span data-stu-id="3d7e0-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="3d7e0-128">Geste d’appui en l’air</span><span class="sxs-lookup"><span data-stu-id="3d7e0-128">Air Tap gesture</span></span>
- <span data-ttu-id="3d7e0-129">Énoncer les commandes vocales « Select » ou l’une des commandes vocales ciblé</span><span class="sxs-lookup"><span data-stu-id="3d7e0-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="3d7e0-130">Appuyez sur le bouton unique un [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="3d7e0-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="3d7e0-131">Appuyez sur le bouton « A » sur un Xbox Gamepad</span><span class="sxs-lookup"><span data-stu-id="3d7e0-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="3d7e0-132">Appuyez sur le bouton « A » sur un contrôleur Adaptive Xbox</span><span class="sxs-lookup"><span data-stu-id="3d7e0-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="3d7e0-133">Mouvement d’appui regards de tête et air</span><span class="sxs-lookup"><span data-stu-id="3d7e0-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="3d7e0-134">Appui en l’air est un mouvement en appuyant sur avec la main droite.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="3d7e0-135">Pour effectuer un appui, déclencher votre doigt de l’index à la position de prête, puis pincement avec votre curseur et déclencher votre doigt index sauvegarder à libérer.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="3d7e0-136">Sur 1 HoloLens, appui en l’Air est l’entrée secondaire courante.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Doigt dans la position de prête, puis un mouvement cliquez ou appuyez sur](images/readyandpress.jpg)<br>

<span data-ttu-id="3d7e0-138">Appui en l’air est également disponible sur HoloLens 2, et il a été levée à partir de la version d’origine.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="3d7e0-139">Presque tous les types de pinches sont désormais pris en charge, tant que la main est vertical et exploitation toujours.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="3d7e0-140">Cela rend beaucoup plus facile pour les utilisateurs à apprendre et effectuez le geste.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="3d7e0-141">Ce nouvel appui remplace l’ancien via l’API de même, pour les applications existantes obtiennent le nouveau comportement automatiquement après recompilation pour HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="3d7e0-142">Commande de vocale regards de tête et « Select »</span><span class="sxs-lookup"><span data-stu-id="3d7e0-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="3d7e0-143">Exécution des commandes vocales sont une des méthodes d’interaction principal sur la réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="3d7e0-144">Il fournit un mécanisme de « Mains libre » très puissant pour contrôler le système.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="3d7e0-145">Il existe autre types de modèles d’interaction vocale :</span><span class="sxs-lookup"><span data-stu-id="3d7e0-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="3d7e0-146">La commande générique « Select » qui permet d’effectuer une activation de « clic » ou la validation comme une entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="3d7e0-147">Commandes d’objet comme « Fermer » ou « Agrandissez-le » qui permettent de réaliser et valider dans une action en tant qu’une entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="3d7e0-148">Commnads globaux tels que « Accédez à démarrer » qui ne nécessitent pas une cible.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="3d7e0-149">Interfaces utilisateur de conversation ou des entités comme Cortana qui disposent d’une capacité d’intelligence artificielle en langage naturel.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="3d7e0-150">Commnads personnalisé</span><span class="sxs-lookup"><span data-stu-id="3d7e0-150">Custom commnads</span></span>

<span data-ttu-id="3d7e0-151">Pour trouver plus d’informations et une liste de comprenhesive des commandes disponibles et l’utilisation, consultez notre [vocal conception](voice-design.md) des conseils.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice design](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="3d7e0-152">Regards de tête et HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="3d7e0-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="3d7e0-153">Le HoloLens Clicker est le premier périphérique spécialement conçu pour HoloLens et est inclus avec l’édition de développement HoloLens 1.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="3d7e0-154">Le HoloLens Clicker permet à un utilisateur de cliquer avec le mouvement de la main minimal et valider en tant qu’une entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="3d7e0-155">Le clicker HoloLens se connecte à la HoloLens 1 ou 2 à l’aide de Bluetooth faible énergie (BTLE).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

![](images/hololens-clicker-500px.jpg)<br>
<span data-ttu-id="3d7e0-156">HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="3d7e0-156">HoloLens Clicker</span></span>

<span data-ttu-id="3d7e0-157">Plus d’informations et obtenir des instructions pour coupler l’appareil, vous pouvez trouver [ici](hardware-accessories.md#pairing-bluetooth-accessories)</span><span class="sxs-lookup"><span data-stu-id="3d7e0-157">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="3d7e0-158">Regards de tête et de contrôleur sans fil Xbox</span><span class="sxs-lookup"><span data-stu-id="3d7e0-158">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="3d7e0-159">Le contrôleur sans fil Xbox permet pour exécuter une commande « clic » comme une base de données secondaire d’entrée à l’aide du bouton A.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-159">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="3d7e0-160">L’appareil est mappé à un ensemble par défaut des actions qui aident à naviguer et contrôler le système.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-160">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="3d7e0-161">Si vous souhaitez personnaliser le contrôleur, utilisez le Xbox Accesories application pour configurer votre contrôleur de sans fil Xbox.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-161">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

![](images/xboxcontroller.jpg)<br>
<span data-ttu-id="3d7e0-162">Contrôleur sans fil Xbox</span><span class="sxs-lookup"><span data-stu-id="3d7e0-162">Xbox Wireless Controller</span></span>

[<span data-ttu-id="3d7e0-163">Association d’une manette Xbox avec votre PC</span><span class="sxs-lookup"><span data-stu-id="3d7e0-163">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="3d7e0-164">Contrôleur Adaptive regards de tête et Xbox</span><span class="sxs-lookup"><span data-stu-id="3d7e0-164">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="3d7e0-165">Conçu principalement pour répondre aux besoins de joueurs à mobilité réduite, le contrôleur Adaptive Xbox est un hub unifié pour les appareils qui permet de rendre la réalité mixte plus accessible.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-165">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="3d7e0-166">Le contrôleur Adaptive Xbox permet d’exécuter une commande « clic » comme une base de données secondaire d’entrée à l’aide du bouton A.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-166">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="3d7e0-167">L’appareil est mappé à un ensemble par défaut des actions qui aident à naviguer et contrôler le système.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-167">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="3d7e0-168">Si vous souhaitez personnaliser le contrôleur, utilisez le Xbox Accesories application pour configurer votre contrôleur Adaptive Xbox.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-168">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

![](images/xbox-adaptive-controller-devices.jpg)<br>
<span data-ttu-id="3d7e0-169">Contrôleur Adaptive Xbox</span><span class="sxs-lookup"><span data-stu-id="3d7e0-169">Xbox Adaptive Controller</span></span>

<span data-ttu-id="3d7e0-170">Connecter des appareils externes tels que des commutateurs, des boutons, des montages et manettes de jeu pour créer une expérience personnalisée contrôleurs qui identifie de façon unique vous appartient.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-170">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="3d7e0-171">Les entrées de bouton, Stick analogique et déclencheur sont contrôlées avec des périphériques d’assistance connectés via les prises de 3,5 mm et ports USB.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-171">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

![](images/xbox-adaptive-controller-ports.jpg)<br>
<span data-ttu-id="3d7e0-172">Ports de contrôleur Adaptive Xbox</span><span class="sxs-lookup"><span data-stu-id="3d7e0-172">Xbox Adaptive Controller ports</span></span>

[<span data-ttu-id="3d7e0-173">Instructions pour coupler l’appareil</span><span class="sxs-lookup"><span data-stu-id="3d7e0-173">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="3d7e0-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Plus d’informations sur le site Xbox</a></span><span class="sxs-lookup"><span data-stu-id="3d7e0-174"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


# <a name="head-gaze-design-guidelines"></a><span data-ttu-id="3d7e0-175">Instructions de conception des regards de tête</span><span class="sxs-lookup"><span data-stu-id="3d7e0-175">Head-gaze design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="3d7e0-176">Obtenir des instructions spécifiques à l’utilisation de conception [bientôt](index.md).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-176">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="3d7e0-177">Ciblage de tête-regards</span><span class="sxs-lookup"><span data-stu-id="3d7e0-177">Head-gaze targeting</span></span>
<span data-ttu-id="3d7e0-178">Toutes les interactions reposent sur la capacité d’un utilisateur à cibler l’élément qu'ils souhaitent interagir, quelle que soit la modalité d’entrée.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-178">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="3d7e0-179">En réalité mixte Windows, cela s’effectue en général à l’aide regard de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-179">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="3d7e0-180">Pour permettre aux utilisateurs de travailler avec une expérience avec succès, présentation de calculée du système de l’intention de l’utilisateur et l’intention de réelle de l’utilisateur, doit être alignées aussi près que possible.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-180">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="3d7e0-181">Dans la mesure que le système interprète les actions prévues de l’utilisateur correctement, la satisfaction des augmentations et les performances améliore.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-181">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="3d7e0-182">Commentaires et dimensionnement de la cible</span><span class="sxs-lookup"><span data-stu-id="3d7e0-182">Target sizing and feedback</span></span>
<span data-ttu-id="3d7e0-183">Le vecteur du pointage de regard a été démontré à plusieurs reprises pour être utilisable pour le ciblage précis, mais souvent convient le mieux brutes ciblage (lors de l’acquisition un tantinet supérieure cibles).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-183">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="3d7e0-184">Les tailles cible minimale de 1 à 1.5 degrés doivent autoriser les actions utilisateur réussie dans la plupart des scénarios, bien que les cibles de degrés 3 permettent souvent pour améliorer la vitesse.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-184">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="3d7e0-185">Notez que la taille que les cibles de l’utilisateur est effectivement une zone 2D même pour les éléments 3D--quelle que soit la projection est accessible sur les doit correspondre à la zone pouvant être ciblée.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-185">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="3d7e0-186">Fournissant certains cue marquants qu’un élément est « actif » (que l’utilisateur cible il) est extrêmement utile : il peut s’agir traitements tels que des effets visibles « pointage », mises en surbrillance audio ou clics, ou désactivez l’alignement d’un curseur avec un élément.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-186">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="3d7e0-187">![Taille cible optimal à distance de compteur 2](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="3d7e0-187">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="3d7e0-188">*Taille cible optimal à distance de compteur 2*</span><span class="sxs-lookup"><span data-stu-id="3d7e0-188">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="3d7e0-189">![Un exemple de mise en surbrillance d’un objet ciblé du pointage de regard](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="3d7e0-189">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="3d7e0-190">*Un exemple de mise en surbrillance d’un objet ciblé du pointage de regard*</span><span class="sxs-lookup"><span data-stu-id="3d7e0-190">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="3d7e0-191">Placement de la cible</span><span class="sxs-lookup"><span data-stu-id="3d7e0-191">Target placement</span></span>
<span data-ttu-id="3d7e0-192">Utilisateurs échouent souvent rechercher des éléments d’interface utilisateur sont positionnés très élevé ou très faible dans leur champ de vision, se concentrant la majeure partie de leur attention sur des zones autour de leur vue principale (généralement à peu près yeux).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-192">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="3d7e0-193">Peut aider à placer la plupart des cibles dans certaines bande raisonnable autour des yeux.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-193">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="3d7e0-194">Étant donné la tendance pour les utilisateurs pour vous concentrer sur une zone visual relativement réduite à tout moment (cône l’attention de vision est à peu près 10 degrés), regroupement des éléments d’interface utilisateur au degré que qu’ils sont conceptuellement associés peut exploiter le chaînage l’attention des comportements à partir de élément à un autre en tant qu’utilisateur empruntant leurs regards une zone.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-194">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="3d7e0-195">Lorsque vous concevez l’interface utilisateur, gardez à l’esprit les grandes variations dans le champ de vision entre HoloLens et des casques IMMERSIFS potentielles.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-195">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="3d7e0-196">![Un exemple d’éléments de l’interface utilisateur groupés pour des regards plus facile de ciblage dans l’Explorateur de Galaxy](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="3d7e0-196">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="3d7e0-197">*Un exemple d’éléments de l’interface utilisateur groupés pour des regards plus facile de ciblage dans l’Explorateur de Galaxy*</span><span class="sxs-lookup"><span data-stu-id="3d7e0-197">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="3d7e0-198">Amélioration des comportements de ciblage</span><span class="sxs-lookup"><span data-stu-id="3d7e0-198">Improving targeting behaviors</span></span>
<span data-ttu-id="3d7e0-199">Si l’intention de l’utilisateur pour cibler un élément peut être déterminée (ou approximative étroitement), il peut être très utile accepter les tentatives de « near miss » à l’interaction comme s’ils ont été correctement ciblés.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-199">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="3d7e0-200">Il existe un certain nombre de méthodes réussites qui peuvent être incorporées dans les expériences de réalité mixte :</span><span class="sxs-lookup"><span data-stu-id="3d7e0-200">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="3d7e0-201">Stabilisation du pointage de regard HEAD (« wells gravité »)</span><span class="sxs-lookup"><span data-stu-id="3d7e0-201">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="3d7e0-202">Cela doit être allumé/all de la plupart du temps.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-202">This should be turned on most/all of the time.</span></span> <span data-ttu-id="3d7e0-203">Cette technique supprime le gigues du tête/cou naturel que les utilisateurs devront peut-être.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-203">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="3d7e0-204">Également le déplacement en raison de comportements de recherche/parler.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-204">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="3d7e0-205">Algorithmes de lien le plus proche</span><span class="sxs-lookup"><span data-stu-id="3d7e0-205">Closest link algorithms</span></span>
<span data-ttu-id="3d7e0-206">Ceux-ci fonctionnent le mieux dans les zones épars contenu interactif.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-206">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="3d7e0-207">S’il existe une forte probabilité que vous pouvez déterminer qu’un utilisateur a tenté d’interagir avec, vous pouvez compléter leurs capacités de ciblage par simplement en supposant que certain niveau d’objectif.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-207">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="3d7e0-208">Actions postdatage/postdating</span><span class="sxs-lookup"><span data-stu-id="3d7e0-208">Backdating/postdating actions</span></span>
<span data-ttu-id="3d7e0-209">Ce mécanisme est utile dans les tâches nécessitant de vitesse.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-209">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="3d7e0-210">Lors du déplace d’un utilisateur via une série de manœuvres/activation ciblant à la vitesse, il peut être utile pour supposent une intention et permettre les étapes manquantes agir sur les cibles de l’utilisateur avait le focus légèrement avant ou après un appui (50 ms avant/après était en vigueur dans légèrement au début de test).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-210">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="3d7e0-211">Lissage</span><span class="sxs-lookup"><span data-stu-id="3d7e0-211">Smoothing</span></span>
<span data-ttu-id="3d7e0-212">Ce mécanisme est utile pour les mouvements de chemins, en réduisant l’instabilité/OSCILLANT légère en raison des caractéristiques physiques mouvement de la tête.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-212">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="3d7e0-213">Lorsque le lissage sur les mouvements des chemins, smooth par taille/distance de mouvements plutôt qu’au fil du temps</span><span class="sxs-lookup"><span data-stu-id="3d7e0-213">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="3d7e0-214">Magnétisme</span><span class="sxs-lookup"><span data-stu-id="3d7e0-214">Magnetism</span></span>
<span data-ttu-id="3d7e0-215">Ce mécanisme peut être considéré comme une version plus générale d’algorithmes de « Lier le plus proche », un curseur vers une cible de dessin ou l’augmentation simplement hitboxes (qu’il soit visible ou non) que les utilisateurs s’approcher des objectifs probables, à l’aide de la disposition interactive à une certaine connaissance intention de l’utilisateur une meilleure approche.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-215">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="3d7e0-216">Cela peut être particulièrement efficace pour les petites cibles.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-216">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="3d7e0-217">Le focus adhérence</span><span class="sxs-lookup"><span data-stu-id="3d7e0-217">Focus stickiness</span></span>
<span data-ttu-id="3d7e0-218">Lorsque vous déterminez ce qui les plus proches des éléments interactifs pour donner le focus à, fournir un décalage à l’élément ayant le focus.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-218">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="3d7e0-219">Cela vous aidera à réduire le focus erratique commutation des comportements flottant à un point médian entre deux éléments avec bruit naturelle.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-219">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="3d7e0-220">Mouvements composite</span><span class="sxs-lookup"><span data-stu-id="3d7e0-220">Composite gestures</span></span>
<span data-ttu-id="3d7e0-221">Applications peuvent reconnaître plusieurs seulement les clics.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-221">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="3d7e0-222">En combinant tap, maintenez et mise en production avec le mouvement de la main, des gestes composites plus complexes peuvent être effectuées.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-222">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="3d7e0-223">Ces mouvements composites ou de haut niveau générer sur le plus bas niveau d’entrée des données spatiales (à partir d’appui en l’Air Bloom) que les développeurs ont accès à.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-223">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="3d7e0-224">Appui</span><span class="sxs-lookup"><span data-stu-id="3d7e0-224">Air tap</span></span>
<span data-ttu-id="3d7e0-225">Le geste d’appui Air (ainsi que les autres gestes ci-dessous) réagit uniquement à un drainage spécifique.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-225">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="3d7e0-226">Pour détecter les autres robinets, tels que Menu ou comprendre, votre application doit utiliser directement les interactions de bas niveau décrites dans la section de mouvements de deux composants clé ci-dessus.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-226">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="3d7e0-227">Cliquez et maintenez</span><span class="sxs-lookup"><span data-stu-id="3d7e0-227">Tap and hold</span></span>
<span data-ttu-id="3d7e0-228">Blocage consiste simplement à maintenir la position du doigt vers le bas de l’appui en l’air.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-228">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="3d7e0-229">La combinaison d’appui en l’air et hold autorise une grande variété de « cliquez et faites glisser » des interactions plus complexes lorsqu’elles sont combinées avec déplacement arm telles que la sélection d’un objet au lieu d’activer ou de « mousedown » des interactions secondaire par exemple affichage d’un menu contextuel.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-229">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="3d7e0-230">Attention doit être utilisée lors de la conception pour ce mouvement Toutefois, en tant qu’utilisateurs peut être sujette à assouplissement leurs postures disponible au cours de tout mouvement étendu.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-230">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="3d7e0-231">Manipulation</span><span class="sxs-lookup"><span data-stu-id="3d7e0-231">Manipulation</span></span>
<span data-ttu-id="3d7e0-232">Les mouvements de manipulation peuvent servir à déplacer, redimensionner ou faire pivoter un hologramme lorsque vous souhaitez que l’hologramme pour réagir 1:1 pour les mouvements de main de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-232">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="3d7e0-233">Une utilisation de ces mouvements 1:1 consiste à laisser l’utilisateur dessiner ou peindre dans le monde.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-233">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="3d7e0-234">Le ciblage initiale pour un mouvement de manipulation doit être effectué en regards ou pointant vers.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-234">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="3d7e0-235">Une fois que le démarrage de maintenir, toute manipulation de l’objet est ensuite gérée manuellement mouvements, libération de l’utilisateur à rechercher pendant qu’elles manipulent.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-235">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="3d7e0-236">Navigation</span><span class="sxs-lookup"><span data-stu-id="3d7e0-236">Navigation</span></span>
<span data-ttu-id="3d7e0-237">Les mouvements de navigation fonctionnent comme une manette de jeu virtuel et peuvent être utilisées pour naviguer de widgets d’interface utilisateur, tels que des menus radiales.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-237">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="3d7e0-238">Vous maintenez sur pour démarrer le mouvement, puis déplacez votre main dans un cube 3D normalisé, centré autour de la presse initiale.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-238">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="3d7e0-239">Vous pouvez déplacer votre main sur l’axe des X, Y ou Z à partir de la valeur -1 à 1, 0 étant le point de départ.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-239">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="3d7e0-240">Navigation peut servir à générer basé sur la vitesse de défilement continu ou gestes de zoom, similaires à une interface utilisateur 2D de défilement en cliquant sur le bouton central de la souris puis diminué en déplaçant la souris.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-240">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="3d7e0-241">Navigation avec rails désigne la capacité de reconnaissance de mouvements dans un certain axe jusqu'à ce que certain seuil est atteint sur cet axe.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-241">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="3d7e0-242">Cela est utile, uniquement lorsque le déplacement dans plus d’un axe est activé dans une application par le développeur, par exemple, si une application est configurée pour reconnaître des gestes de navigation entre axe des X, Y, mais également spécifiée X axe avec rails.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-242">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="3d7e0-243">Dans ce cas système reconnaît des mouvements de main sur axe des X tant qu’ils restent au sein d’un rails imaginaire (guide) sur l’axe, X si l’axe des Y produit également des mouvements de main.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-243">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="3d7e0-244">Dans les applications 2D, les utilisateurs peuvent utiliser des gestes de navigation verticale pour faire défiler, effectuer un zoom avant ou faites glisser à l’intérieur de l’application.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-244">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="3d7e0-245">Cela injecte finales doigt virtuel à l’application pour simuler des entrées tactiles multipoints du même type.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-245">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="3d7e0-246">Les utilisateurs peuvent sélectionner ces actions ont lieu en basculant entre les outils sur la barre située au-dessus de l’application, en sélectionnant le bouton ou en indiquant que '< défilement, faites glisser/Zoom > outil'.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-246">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="3d7e0-247">Plus d’informations sur les mouvements composites</span><span class="sxs-lookup"><span data-stu-id="3d7e0-247">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="3d7e0-248">Modules de reconnaissance de mouvement</span><span class="sxs-lookup"><span data-stu-id="3d7e0-248">Gesture recognizers</span></span>

<span data-ttu-id="3d7e0-249">L’un des avantages de l’utilisation de reconnaissance de mouvement sont que vous pouvez configurer un module de reconnaissance de mouvement uniquement pour les gestes que l’hologramme actuellement ciblée peut accepter.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-249">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="3d7e0-250">La plateforme effectue uniquement la levée d’ambiguïté nécessaire de distinguer ces mouvements pris en charge particuliers.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-250">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="3d7e0-251">De cette façon, un hologramme qui prend en charge uniquement appui peut accepter une durée prolongée entre press et de mise en production, tout en un hologramme que prend en charge à la fois tap et hold peut promouvoir le tap à une suspension après le seuil de temps d’attente.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-251">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="3d7e0-252">Reconnaissance de main</span><span class="sxs-lookup"><span data-stu-id="3d7e0-252">Hand recognition</span></span>
<span data-ttu-id="3d7e0-253">HoloLens reconnaît des mouvements de main en effectuant le suivi de la position d’un ou deux mains qui sont visibles à l’appareil.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-253">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="3d7e0-254">HoloLens voit mains lorsqu’ils sont dans l’état prêt (arrière de l’aiguille de face vous avec votre index) ou l’état enfoncé (arrière main face à vous avec l’index vers le bas).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-254">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="3d7e0-255">Lorsque mains se trouvent dans les autres pose, le HoloLens les ignorer.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-255">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="3d7e0-256">Pour chaque aiguille ce HoloLens détecte, vous pouvez accéder à sa position (sans orientation) et son état enfoncé.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-256">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="3d7e0-257">Lorsque le bord de l’image de mouvement arrive à la main, vous êtes également fourni avec un vecteur de direction, vous pouvez afficher à l’utilisateur afin qu’ils connaissent le déplacement de la main pour l’obtenir précédent où HoloLens peut la voir.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-257">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="3d7e0-258">Frame de mouvement</span><span class="sxs-lookup"><span data-stu-id="3d7e0-258">Gesture frame</span></span>
<span data-ttu-id="3d7e0-259">Pour les mouvements sur HoloLens, la main doit être dans un « mouvement cadre », dans une plage que les caméras de détection de mouvement peuvent voir correctement (très à peu près de nez de taille et entre les épaules).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-259">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="3d7e0-260">Les utilisateurs doivent être formés sur cette zone de la reconnaissance pour la réussite d’action et pour leur propres confort (nombre d’utilisateurs initialement supposera que le frame de mouvement doit être au sein de leur vue via HoloLens et retardez pas leurs bras uncomfortably pour interagir).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-260">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="3d7e0-261">Lorsque vous utilisez le HoloLens Clicker, vos mains n’avez pas besoin de se trouver dans le cadre de mouvement.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-261">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="3d7e0-262">Dans le cas des gestes continues existe en particulier, des risques d’utilisateurs en déplacement ne commencent à utiliser en dehors de l’image de mouvement en mouvement intermédiaire (pendant le déplacement d’un objet HOLOGRAPHIQUE, par exemple) et la perte de leur résultat prévu.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-262">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="3d7e0-263">Voici trois choses que vous devez prendre en compte :</span><span class="sxs-lookup"><span data-stu-id="3d7e0-263">There are three things that you should consider:</span></span>

- <span data-ttu-id="3d7e0-264">Éducation des utilisateurs sur le frame de mouvement existence et limites approximatifs (enseigné pendant l’installation de HoloLens).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-264">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="3d7e0-265">Avertissement aux utilisateurs lorsque leurs mouvements sont arrivent à/avec rupture les limites du cadre de mouvement dans une application, au même niveau qu’un mouvement perdu aboutira à des résultats indésirables.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-265">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="3d7e0-266">Des études ont montré les qualités principales d’un tel système de notification et l’interpréteur de commandes HoloLens fournit un bon exemple de ce type de notification (visuel sur le curseur central, qui indique le sens dans les limites traversée est en cours).</span><span class="sxs-lookup"><span data-stu-id="3d7e0-266">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="3d7e0-267">Conséquences de rompre les limites de frame de mouvement doivent être réduites.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-267">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="3d7e0-268">En règle générale, cela signifie que le résultat d’un mouvement doit être arrêté à la limite, mais pas inversé.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-268">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="3d7e0-269">Par exemple, si un utilisateur déplace un objet HOLOGRAPHIQUE dans une même pièce, le déplacement doit s’arrêter lorsque le frame de mouvement est dépassé, mais ne pas être retourné au point de départ.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-269">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="3d7e0-270">L’utilisateur peut rencontrer certains frustration puis, mais peut comprendre plus rapidement les limites et pas obligé de redémarrer leurs actions prévues sont complète chaque fois.</span><span class="sxs-lookup"><span data-stu-id="3d7e0-270">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="3d7e0-271">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="3d7e0-271">See also</span></span>
* [<span data-ttu-id="3d7e0-272">Manipulation directe</span><span class="sxs-lookup"><span data-stu-id="3d7e0-272">Direct manipulation</span></span>](direct-manipulation.md)
* [<span data-ttu-id="3d7e0-273">Pointer et valider</span><span class="sxs-lookup"><span data-stu-id="3d7e0-273">Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="3d7e0-274">Fonctionnalités de base des interactions</span><span class="sxs-lookup"><span data-stu-id="3d7e0-274">Interaction fundamentals</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="3d7e0-275">Pointer du regard et fixer</span><span class="sxs-lookup"><span data-stu-id="3d7e0-275">Gaze and dwell</span></span>](gaze-targeting.md)
* [<span data-ttu-id="3d7e0-276">Pointer du regard et parler</span><span class="sxs-lookup"><span data-stu-id="3d7e0-276">Gaze and voice</span></span>](voice-design.md)





