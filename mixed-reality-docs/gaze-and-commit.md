---
title: Suivre de la tête et valider
description: Vue d’ensemble du modèle d’entrée Suivre de la tête et valider
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, pointage du regard, ciblage avec le regard, interaction, conception
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692303"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="854e3-104">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="854e3-104">Head-gaze and commit</span></span>
<span data-ttu-id="854e3-105">Le modèle Suivre de la tête et valider est un modèle d’entrée qui implique de cibler un objet avec un mouvement de votre tête pointant vers l’avant, puis d’agir dessus avec une entrée secondaire telle qu’un clic aérien manuel ou la commande vocale « Select ».</span><span class="sxs-lookup"><span data-stu-id="854e3-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="854e3-106">Considéré comme un modèle d’entrée « de loin » avec manipulation indirecte, il est particulièrement adapté pour l’interaction avec du contenu hors de portée de main.</span><span class="sxs-lookup"><span data-stu-id="854e3-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="854e3-107">Prise en charge des appareils</span><span class="sxs-lookup"><span data-stu-id="854e3-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="854e3-108"><strong>Modèle d’entrée</strong></span><span class="sxs-lookup"><span data-stu-id="854e3-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="854e3-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1ère génération)</strong></a></span><span class="sxs-lookup"><span data-stu-id="854e3-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="854e3-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="854e3-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="854e3-111"><a href="immersive-headset-hardware-details.md"><strong>Casques immersifs</strong></a></span><span class="sxs-lookup"><span data-stu-id="854e3-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="854e3-112">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="854e3-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="854e3-113">✔️ Recommandé</span><span class="sxs-lookup"><span data-stu-id="854e3-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="854e3-114">✔️ Recommandé (troisième choix ; <a href="interaction-fundamentals.md">voir les autres options</a>)</span><span class="sxs-lookup"><span data-stu-id="854e3-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="854e3-115">➕ Autre option</span><span class="sxs-lookup"><span data-stu-id="854e3-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="854e3-116">Suivi de la tête</span><span class="sxs-lookup"><span data-stu-id="854e3-116">Head-gaze</span></span>
<span data-ttu-id="854e3-117">Les casques de réalité mixte utilisent la position et l’orientation de la tête de l’utilisateur pour déterminer le vecteur de direction de sa tête.</span><span class="sxs-lookup"><span data-stu-id="854e3-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="854e3-118">Vous pouvez l’assimiler à un rayon laser qui prend son origine entre les yeux de l’utilisateur et pointe droit devant.</span><span class="sxs-lookup"><span data-stu-id="854e3-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="854e3-119">C’est une approximation assez grossière de la zone vers laquelle se porte le regard de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="854e3-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="854e3-120">Votre application peut croiser ce rayon avec des objets virtuels ou réels et dessiner un curseur à cet emplacement pour indiquer à l’utilisateur ce qu’il est en train de cibler.</span><span class="sxs-lookup"><span data-stu-id="854e3-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="854e3-121">En plus du suivi de la tête, certains casques de réalité mixte tels que HoloLens 2 incluent des systèmes de suivi visuel qui produisent un vecteur de suivi du regard.</span><span class="sxs-lookup"><span data-stu-id="854e3-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="854e3-122">Ces dispositifs fournissent une mesure précise de la zone vers laquelle se porte le regard de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="854e3-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="854e3-123">Il est possible de générer des interactions de type pointage du regard et validation avec le suivi du regard, mais cela suppose un ensemble très différent de contraintes conceptuelles qui sera abordé séparément dans l’[article consacré au suivi visuel](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="854e3-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="854e3-124">Validation</span><span class="sxs-lookup"><span data-stu-id="854e3-124">Commit</span></span>
<span data-ttu-id="854e3-125">Après avoir ciblé un objet ou un élément d’interface utilisateur, l’utilisateur peut interagir avec lui ou « cliquer » dessus à l’aide d’une entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="854e3-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="854e3-126">Il s’agit de l’étape de validation du modèle.</span><span class="sxs-lookup"><span data-stu-id="854e3-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="854e3-127">Les méthodes de validation suivantes sont prises en charge :</span><span class="sxs-lookup"><span data-stu-id="854e3-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="854e3-128">Clic aérien</span><span class="sxs-lookup"><span data-stu-id="854e3-128">Air Tap gesture</span></span>
- <span data-ttu-id="854e3-129">Énoncer la commande vocale « Select » ou l’une des commandes vocales ciblées</span><span class="sxs-lookup"><span data-stu-id="854e3-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="854e3-130">Appuyer sur le bouton unique d’un [dispositif de clic HoloLens](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="854e3-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="854e3-131">Appuyer sur le bouton « A » d’une manette Xbox</span><span class="sxs-lookup"><span data-stu-id="854e3-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="854e3-132">Appuyer sur le bouton « A » d’une manette Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="854e3-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="854e3-133">Suivi de la tête et clic aérien</span><span class="sxs-lookup"><span data-stu-id="854e3-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="854e3-134">Le clic aérien est une action d’appui avec la main levée.</span><span class="sxs-lookup"><span data-stu-id="854e3-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="854e3-135">Pour effectuer un clic aérien, relevez l’index jusqu’à la position « prêt », effectuez un pincement avec votre pouce, puis relevez l’index pour libérer l’objet.</span><span class="sxs-lookup"><span data-stu-id="854e3-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="854e3-136">Sur HoloLens 1, le clic aérien est l’entrée secondaire la plus courante.</span><span class="sxs-lookup"><span data-stu-id="854e3-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Doigt en position « prêt », puis mouvement de clic ou d’appui](images/readyandpress.jpg)<br>

<span data-ttu-id="854e3-138">Le clic aérien est également disponible sur HoloLens 2, et il a été assoupli par rapport à la version d’origine.</span><span class="sxs-lookup"><span data-stu-id="854e3-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="854e3-139">Presque tous les types de pincements sont désormais pris en charge, sous réserve que la main soit verticale et immobile.</span><span class="sxs-lookup"><span data-stu-id="854e3-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="854e3-140">Ainsi, les utilisateurs peuvent apprendre et effectuer le mouvement beaucoup plus facilement.</span><span class="sxs-lookup"><span data-stu-id="854e3-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="854e3-141">Comme ce nouveau clic aérien remplace l’ancien par le biais de la même API, les applications existantes bénéficient automatiquement du nouveau comportement une fois recompilées pour HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="854e3-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="854e3-142">Suivi de la tête et commande vocale « Select »</span><span class="sxs-lookup"><span data-stu-id="854e3-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="854e3-143">La méthode Commander avec la voix est l’une des méthodes d’interaction principales sur Mixed Reality.</span><span class="sxs-lookup"><span data-stu-id="854e3-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="854e3-144">Elle fournit un mécanisme « mains-libres » très puissant pour contrôler le système.</span><span class="sxs-lookup"><span data-stu-id="854e3-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="854e3-145">Il existe différents types de modèles d’interaction vocale :</span><span class="sxs-lookup"><span data-stu-id="854e3-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="854e3-146">La commande générique « Select » qui permet d’effectuer une action ou une validation avec un clic en guise d’entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="854e3-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="854e3-147">Les commandes d’objet comme « Close » ou « Make it bigger » qui permettent d’effectuer et de valider une action en tant qu’entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="854e3-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="854e3-148">Les commandes globales telles que « Go to start » qui ne nécessitent pas de cible.</span><span class="sxs-lookup"><span data-stu-id="854e3-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="854e3-149">Les entités ou interfaces utilisateur de conversation comme Cortana qui disposent d’une fonctionnalité de langage naturel faisant appel à l’intelligence artificielle.</span><span class="sxs-lookup"><span data-stu-id="854e3-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="854e3-150">Commandes personnalisées</span><span class="sxs-lookup"><span data-stu-id="854e3-150">Custom commnads</span></span>

<span data-ttu-id="854e3-151">Pour obtenir des informations supplémentaires ainsi qu’une liste complète des commandes disponibles et une description de leur utilisation, consultez notre guide sur la [méthode Commander avec la voix](voice-design.md).</span><span class="sxs-lookup"><span data-stu-id="854e3-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="854e3-152">Suivi de la tête et dispositif de clic HoloLens</span><span class="sxs-lookup"><span data-stu-id="854e3-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="854e3-153">Le dispositif de clic HoloLens est le premier périphérique spécialement conçu pour HoloLens et est inclus avec l’édition de développement HoloLens 1.</span><span class="sxs-lookup"><span data-stu-id="854e3-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="854e3-154">Le dispositif de clic HoloLens permet à un utilisateur de cliquer avec un mouvement de la main minimal et d’effectuer une validation en tant qu’entrée secondaire.</span><span class="sxs-lookup"><span data-stu-id="854e3-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="854e3-155">Le dispositif de clic HoloLens se connecte à HoloLens 1 ou 2 à l’aide de la technologie Bluetooth basse énergie.</span><span class="sxs-lookup"><span data-stu-id="854e3-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="854e3-156">![Dispositif de clic HoloLens](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="854e3-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="854e3-157">*Dispositif de clic HoloLens*</span><span class="sxs-lookup"><span data-stu-id="854e3-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="854e3-158">Vous trouverez [ici](hardware-accessories.md#pairing-bluetooth-accessories) plus d’informations et des instructions sur le couplage de l’appareil.</span><span class="sxs-lookup"><span data-stu-id="854e3-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="854e3-159">Suivi de la tête et manette Xbox Wireless Controller</span><span class="sxs-lookup"><span data-stu-id="854e3-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="854e3-160">La manette Xbox Wireless Controller permet d’effectuer une action avec un clic en tant qu’entrée secondaire à l’aide du bouton A.</span><span class="sxs-lookup"><span data-stu-id="854e3-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="854e3-161">L’appareil est mappé à un ensemble par défaut d’actions qui aident à parcourir et à contrôler le système.</span><span class="sxs-lookup"><span data-stu-id="854e3-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="854e3-162">Si vous souhaitez personnaliser votre manette Xbox Wireless Controller, vous pouvez la configurer à l’aide de l’application Accessoires Xbox.</span><span class="sxs-lookup"><span data-stu-id="854e3-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="854e3-163">![Manette Xbox Wireless Controller](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="854e3-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="854e3-164">*Manette Xbox Wireless Controller*</span><span class="sxs-lookup"><span data-stu-id="854e3-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="854e3-165">Couplage d’une manette Xbox avec votre PC</span><span class="sxs-lookup"><span data-stu-id="854e3-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="854e3-166">Suivi de la tête et manette Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="854e3-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="854e3-167">Conçu principalement pour répondre aux besoins des joueurs à mobilité réduite, la manette Xbox Adaptive Controller est un hub unifié pour les appareils qui aide à rendre Mixed Reality plus accessible.</span><span class="sxs-lookup"><span data-stu-id="854e3-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="854e3-168">La manette Xbox Adaptive Controller permet d’effectuer une action avec un clic en tant qu’entrée secondaire à l’aide du bouton A.</span><span class="sxs-lookup"><span data-stu-id="854e3-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="854e3-169">L’appareil est mappé à un ensemble par défaut d’actions qui aident à parcourir et à contrôler le système.</span><span class="sxs-lookup"><span data-stu-id="854e3-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="854e3-170">Si vous souhaitez personnaliser le contrôleur, utilisez l’application Accessoires Xbox pour configurer votre contrôleur adaptatif Xbox.</span><span class="sxs-lookup"><span data-stu-id="854e3-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="854e3-171">![Manette Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="854e3-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="854e3-172">*Manette Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="854e3-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="854e3-173">Connectez des appareils externes tels que des commutateurs, des boutons, des montages et des manettes de jeu pour créer une expérience de contrôleurs personnalisée unique.</span><span class="sxs-lookup"><span data-stu-id="854e3-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="854e3-174">Les entrées de bouton, de joystick et de déclencheur sont contrôlées avec des appareils d’assistance connectés par le biais de prises 3,5 mm et de ports USB.</span><span class="sxs-lookup"><span data-stu-id="854e3-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="854e3-175">![Ports de la manette Xbox Adaptive Controller](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="854e3-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="854e3-176">*Ports de la manette Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="854e3-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="854e3-177">Instructions pour coupler l’appareil</span><span class="sxs-lookup"><span data-stu-id="854e3-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="854e3-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Plus d’informations sur le site Xbox</a></span><span class="sxs-lookup"><span data-stu-id="854e3-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="854e3-179">Recommandations en matière de conception</span><span class="sxs-lookup"><span data-stu-id="854e3-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="854e3-180">Des conseils spécifiques à la conception de fonctionnalités de pointage du regard seront [bientôt](index.md) disponibles.</span><span class="sxs-lookup"><span data-stu-id="854e3-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="854e3-181">Ciblage avec la tête</span><span class="sxs-lookup"><span data-stu-id="854e3-181">Head-gaze targeting</span></span>
<span data-ttu-id="854e3-182">Toutes les interactions reposent sur la capacité d’un utilisateur à cibler l’élément avec lequel il souhaite interagir, quelle que soit la modalité d’entrée.</span><span class="sxs-lookup"><span data-stu-id="854e3-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="854e3-183">Dans Windows Mixed Reality, cette opération fait généralement appel au pointage du regard de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="854e3-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="854e3-184">Pour procurer une expérience efficace à un utilisateur, il est nécessaire que la compréhension de son intention telle que la calcule le système et son intention réelle soient alignées aussi étroitement que possible.</span><span class="sxs-lookup"><span data-stu-id="854e3-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="854e3-185">Plus le système interprète les actions prévues de l’utilisateur correctement, plus la satisfaction augmente et les performances s’améliorent.</span><span class="sxs-lookup"><span data-stu-id="854e3-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="854e3-186">Dimensionnement des cibles et retour</span><span class="sxs-lookup"><span data-stu-id="854e3-186">Target sizing and feedback</span></span>
<span data-ttu-id="854e3-187">Il a été démontré à plusieurs reprises que le vecteur du pointage du regard peut être utilisé pour le ciblage précis, mais qu’il convient souvent le mieux pour le ciblage brut (acquisition de cibles un peu plus grandes).</span><span class="sxs-lookup"><span data-stu-id="854e3-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="854e3-188">Les tailles de cible minimales de 1 à 1,5 degré doivent permettre le bon déroulement des actions utilisateur dans la plupart des scénarios, bien que des cibles de 3 degrés puissent souvent générer un gain de vitesse.</span><span class="sxs-lookup"><span data-stu-id="854e3-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="854e3-189">Notez que la taille que cible l’utilisateur est une zone 2D même pour les éléments 3D ; la projection qui lui fait face, quelle qu’elle soit, doit être la zone pouvant être ciblée.</span><span class="sxs-lookup"><span data-stu-id="854e3-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="854e3-190">Il est extrêmement utile de fournir à l’utilisateur des indicateurs marquants montrant qu’un élément est « actif » (qu’il est en train de le cibler) ; il peut s’agir de traitements tels que des effets de « pointage » visibles, des mises en évidence audio, des clics ou de l’alignement clair d’un curseur avec un élément.</span><span class="sxs-lookup"><span data-stu-id="854e3-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="854e3-191">![Taille de cible optimale à une distance de 2 mètres](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="854e3-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="854e3-192">*Taille de cible optimale à une distance de 2 mètres*</span><span class="sxs-lookup"><span data-stu-id="854e3-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="854e3-193">![Exemple de mise en surbrillance d’un objet ciblé avec le regard](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="854e3-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="854e3-194">*Exemple de mise en surbrillance d’un objet ciblé avec le regard*</span><span class="sxs-lookup"><span data-stu-id="854e3-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="854e3-195">Placement de la cible</span><span class="sxs-lookup"><span data-stu-id="854e3-195">Target placement</span></span>
<span data-ttu-id="854e3-196">Les utilisateurs ne parviennent pas souvent à trouver les éléments d’interface utilisateur qui sont positionnés très haut ou très bas dans leur champ de vision, concentrant la majeure partie de leur attention sur des zones autour de leur vue principale (généralement au niveau des yeux).</span><span class="sxs-lookup"><span data-stu-id="854e3-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="854e3-197">Le fait de placer la plupart des cibles dans une bande raisonnable autour des yeux peut s’avérer utile.</span><span class="sxs-lookup"><span data-stu-id="854e3-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="854e3-198">Etant donné que les utilisateurs ont tendance à se concentrer sur un champ visuel relativement étroit (le cône de vision lié à l’attention est à peu près de 10 degrés), ils sont davantage susceptibles de passer d’un élément à l’autre à mesure qu’ils déplacent leur regard si les éléments d’interface utilisateur d’un même concept sont regroupés dans ce champ de vision.</span><span class="sxs-lookup"><span data-stu-id="854e3-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="854e3-199">Quand vous concevez l’interface utilisateur, gardez à l’esprit les grandes variations potentielles du champ de vision entre les casques immersifs et HoloLens.</span><span class="sxs-lookup"><span data-stu-id="854e3-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="854e3-200">![Exemple d’éléments d’interface utilisateur groupés pour faciliter le ciblage avec le regard dans Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="854e3-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="854e3-201">*Exemple d’éléments d’interface utilisateur groupés pour faciliter le ciblage avec le regard dans Galaxy Explorer*</span><span class="sxs-lookup"><span data-stu-id="854e3-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="854e3-202">Amélioration des comportements de ciblage</span><span class="sxs-lookup"><span data-stu-id="854e3-202">Improving targeting behaviors</span></span>
<span data-ttu-id="854e3-203">Si l’intention de l’utilisateur de cibler un élément peut être déterminée (ou approchée étroitement), il peut être très utile d’accepter comme correctes les tentatives d’interaction échouant de peu.</span><span class="sxs-lookup"><span data-stu-id="854e3-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="854e3-204">Il existe un certain nombre de méthodes utiles pouvant être incorporées dans les expériences de réalité mixte :</span><span class="sxs-lookup"><span data-stu-id="854e3-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="854e3-205">Stabilisation avec suivi de la tête (« stabilisation de la gravité »)</span><span class="sxs-lookup"><span data-stu-id="854e3-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="854e3-206">Cette technique doit être activée tout le temps ou la plupart du temps.</span><span class="sxs-lookup"><span data-stu-id="854e3-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="854e3-207">Elle supprime les petits mouvements naturels de la tête ou du cou que l’utilisateur peut faire.</span><span class="sxs-lookup"><span data-stu-id="854e3-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="854e3-208">Il en va de même des comportements liés à l’observation et à l’élocution.</span><span class="sxs-lookup"><span data-stu-id="854e3-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="854e3-209">Algorithmes du lien le plus proche</span><span class="sxs-lookup"><span data-stu-id="854e3-209">Closest link algorithms</span></span>
<span data-ttu-id="854e3-210">Ces derniers fonctionnent le mieux dans les zones dont le contenu interactif est clairsemé.</span><span class="sxs-lookup"><span data-stu-id="854e3-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="854e3-211">S’il existe une forte probabilité que vous puissiez déterminer ce avec quoi un utilisateur a tenté d’interagir, vous pouvez compléter ses capacités de ciblage simplement en supposant un certain niveau d’intention.</span><span class="sxs-lookup"><span data-stu-id="854e3-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="854e3-212">Actions d’antidatage et de postdatage</span><span class="sxs-lookup"><span data-stu-id="854e3-212">Backdating/postdating actions</span></span>
<span data-ttu-id="854e3-213">Ce mécanisme est utile dans les tâches nécessitant de la vitesse.</span><span class="sxs-lookup"><span data-stu-id="854e3-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="854e3-214">Quand un utilisateur effectue rapidement une série de manœuvres d’activation ou de ciblage, il peut être utile de supposer ses intentions et de l’autoriser à manquer des étapes pour lui permettre d’agir sur les cibles qu’il avait dans son champ de vision légèrement avant ou après l’appui (un écart de 50 ms avant/après s’est avéré efficace au cours des premiers tests).</span><span class="sxs-lookup"><span data-stu-id="854e3-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="854e3-215">Adoucissage</span><span class="sxs-lookup"><span data-stu-id="854e3-215">Smoothing</span></span>
<span data-ttu-id="854e3-216">Ce mécanisme est utile pour les mouvements de déplacement, réduisant les petits mouvements et les tremblements naturels de la tête.</span><span class="sxs-lookup"><span data-stu-id="854e3-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="854e3-217">Quand vous adoucissez les mouvements de déplacement, agissez sur la taille/distance des mouvements plutôt que sur leur durée.</span><span class="sxs-lookup"><span data-stu-id="854e3-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="854e3-218">Magnétisme</span><span class="sxs-lookup"><span data-stu-id="854e3-218">Magnetism</span></span>
<span data-ttu-id="854e3-219">Ce mécanisme peut être considéré comme une version plus générale des algorithmes du « lien le plus proche » ; il consiste à déplacer un curseur vers une cible ou simplement à agrandir les zones de ciblage (visibles ou non) à mesure que l’utilisateur s’approche de cibles probables, en s’appuyant sur la disposition interactive pour mieux interpréter l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="854e3-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="854e3-220">Il peut être particulièrement efficace pour les petites cibles.</span><span class="sxs-lookup"><span data-stu-id="854e3-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="854e3-221">Adhérence du focus</span><span class="sxs-lookup"><span data-stu-id="854e3-221">Focus stickiness</span></span>
<span data-ttu-id="854e3-222">Quand vous déterminez à quels éléments interactifs proches donner le focus, déportez-vous de l’élément qui a actuellement le focus.</span><span class="sxs-lookup"><span data-stu-id="854e3-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="854e3-223">Cette approche aide à réduire les comportements erratiques liés aux changements de focus quand l’utilisateur se trouve entre deux éléments avec un bruit normal.</span><span class="sxs-lookup"><span data-stu-id="854e3-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="854e3-224">Mouvements composites</span><span class="sxs-lookup"><span data-stu-id="854e3-224">Composite gestures</span></span>
<span data-ttu-id="854e3-225">Les applications peuvent reconnaître d’autres choses que de simples appuis.</span><span class="sxs-lookup"><span data-stu-id="854e3-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="854e3-226">La combinaison des actions d’appui, d’appui prolongé et de libération avec le mouvement de la main permet d’effectuer des mouvements composites plus complexes.</span><span class="sxs-lookup"><span data-stu-id="854e3-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="854e3-227">Ces mouvements composites ou de haut niveau s’appuient sur les données d’entrée spatiales de bas niveau (allant du clic aérien à l’écartement des doigts paume vers le haut) auxquelles les développeurs ont accès.</span><span class="sxs-lookup"><span data-stu-id="854e3-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="854e3-228">Clic aérien</span><span class="sxs-lookup"><span data-stu-id="854e3-228">Air tap</span></span>
<span data-ttu-id="854e3-229">Le clic aérien (ainsi que les autres mouvements ci-dessous) réagit uniquement à un appui spécifique.</span><span class="sxs-lookup"><span data-stu-id="854e3-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="854e3-230">Pour détecter les autres appuis, tels que l’ouverture d’un menu ou la saisie d’un objet, votre application doit utiliser directement les interactions de bas niveau décrites plus haut dans la section consacrée aux mouvements à deux composants clés.</span><span class="sxs-lookup"><span data-stu-id="854e3-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="854e3-231">Appui de longue durée</span><span class="sxs-lookup"><span data-stu-id="854e3-231">Tap and hold</span></span>
<span data-ttu-id="854e3-232">L’appui prolongé consiste simplement à maintenir la position du doigt vers le bas pendant le clic aérien.</span><span class="sxs-lookup"><span data-stu-id="854e3-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="854e3-233">La combinaison du clic aérien et de l’appui prolongé autorise une grande variété d’interactions de type « clic et glissement » plus complexes quand elles sont combinées avec un déplacement du bras, telles que la sélection d’un objet au lieu de son activation, ou d’interactions secondaires de type « clic de bouton de la souris », telles que l’affichage d’un menu contextuel.</span><span class="sxs-lookup"><span data-stu-id="854e3-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="854e3-234">Toutefois, vous devez faire preuve de vigilance lors de la conception de ce mouvement, car l’utilisateur peut être sujet à relâcher ses postures de la main pendant un mouvement étendu.</span><span class="sxs-lookup"><span data-stu-id="854e3-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="854e3-235">Manipulation</span><span class="sxs-lookup"><span data-stu-id="854e3-235">Manipulation</span></span>
<span data-ttu-id="854e3-236">Les mouvements de manipulation peuvent servir à déplacer, redimensionner ou faire pivoter un hologramme quand vous voulez qu’il obéisse exactement aux mouvements de la main de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="854e3-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="854e3-237">La possibilité pour l’utilisateur de dessiner ou de peindre dans le monde illustre l’utilisation de ce type de mouvement.</span><span class="sxs-lookup"><span data-stu-id="854e3-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="854e3-238">Le ciblage initial pour un mouvement de manipulation doit être effectué au moyen d’un pointage du regard ou d’un pointage.</span><span class="sxs-lookup"><span data-stu-id="854e3-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="854e3-239">Dès que l’appui de longue durée commence, toute manipulation de l’objet est gérée par les mouvements de la main, l’utilisateur pouvant alors déplacer son regard pendant qu’il effectue ses manipulations.</span><span class="sxs-lookup"><span data-stu-id="854e3-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="854e3-240">Navigation</span><span class="sxs-lookup"><span data-stu-id="854e3-240">Navigation</span></span>
<span data-ttu-id="854e3-241">Les mouvements de navigation fonctionnent comme une manette de jeu virtuelle et peuvent être utilisés pour parcourir des widgets d’interface utilisateur, tels que des menus circulaires.</span><span class="sxs-lookup"><span data-stu-id="854e3-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="854e3-242">Vous appuyez longuement pour démarrer le mouvement, puis déplacez votre main dans un cube 3D normalisé, centré sur l’appui initial.</span><span class="sxs-lookup"><span data-stu-id="854e3-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="854e3-243">Vous pouvez déplacer votre main sur l’axe des X, Y ou Z à partir d’une valeur comprise entre -1 et 1, 0 étant le point de départ.</span><span class="sxs-lookup"><span data-stu-id="854e3-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="854e3-244">La navigation peut servir à générer des mouvements de zoom ou de défilement continus basés sur la vitesse, à l’image du défilement d’une interface utilisateur 2D que vous pouvez obtenir en cliquant sur le bouton central de la souris, puis en déplaçant le pointeur de la souris vers le haut ou le bas.</span><span class="sxs-lookup"><span data-stu-id="854e3-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="854e3-245">La navigation avec rails désigne la possibilité de reconnaître les mouvements dans un certain axe jusqu’à ce qu’un seuil donné soit atteint sur cet axe.</span><span class="sxs-lookup"><span data-stu-id="854e3-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="854e3-246">Cela n’est utile que si le développeur d’une application active le déplacement dans plus d’un axe ; c’est, par exemple, le cas si l’application est configurée pour reconnaître des mouvements de navigation sur l’axe des X et Y, mais qu’elle spécifie également l’axe X avec des rails.</span><span class="sxs-lookup"><span data-stu-id="854e3-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="854e3-247">Dans ce cas, le système reconnaît les mouvements de la main sur l’axe des X tant qu’ils restent à l’intérieur de rails imaginaires (guide) sur l’axe des X, si un mouvement de la main se produit également sur l’axe des Y.</span><span class="sxs-lookup"><span data-stu-id="854e3-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="854e3-248">Dans les applications 2D, l’utilisateur peut se servir de mouvements de navigation verticaux pour faire défiler l’écran, effectuer un zoom ou faire glisser un élément à l’intérieur de l’application.</span><span class="sxs-lookup"><span data-stu-id="854e3-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="854e3-249">Des interactions tactiles virtuelles sont ainsi injectées dans l’application pour simuler des mouvements tactiles du même type.</span><span class="sxs-lookup"><span data-stu-id="854e3-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="854e3-250">L’utilisateur peut sélectionner l’action à effectuer en basculant d’un outil à l’autre dans la barre située au-dessus de l’application, en sélectionnant le bouton adéquat ou en disant «<Scroll/Drag/Zoom> Tool ».</span><span class="sxs-lookup"><span data-stu-id="854e3-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="854e3-251">Plus d’informations sur les mouvements composites</span><span class="sxs-lookup"><span data-stu-id="854e3-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="854e3-252">Modules de reconnaissance des mouvements</span><span class="sxs-lookup"><span data-stu-id="854e3-252">Gesture recognizers</span></span>

<span data-ttu-id="854e3-253">L’un des avantages de l’utilisation de la reconnaissance des mouvements est que vous pouvez configurer un module de reconnaissance des mouvements uniquement pour les mouvements que l’hologramme actuellement ciblé peut accepter.</span><span class="sxs-lookup"><span data-stu-id="854e3-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="854e3-254">La plateforme n’effectue que la levée d’ambiguïté nécessaire pour distinguer les mouvements pris en charge concernés.</span><span class="sxs-lookup"><span data-stu-id="854e3-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="854e3-255">De cette façon, un hologramme qui prend en charge uniquement le clic aérien peut accepter n’importe quelle durée entre l’appui et la libération, tandis qu’un hologramme qui prend en charge l’appui de longue durée peut promouvoir l’appui en appui prolongé une fois écoulée la durée d’appui définie.</span><span class="sxs-lookup"><span data-stu-id="854e3-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="854e3-256">Reconnaissance des mouvements de la main</span><span class="sxs-lookup"><span data-stu-id="854e3-256">Hand recognition</span></span>
<span data-ttu-id="854e3-257">HoloLens reconnaît les mouvements de la main en effectuant le suivi de la position de la main, ou des mains, que l’appareil peut voir.</span><span class="sxs-lookup"><span data-stu-id="854e3-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="854e3-258">HoloLens voit les mains quand elles sont dans l’état « prêt » (dos de la main face à vous, index dressé) ou « enfoncé » (dos de la main face à vous, index abaissé).</span><span class="sxs-lookup"><span data-stu-id="854e3-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="854e3-259">Quand les mains sont dans d’autres poses, HoloLens les ignore.</span><span class="sxs-lookup"><span data-stu-id="854e3-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="854e3-260">Pour chaque main que HoloLens détecte, vous pouvez accéder à sa position (sans orientation) et à son état « enfoncé ».</span><span class="sxs-lookup"><span data-stu-id="854e3-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="854e3-261">Quand la main s’approche du bord du cadre de mouvement, vous disposez également d’un vecteur de direction, que vous pouvez présenter à l’utilisateur afin qu’il sache comment déplacer sa main de manière à ce que HoloLens puisse la voir.</span><span class="sxs-lookup"><span data-stu-id="854e3-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="854e3-262">Cadre de mouvement</span><span class="sxs-lookup"><span data-stu-id="854e3-262">Gesture frame</span></span>
<span data-ttu-id="854e3-263">Pour les mouvements sur HoloLens, la main doit être dans un « cadre de mouvement », dans une plage de visibilité appropriée pour les caméras de détection de mouvement (à peu près du nez à la taille et entre les épaules).</span><span class="sxs-lookup"><span data-stu-id="854e3-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="854e3-264">Les utilisateurs doivent être formés sur cette zone de reconnaissance, à la fois pour la réussite de leurs actions et pour leur propre confort (nombre d’utilisateurs, qui supposent initialement que le cadre de mouvement doit se trouver dans la vue que leur procure HoloLens, maintiennent leurs bras levés de manière inconfortable pour effectuer les opérations d’interaction).</span><span class="sxs-lookup"><span data-stu-id="854e3-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="854e3-265">Quand vous utilisez le dispositif de clic HoloLens, vos mains n’ont pas besoin de se trouver dans le cadre de mouvement.</span><span class="sxs-lookup"><span data-stu-id="854e3-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="854e3-266">Dans le cas des mouvements continus notamment, l’utilisateur risque de déplacer ses mains hors du cadre de mouvement au milieu du geste (pendant qu’il déplace un objet holographique, par exemple) et de perdre le résultat prévu.</span><span class="sxs-lookup"><span data-stu-id="854e3-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="854e3-267">Voici trois choses que vous devez envisager :</span><span class="sxs-lookup"><span data-stu-id="854e3-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="854e3-268">Former les utilisateurs à l’existence du cadre de mouvement et aux limites approximatives (cette formation est dispensée pendant la configuration de HoloLens).</span><span class="sxs-lookup"><span data-stu-id="854e3-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="854e3-269">Avertir les utilisateurs quand leurs mouvements s’approchent des limites du cadre de mouvement dans une application, ou les franchissent, au point qu’une perte de mouvement peut engendrer des résultats indésirables.</span><span class="sxs-lookup"><span data-stu-id="854e3-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="854e3-270">Des études ont montré les qualités principales d’un tel système de notification, auquel répond le shell HoloLens avec une notification visuelle sur le curseur central, indiquant le sens dans lequel la limite est franchie.</span><span class="sxs-lookup"><span data-stu-id="854e3-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="854e3-271">Réduire au minimum les conséquences d’un franchissement des limites du cadre de mouvement.</span><span class="sxs-lookup"><span data-stu-id="854e3-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="854e3-272">En règle générale, le résultat d’un mouvement doit être arrêté à la limite, mais pas inversé.</span><span class="sxs-lookup"><span data-stu-id="854e3-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="854e3-273">Par exemple, si un utilisateur déplace un objet holographique dans une pièce, le déplacement doit s’arrêter quand le cadre de mouvement est dépassé, mais il ne doit pas être retourné au point de départ.</span><span class="sxs-lookup"><span data-stu-id="854e3-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="854e3-274">L’utilisateur peut alors ressentir une certaine frustration, mais peut comprendre plus rapidement les limites sans être systématiquement obligé de redémarrer les actions souhaitées dans leur intégralité.</span><span class="sxs-lookup"><span data-stu-id="854e3-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="854e3-275">Voir également</span><span class="sxs-lookup"><span data-stu-id="854e3-275">See also</span></span>
* [<span data-ttu-id="854e3-276">Manipulation directe avec les mains</span><span class="sxs-lookup"><span data-stu-id="854e3-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="854e3-277">Pointer et valider avec les mains</span><span class="sxs-lookup"><span data-stu-id="854e3-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="854e3-278">Interactions instinctuelles</span><span class="sxs-lookup"><span data-stu-id="854e3-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="854e3-279">Suivre de la tête et stabiliser</span><span class="sxs-lookup"><span data-stu-id="854e3-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="854e3-280">Commander avec la voix</span><span class="sxs-lookup"><span data-stu-id="854e3-280">Voice commanding</span></span>](voice-design.md)





