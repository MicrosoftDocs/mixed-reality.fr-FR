---
title: Mains et contrôleurs de mouvement dans DirectX
description: Guide du développeur pour l’utilisation du suivi de la main et les contrôleurs de mouvement dans les applications DirectX natives.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/30/2019
ms.topic: article
keywords: mains, contrôleurs de mouvement, directx, entrée, hologrammes
ms.openlocfilehash: 08666c8c26cd4851c0c003a96a9e96d7a90228ac
ms.sourcegitcommit: 45676da11ebe33a2aa3dccec0e8ad7d714420853
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 05/15/2019
ms.locfileid: "65629642"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="44f4e-104">Mains et contrôleurs de mouvement dans DirectX</span><span class="sxs-lookup"><span data-stu-id="44f4e-104">Hands and motion controllers in DirectX</span></span>

<span data-ttu-id="44f4e-105">En réalité mixte de Windows, les deux main et [contrôleur de mouvement](motion-controllers.md) l’entrée est gérée via l’API, une entrée spatiale trouvée dans le [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) espace de noms.</span><span class="sxs-lookup"><span data-stu-id="44f4e-105">In Windows Mixed Reality, both hand and [motion controller](motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="44f4e-106">Cela vous permet de gérer facilement des actions courantes telles que **sélectionnez** appuie sur la même façon entre les mains et contrôleurs de mouvement.</span><span class="sxs-lookup"><span data-stu-id="44f4e-106">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="44f4e-107">Prise en main</span><span class="sxs-lookup"><span data-stu-id="44f4e-107">Getting started</span></span>

<span data-ttu-id="44f4e-108">Pour accéder à spatiale d’entrée en réalité mixte Windows, démarrez avec l’interface SpatialInteractionManager.</span><span class="sxs-lookup"><span data-stu-id="44f4e-108">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="44f4e-109">Vous pouvez accéder à cette interface en appelant [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), généralement occasionnellement lors du démarrage de l’application.</span><span class="sxs-lookup"><span data-stu-id="44f4e-109">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="44f4e-110">Les travaux de le SpatialInteractionManager consiste à fournir un accès aux [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), qui représentent une source d’entrée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-110">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="44f4e-111">Il existe trois types de SpatialInteractionSources disponibles dans le système.</span><span class="sxs-lookup"><span data-stu-id="44f4e-111">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="44f4e-112">**Main** représente main détectés d’un utilisateur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-112">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="44f4e-113">Sources de main offrent des fonctionnalités différentes en fonction de l’appareil, allant des gestes de base sur HoloLens main entièrement articulés suivi sur HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="44f4e-113">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="44f4e-114">**Contrôleur** représente un contrôleur de mouvement associé.</span><span class="sxs-lookup"><span data-stu-id="44f4e-114">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="44f4e-115">Contrôleurs de mouvement peuvent offrir un éventail de fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="44f4e-115">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="44f4e-116">Exemple : Sélectionnez les déclencheurs, les boutons de Menu, des boutons de compréhension, pavés tactiles et sticks analogiques.</span><span class="sxs-lookup"><span data-stu-id="44f4e-116">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="44f4e-117">**Voix** représente la voix de l’utilisateur à propos du système a détecté les mots clés.</span><span class="sxs-lookup"><span data-stu-id="44f4e-117">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="44f4e-118">Par exemple, cette source est injecter l’appui sur une sélection et mise en production chaque fois que l’utilisateur dit « Select ».</span><span class="sxs-lookup"><span data-stu-id="44f4e-118">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="44f4e-119">Par image données pour une source est représentée par le [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span><span class="sxs-lookup"><span data-stu-id="44f4e-119">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="44f4e-120">Il existe deux façons différentes d’accéder à ces données, selon que vous souhaitez utiliser un modèle événementiel ou reposant sur l’interrogation dans votre application.</span><span class="sxs-lookup"><span data-stu-id="44f4e-120">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="44f4e-121">Entrée pilotée par événements</span><span class="sxs-lookup"><span data-stu-id="44f4e-121">Event-driven input</span></span>
<span data-ttu-id="44f4e-122">Le SpatialInteractionManager fournit un nombre d’événements que votre application peut écouter.</span><span class="sxs-lookup"><span data-stu-id="44f4e-122">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="44f4e-123">Sont des exemples [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) et [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="44f4e-123">A few examples include   [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="44f4e-124">Par exemple, le code suivant connecte un gestionnaire d’événements appelé MyApp::OnSourcePressed à l’événement SourcePressed.</span><span class="sxs-lookup"><span data-stu-id="44f4e-124">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="44f4e-125">Cela permet à votre application détecter les appuis sur n’importe quel type de source de l’interaction.</span><span class="sxs-lookup"><span data-stu-id="44f4e-125">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="44f4e-126">Cet événement appuyé est envoyé à votre application de façon asynchrone, ainsi que la SpatialInteractionSourceState correspondant au moment où que la presse s’est produite.</span><span class="sxs-lookup"><span data-stu-id="44f4e-126">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="44f4e-127">Votre application ou le moteur de jeu souhaitez peut-être effectuer un traitement immédiatement, ou vous souhaiterez peut-être les données d’événement dans votre routine de traitement des entrées de file d’attente.</span><span class="sxs-lookup"><span data-stu-id="44f4e-127">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="44f4e-128">Voici une fonction de gestionnaire d’événements pour l’événement SourcePressed, qui montre comment vérifier si le bouton de sélection a été enfoncé.</span><span class="sxs-lookup"><span data-stu-id="44f4e-128">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="44f4e-129">Le code ci-dessus vérifie uniquement la presse 'Select', qui correspond à l’action principale sur l’appareil.</span><span class="sxs-lookup"><span data-stu-id="44f4e-129">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="44f4e-130">Effectuer un AirTap sur HoloLens ou exemples tirant le déclencheur sur un contrôleur de mouvement.</span><span class="sxs-lookup"><span data-stu-id="44f4e-130">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="44f4e-131">Presses 'Select' représentent l’intention de l’utilisateur pour activer l’hologramme que cibler.</span><span class="sxs-lookup"><span data-stu-id="44f4e-131">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="44f4e-132">L’événement SourcePressed se déclenche pendant un nombre de boutons différents et des mouvements, et vous pouvez inspecter les autres propriétés sur le SpatialInteractionSource à tester pour ces cas.</span><span class="sxs-lookup"><span data-stu-id="44f4e-132">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="44f4e-133">Entrée d’interrogation.</span><span class="sxs-lookup"><span data-stu-id="44f4e-133">Polling-based input</span></span>
<span data-ttu-id="44f4e-134">Vous pouvez également utiliser SpatialInteractionManager pour interroger l’état actuel de l’entrée chaque trame.</span><span class="sxs-lookup"><span data-stu-id="44f4e-134">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="44f4e-135">Pour ce faire, appelez simplement [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) chaque trame.</span><span class="sxs-lookup"><span data-stu-id="44f4e-135">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="44f4e-136">Cette fonction retourne un tableau contenant une [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) pour chaque actif [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="44f4e-136">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="44f4e-137">Cela signifie une pour chaque contrôleur de mouvement active, une pour chaque aiguille suivie et une pour la reconnaissance vocale si une commande 'select' a été récemment prononcée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-137">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="44f4e-138">Vous pouvez ensuite inspecter les propriétés sur chaque SpatialInteractionSourceState à entrée du lecteur dans votre application.</span><span class="sxs-lookup"><span data-stu-id="44f4e-138">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="44f4e-139">Voici un exemple montrant comment vérifier l’action « select » à l’aide de la méthode d’interrogation.</span><span class="sxs-lookup"><span data-stu-id="44f4e-139">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="44f4e-140">Notez que le *prédiction* variable représente un [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) objet, ce qui peut être obtenu à partir de la [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="44f4e-140">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="44f4e-141">Chaque SpatialInteractionSource a un ID, vous pouvez utiliser pour identifier les nouvelles sources et de mettre en corrélation les sources existantes à partir d’une image à l’autre.</span><span class="sxs-lookup"><span data-stu-id="44f4e-141">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="44f4e-142">Mains sont affectés à un nouvel ID chaque fois qu’ils laissez, puis entrez l’angle d’ouverture, mais les ID de contrôleur restent statiques pendant la durée de la session.</span><span class="sxs-lookup"><span data-stu-id="44f4e-142">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="44f4e-143">Vous pouvez utiliser les événements sur SpatialInteractionManager comme [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) et [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), pour réagir quand mains ou à destination de l’appareil de l’afficher, ou lorsque les contrôleurs de mouvement sont activés/désactivé ou sont couplé/apparié.</span><span class="sxs-lookup"><span data-stu-id="44f4e-143">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="44f4e-144">Prédite et risque de poser historiques</span><span class="sxs-lookup"><span data-stu-id="44f4e-144">Predicted vs. historical poses</span></span>
<span data-ttu-id="44f4e-145">Notez que GetDetectedSourcesAtTimestamp a un paramètre de timestamp.</span><span class="sxs-lookup"><span data-stu-id="44f4e-145">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="44f4e-146">Cela vous permet de demander l’état et présentent des données qui sont soit prédite ou historiques et ainsi vous mettre en corrélation spatiales interactions avec d’autres sources d’entrée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-146">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="44f4e-147">Par exemple, lors du rendu de position de la main dans le frame actuel, vous pouvez passer dans l’horodatage prédite fournie par le [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="44f4e-147">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="44f4e-148">Cela permet au système de prédire-avant la position de la main pour s’aligner sur la sortie de l’image rendue, en réduisant la latence perçue.</span><span class="sxs-lookup"><span data-stu-id="44f4e-148">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="44f4e-149">Toutefois, telle une pose prédite ne produit pas un rayon de pointage idéale pour le ciblage avec une source de l’interaction.</span><span class="sxs-lookup"><span data-stu-id="44f4e-149">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="44f4e-150">Par exemple, lorsqu’un bouton de contrôleur de mouvement est enfoncé, il peut prendre jusqu'à 20 ms pour cet événement à se propager via Bluetooth au système d’exploitation.</span><span class="sxs-lookup"><span data-stu-id="44f4e-150">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="44f4e-151">De même, une fois un utilisateur effectue un mouvement de la main, une certaine quantité de temps peut passer avant que le système détecte le mouvement et votre application, puis interroge pour lui.</span><span class="sxs-lookup"><span data-stu-id="44f4e-151">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="44f4e-152">Au moment où votre application interroge pour un changement d’état, le risque de poser head et main utilisé pour cible interaction s’est passée dans le passé.</span><span class="sxs-lookup"><span data-stu-id="44f4e-152">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="44f4e-153">Si vous ciblez en passant d’horodatage de votre HolographicFrame actuel à GetDetectedSourcesAtTimestamp, la pose sera à la place par progression prédit pour le ciblage rayon au moment où que le frame s’affichera, qui pourrait être plus de 20 ms à l’avenir.</span><span class="sxs-lookup"><span data-stu-id="44f4e-153">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="44f4e-154">Cette pose futures est valable pour *rendu* la source de l’interaction, composés, mais notre problème de temps pour *ciblant* l’interaction, comme l’utilisateur du ciblage s’est produite dans le passé.</span><span class="sxs-lookup"><span data-stu-id="44f4e-154">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="44f4e-155">Heureusement, le [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) et [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) événements fournissent l’historique [état](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associé chaque événement d’entrée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-155">Fortunately, the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="44f4e-156">Cela inclut directement pose de tête et main historiques disponibles via [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), ainsi que d’un historique [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) que vous pouvez passer aux autres API pour mettre en corrélation avec cet événement.</span><span class="sxs-lookup"><span data-stu-id="44f4e-156">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="44f4e-157">Ceci nous mène aux meilleures pratiques suivantes lors de rendu et de ciblage avec mains et les contrôleurs de chaque image :</span><span class="sxs-lookup"><span data-stu-id="44f4e-157">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="44f4e-158">Pour **rendu de main/contrôleur** chaque trame, votre application doit **interrogation** pour le **prédit avant** poser de chaque source de l’interaction au moment de photon du frame actif.</span><span class="sxs-lookup"><span data-stu-id="44f4e-158">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="44f4e-159">Vous pouvez interroger pour toutes les sources d’interaction en appelant [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) chaque trame, en passant l’horodatage prédite fourni par [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="44f4e-159">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="44f4e-160">Pour **main/contrôleur ciblant** selon une press ou une mise en production, votre application doit gérer enfoncé/publié **événements**, raycasting selon le **historique** pose de tête ou de la main pour Cet événement.</span><span class="sxs-lookup"><span data-stu-id="44f4e-160">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="44f4e-161">Vous obtenez ce ciblage ray en gérant la [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) ou [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) événement, bien le [état](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) propriété à partir des arguments d’événement avant d’appeler ses [ TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) (méthode).</span><span class="sxs-lookup"><span data-stu-id="44f4e-161">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="44f4e-162">Propriétés d’entrée entre les périphériques</span><span class="sxs-lookup"><span data-stu-id="44f4e-162">Cross-device input properties</span></span>
<span data-ttu-id="44f4e-163">L’API SpatialInteractionSource prend en charge les contrôleurs et les systèmes avec un large éventail de fonctionnalités de suivi de main.</span><span class="sxs-lookup"><span data-stu-id="44f4e-163">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="44f4e-164">Un certain nombre de ces fonctionnalités est commun aux types d’appareils.</span><span class="sxs-lookup"><span data-stu-id="44f4e-164">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="44f4e-165">Par exemple, main suivi mouvement contrôleurs et les deux fournissent une action « sélectionner » et une position 3D.</span><span class="sxs-lookup"><span data-stu-id="44f4e-165">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="44f4e-166">Dans la mesure du possible, l’API mappe ces fonctionnalités courantes pour les mêmes propriétés sur le SpatialInteractionSource.</span><span class="sxs-lookup"><span data-stu-id="44f4e-166">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="44f4e-167">Cela permet aux applications plus facilement prendre en charge un large éventail de types d’entrée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-167">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="44f4e-168">Le tableau suivant décrit les propriétés qui sont prises en charge, et les comparer entre les types d’entrée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-168">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="44f4e-169">Propriété</span><span class="sxs-lookup"><span data-stu-id="44f4e-169">Property</span></span> | <span data-ttu-id="44f4e-170">Description</span><span class="sxs-lookup"><span data-stu-id="44f4e-170">Description</span></span> | <span data-ttu-id="44f4e-171">Mouvements de HoloLens</span><span class="sxs-lookup"><span data-stu-id="44f4e-171">HoloLens Gestures</span></span> | <span data-ttu-id="44f4e-172">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="44f4e-172">Motion Controllers</span></span> | <span data-ttu-id="44f4e-173">Mains articulés</span><span class="sxs-lookup"><span data-stu-id="44f4e-173">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="44f4e-174">SpatialInteractionSource ::**gaucher/droitier**</span><span class="sxs-lookup"><span data-stu-id="44f4e-174">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="44f4e-175">Droite ou gauche / contrôleur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-175">Right or left hand / controller.</span></span> | <span data-ttu-id="44f4e-176">Non prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-176">Not Supported</span></span> | <span data-ttu-id="44f4e-177">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-177">Supported</span></span> | <span data-ttu-id="44f4e-178">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-178">Supported</span></span> |
| [<span data-ttu-id="44f4e-179">SpatialInteractionSourceState::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="44f4e-179">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="44f4e-180">État actuel du bouton principal.</span><span class="sxs-lookup"><span data-stu-id="44f4e-180">Current state of the primary button.</span></span> | <span data-ttu-id="44f4e-181">Appui</span><span class="sxs-lookup"><span data-stu-id="44f4e-181">Air Tap</span></span> | <span data-ttu-id="44f4e-182">déclencheur</span><span class="sxs-lookup"><span data-stu-id="44f4e-182">Trigger</span></span> | <span data-ttu-id="44f4e-183">Souple Air appuyez sur (pincement vertical)</span><span class="sxs-lookup"><span data-stu-id="44f4e-183">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="44f4e-184">SpatialInteractionSourceState::**IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="44f4e-184">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="44f4e-185">État actuel du bouton de manipulation.</span><span class="sxs-lookup"><span data-stu-id="44f4e-185">Current state of the grab button.</span></span> | <span data-ttu-id="44f4e-186">Non prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-186">Not Supported</span></span> | <span data-ttu-id="44f4e-187">Bouton de manipulation</span><span class="sxs-lookup"><span data-stu-id="44f4e-187">Grab button</span></span> | <span data-ttu-id="44f4e-188">Main pincement ou fermé</span><span class="sxs-lookup"><span data-stu-id="44f4e-188">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="44f4e-189">SpatialInteractionSourceState::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="44f4e-189">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="44f4e-190">État actuel du bouton de menu.</span><span class="sxs-lookup"><span data-stu-id="44f4e-190">Current state of the menu button.</span></span>    | <span data-ttu-id="44f4e-191">Non prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-191">Not Supported</span></span> | <span data-ttu-id="44f4e-192">Bouton de menu</span><span class="sxs-lookup"><span data-stu-id="44f4e-192">Menu Button</span></span> | <span data-ttu-id="44f4e-193">Non prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-193">Not Supported</span></span> |
| [<span data-ttu-id="44f4e-194">SpatialInteractionSourceLocation ::**Position**</span><span class="sxs-lookup"><span data-stu-id="44f4e-194">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="44f4e-195">Emplacement XYZ de la position main ou la poignée sur le contrôleur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-195">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="44f4e-196">Emplacement de Palm</span><span class="sxs-lookup"><span data-stu-id="44f4e-196">Palm location</span></span> | <span data-ttu-id="44f4e-197">Poignée pose position</span><span class="sxs-lookup"><span data-stu-id="44f4e-197">Grip pose position</span></span> | <span data-ttu-id="44f4e-198">Emplacement de Palm</span><span class="sxs-lookup"><span data-stu-id="44f4e-198">Palm location</span></span> |
| [<span data-ttu-id="44f4e-199">SpatialInteractionSourceLocation ::**Orientation**</span><span class="sxs-lookup"><span data-stu-id="44f4e-199">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="44f4e-200">Quaternion qui représente l’orientation de la main ou la poignée de poser sur le contrôleur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-200">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="44f4e-201">Non prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-201">Not Supported</span></span> | <span data-ttu-id="44f4e-202">Poignée pose orientation</span><span class="sxs-lookup"><span data-stu-id="44f4e-202">Grip pose orientation</span></span> | <span data-ttu-id="44f4e-203">Orientation de Palm</span><span class="sxs-lookup"><span data-stu-id="44f4e-203">Palm orientation</span></span> |
| [<span data-ttu-id="44f4e-204">SpatialPointerInteractionSourcePose ::**Position**</span><span class="sxs-lookup"><span data-stu-id="44f4e-204">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="44f4e-205">Origine du rayon de pointage.</span><span class="sxs-lookup"><span data-stu-id="44f4e-205">Origin of the pointing ray.</span></span> | <span data-ttu-id="44f4e-206">Non prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-206">Not Supported</span></span> | <span data-ttu-id="44f4e-207">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-207">Supported</span></span> | <span data-ttu-id="44f4e-208">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-208">Supported</span></span> |
| [<span data-ttu-id="44f4e-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="44f4e-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="44f4e-210">Direction du rayon pointage.</span><span class="sxs-lookup"><span data-stu-id="44f4e-210">Direction of the pointing ray.</span></span> | <span data-ttu-id="44f4e-211">Non prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-211">Not Supported</span></span> | <span data-ttu-id="44f4e-212">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-212">Supported</span></span> | <span data-ttu-id="44f4e-213">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="44f4e-213">Supported</span></span> |

<span data-ttu-id="44f4e-214">Certaines des propriétés ci-dessus ne sont pas disponibles sur tous les appareils, et l’API fournit un moyen de tester cela.</span><span class="sxs-lookup"><span data-stu-id="44f4e-214">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="44f4e-215">Par exemple, vous pouvez inspecter les [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) propriété pour déterminer si la source fournit une action de compréhension.</span><span class="sxs-lookup"><span data-stu-id="44f4e-215">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="44f4e-216">Pose de poignée et pose de pointage</span><span class="sxs-lookup"><span data-stu-id="44f4e-216">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="44f4e-217">Réalité mixte Windows prend en charge les contrôleurs de mouvements dans un large éventail de facteurs de forme.</span><span class="sxs-lookup"><span data-stu-id="44f4e-217">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="44f4e-218">Il prend également en charge les bras main des systèmes de suivi.</span><span class="sxs-lookup"><span data-stu-id="44f4e-218">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="44f4e-219">Tous ces systèmes ont différentes relations entre la position de la main et le sens de « avant » naturels que les applications doivent utiliser pour les objets pointant ou rendreing à portée de main de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-219">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendreing objects in the user's hand.</span></span>  <span data-ttu-id="44f4e-220">Pour prendre en charge tout ceci, il existe deux types de risque de poser 3D fourni pour les deux contrôleurs de suivi et des mouvements de main.</span><span class="sxs-lookup"><span data-stu-id="44f4e-220">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="44f4e-221">La première est pose de poignée, qui représente la position de main de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-221">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="44f4e-222">La deuxième pointe pose, qui représente un rayon de pointage provenant de la main ou contrôleur de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-222">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="44f4e-223">Par conséquent, si vous souhaitez restituer **main de l’utilisateur** ou **détenues par un objet à portée de main de l’utilisateur**, tel qu’un mot de passe ou d’un électrons, utilisez la pose de poignée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-223">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="44f4e-224">Si vous souhaitez raycast à partir du contrôleur ou d’une part, par exemple lorsque l’utilisateur est **vers l’interface utilisateur** , utilisez la pose de pointage.</span><span class="sxs-lookup"><span data-stu-id="44f4e-224">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="44f4e-225">Vous pouvez accéder à la **poignée pose** via [SpatialInteractionSourceState::Properties::TryGetLocation(...) ](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  Il est défini comme suit :</span><span class="sxs-lookup"><span data-stu-id="44f4e-225">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="44f4e-226">Le **Attrapez position**: Le centroïde de palm naturellement, tout en maintenant le contrôleur ajustée gauche ou droite pour centrer la position au sein de la poignée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-226">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="44f4e-227">Le **Attrapez axe de droite de l’orientation**: Lorsque vous ouvrez totalement la main pour former une pose plat 5-doigt, le rayon qui est normal pour votre palm (en avant à partir de la gauche palm, vers l’arrière de palm droite)</span><span class="sxs-lookup"><span data-stu-id="44f4e-227">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="44f4e-228">Le **Attrapez axe vers l’avant de l’orientation**: Lorsque vous fermez votre main partiellement (comme le cas maintenant le contrôleur), le rayon pointe « forward » via le tube formé par vos doigts non curseur.</span><span class="sxs-lookup"><span data-stu-id="44f4e-228">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="44f4e-229">Le **Attrapez orientation d’axe**: L’axe à distance impliqué par les définitions de droite, en avant.</span><span class="sxs-lookup"><span data-stu-id="44f4e-229">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="44f4e-230">Vous pouvez accéder à la **pose de pointeur** via [SpatialInteractionSourceState::Properties::TryGetLocation (...) :: SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) ou [SpatialInteractionSourceState :: TryGetPointerPose (...) :: TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="44f4e-230">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="44f4e-231">Propriétés d’entrée spécifique du contrôleur</span><span class="sxs-lookup"><span data-stu-id="44f4e-231">Controller-specific input properties</span></span>
<span data-ttu-id="44f4e-232">Pour les contrôleurs, le SpatialInteractionSource a une propriété de contrôleur avec des fonctionnalités supplémentaires.</span><span class="sxs-lookup"><span data-stu-id="44f4e-232">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="44f4e-233">**HasThumbstick :** Si la valeur est true, le contrôleur a un stick analogique.</span><span class="sxs-lookup"><span data-stu-id="44f4e-233">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="44f4e-234">Inspecter le [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) propriété de la SpatialInteractionSourceState pour acquérir le stick analogique x et les valeurs y (ThumbstickX et ThumbstickY), ainsi que son état enfoncé (IsThumbstickPressed).</span><span class="sxs-lookup"><span data-stu-id="44f4e-234">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="44f4e-235">**HasTouchpad :** Si la valeur est true, le contrôleur a un pavé tactile.</span><span class="sxs-lookup"><span data-stu-id="44f4e-235">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="44f4e-236">Inspecter la propriété ControllerProperties de la SpatialInteractionSourceState pour acquérir le pavé tactile x et y valeurs (TouchpadX et TouchpadY) et pour savoir si l’utilisateur touche le panneau (IsTouchpadTouched) et si elles sont en appuyant sur le pavé tactile vers le bas () IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="44f4e-236">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="44f4e-237">**SimpleHapticsController :** L’API SimpleHapticsController pour le contrôleur vous permet d’inspecter les fonctionnalités HAPTIQUES du contrôleur de, et il vous permet également de contrôler le retour haptique.</span><span class="sxs-lookup"><span data-stu-id="44f4e-237">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="44f4e-238">Notez que la plage pour le pavé tactile et stick analogique est -1 et 1 pour les deux axes (de bas en haut et de gauche à droite).</span><span class="sxs-lookup"><span data-stu-id="44f4e-238">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="44f4e-239">La plage pour le déclencheur analogique, qui est accessible à l’aide de la propriété SpatialInteractionSourceState::SelectPressedValue, a une plage de 0 à 1.</span><span class="sxs-lookup"><span data-stu-id="44f4e-239">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="44f4e-240">Une valeur de 1 met en corrélation avec IsSelectPressed étant égal à true ; toute autre valeur met en corrélation avec IsSelectPressed étant égal à false.</span><span class="sxs-lookup"><span data-stu-id="44f4e-240">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="44f4e-241">Main bras de suivi</span><span class="sxs-lookup"><span data-stu-id="44f4e-241">Articulated hand tracking</span></span>
<span data-ttu-id="44f4e-242">L’API de réalité mixte Windows prend en charge pour la main articulé de suivi, par exemple sur HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="44f4e-242">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="44f4e-243">Main bras de suivi peut servir à implémenter la manipulation directe et des modèles d’entrée de point et de validation dans vos applications.</span><span class="sxs-lookup"><span data-stu-id="44f4e-243">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="44f4e-244">Il peut également servir à créer des interactions entièrement personnalisées.</span><span class="sxs-lookup"><span data-stu-id="44f4e-244">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="44f4e-245">Structure de main</span><span class="sxs-lookup"><span data-stu-id="44f4e-245">Hand skeleton</span></span>
<span data-ttu-id="44f4e-246">Main articulé de suivi fournit une structure commune 25 qui permet de nombreux types d’interactions.</span><span class="sxs-lookup"><span data-stu-id="44f4e-246">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="44f4e-247">La structure fournit 5 joints pour les doigts index/intermédiaire/en anneau/peu, 4 joints pour le curseur et 1 poignet mixte.</span><span class="sxs-lookup"><span data-stu-id="44f4e-247">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="44f4e-248">La jointure de poignet sert de la base de la hiérarchie.</span><span class="sxs-lookup"><span data-stu-id="44f4e-248">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="44f4e-249">L’image suivante illustre la disposition de la structure.</span><span class="sxs-lookup"><span data-stu-id="44f4e-249">The following picture illustrates the layout of the skeleton.</span></span>

![Structure de main](images/hand-skeleton.png)

<span data-ttu-id="44f4e-251">Dans la plupart des cas, chaque commune est nommé en fonction de l’OS qu’il représente.</span><span class="sxs-lookup"><span data-stu-id="44f4e-251">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="44f4e-252">Dans la mesure où il n’y a deux segments à chaque commune, nous utilisons une convention de nommage chaque joint en fonction de l’OS enfant à cet emplacement.</span><span class="sxs-lookup"><span data-stu-id="44f4e-252">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="44f4e-253">Le segment de l’enfant est défini comme l’OS plus éloigné du poignet.</span><span class="sxs-lookup"><span data-stu-id="44f4e-253">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="44f4e-254">Par exemple, le « Index PROXIMALE « mixte contient la position de début de l’OS PROXIMALE index et l’orientation de ce segment.</span><span class="sxs-lookup"><span data-stu-id="44f4e-254">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="44f4e-255">Il ne contient pas la position de fin du segment.</span><span class="sxs-lookup"><span data-stu-id="44f4e-255">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="44f4e-256">Si vous avez besoin que, vous obtiendriez il à partir de la prochaine mixte dans la hiérarchie, le « Index intermédiaires » commun.</span><span class="sxs-lookup"><span data-stu-id="44f4e-256">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="44f4e-257">En plus de 25 articulations hiérarchiques, le système fournit un joint palm.</span><span class="sxs-lookup"><span data-stu-id="44f4e-257">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="44f4e-258">Le palm n’est pas généralement considéré partie de la structure du squelette.</span><span class="sxs-lookup"><span data-stu-id="44f4e-258">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="44f4e-259">Il est fourni uniquement comme un moyen pratique pour obtenir la position et l’orientation globale de la main.</span><span class="sxs-lookup"><span data-stu-id="44f4e-259">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="44f4e-260">Les informations suivantes sont fournies pour chaque jointure :</span><span class="sxs-lookup"><span data-stu-id="44f4e-260">The following information is provided for each joint:</span></span>

| <span data-ttu-id="44f4e-261">Nom</span><span class="sxs-lookup"><span data-stu-id="44f4e-261">Name</span></span> | <span data-ttu-id="44f4e-262">Description</span><span class="sxs-lookup"><span data-stu-id="44f4e-262">Description</span></span> |
|--- |--- |
|<span data-ttu-id="44f4e-263">Position</span><span class="sxs-lookup"><span data-stu-id="44f4e-263">Position</span></span> | <span data-ttu-id="44f4e-264">Position 3D de la jointure, disponible dans n’importe quel système de coordonnées demandée.</span><span class="sxs-lookup"><span data-stu-id="44f4e-264">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="44f4e-265">Orientation</span><span class="sxs-lookup"><span data-stu-id="44f4e-265">Orientation</span></span> | <span data-ttu-id="44f4e-266">Orientation 3D de l’OS, disponible dans aucun demandé de système de coordonnées.</span><span class="sxs-lookup"><span data-stu-id="44f4e-266">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="44f4e-267">Rayon</span><span class="sxs-lookup"><span data-stu-id="44f4e-267">Radius</span></span> | <span data-ttu-id="44f4e-268">Distance à la surface de l’apparence à la position commune.</span><span class="sxs-lookup"><span data-stu-id="44f4e-268">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="44f4e-269">Utile pour le réglage des interactions directes ou des visualisations qui s’appuient sur la largeur du doigt.</span><span class="sxs-lookup"><span data-stu-id="44f4e-269">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="44f4e-270">Précision</span><span class="sxs-lookup"><span data-stu-id="44f4e-270">Accuracy</span></span> | <span data-ttu-id="44f4e-271">Fournit une indication sur la certitude comment le système semble sur les informations de cette jointure.</span><span class="sxs-lookup"><span data-stu-id="44f4e-271">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="44f4e-272">Vous pouvez accéder à des données squelette disponible via une fonction sur le [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="44f4e-272">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="44f4e-273">La fonction est appelée [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), et elle retourne un objet appelé [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="44f4e-273">The function is called [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="44f4e-274">Si la source ne prend pas en charge les mains articulés, cette fonction retourne null.</span><span class="sxs-lookup"><span data-stu-id="44f4e-274">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="44f4e-275">Une fois que vous avez un HandPose, vous pouvez obtenir des données mixte actuelles en appelant [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), avec le nom de la jointure, vous êtes intéressé.</span><span class="sxs-lookup"><span data-stu-id="44f4e-275">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="44f4e-276">Les données sont retournées en tant qu’un [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) structure.</span><span class="sxs-lookup"><span data-stu-id="44f4e-276">The data is returned as a [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="44f4e-277">Le code suivant obtient la position de l’info-bulle de votre index.</span><span class="sxs-lookup"><span data-stu-id="44f4e-277">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="44f4e-278">La variable *currentState* représente une instance de [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="44f4e-278">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="44f4e-279">Maillage de main</span><span class="sxs-lookup"><span data-stu-id="44f4e-279">Hand mesh</span></span>

<span data-ttu-id="44f4e-280">L’aiguille articulé de l’API de suivi permet une maille de main entièrement déformable triangle.</span><span class="sxs-lookup"><span data-stu-id="44f4e-280">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="44f4e-281">Ce maillage peut déformer en temps réel, ainsi que la structure de la main et est utile pour la visualisation, ainsi que des techniques de physique avancé.</span><span class="sxs-lookup"><span data-stu-id="44f4e-281">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="44f4e-282">Pour accéder à la maille de main, vous devez d’abord créer un [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) objet en appelant [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) sur le [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="44f4e-282">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="44f4e-283">Cette opération ne doit être effectuée qu’une fois par source, généralement la première fois que vous le voyez.</span><span class="sxs-lookup"><span data-stu-id="44f4e-283">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="44f4e-284">Cela signifie que vous devez appeler cette fonction pour créer un objet HandMeshObserver chaque fois qu’une main passe à l’angle d’ouverture.</span><span class="sxs-lookup"><span data-stu-id="44f4e-284">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="44f4e-285">Notez qu’il s’agit d’une fonction async, vous devez donc gérer avec un peu de concurrence ici.</span><span class="sxs-lookup"><span data-stu-id="44f4e-285">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="44f4e-286">Une fois disponible, vous pouvez demander à l’objet HandMeshObserver de la mémoire tampon d’index triangle, en appelant [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="44f4e-286">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="44f4e-287">Indices ne modifiez pas frame par frame, afin de pouvoir les obtenir qu’une seule fois et les mettre en cache pour la durée de vie de la source.</span><span class="sxs-lookup"><span data-stu-id="44f4e-287">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="44f4e-288">Indices sont fournies dans l’ordre d’enroulement dans le sens horaire.</span><span class="sxs-lookup"><span data-stu-id="44f4e-288">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="44f4e-289">Le code suivant tourne un std::thread détaché pour créer l’Observateur de maillage et extrait la mémoire tampon d’index une fois que l’Observateur de maille est disponible.</span><span class="sxs-lookup"><span data-stu-id="44f4e-289">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="44f4e-290">Il démarre à partir d’une variable appelée *currentState*, qui est une instance de [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) représentant une main suivie.</span><span class="sxs-lookup"><span data-stu-id="44f4e-290">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="44f4e-291">À partir d’un thread détaché est qu’une seule option pour la gestion des appels asynchrones.</span><span class="sxs-lookup"><span data-stu-id="44f4e-291">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="44f4e-292">Vous pouvez également utiliser la nouvelle [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) fonctionnalités prises en charge par C++/WinRT.</span><span class="sxs-lookup"><span data-stu-id="44f4e-292">Alternatively, you could use the new [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="44f4e-293">Une fois que vous avez un objet HandMeshObserver, vous ne devriez conserver il pendant la durée de son SpatialInteractionSource correspondant est actif.</span><span class="sxs-lookup"><span data-stu-id="44f4e-293">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="44f4e-294">Puis chaque cadre, vous pouvez le demander de la dernière mémoire tampon vertex qui représente la main en appelant [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) et en passant un [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) instance qui représente la pose que vous souhaitez les sommets pour.</span><span class="sxs-lookup"><span data-stu-id="44f4e-294">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="44f4e-295">Chaque vertex dans la mémoire tampon a une position et un élément normal.</span><span class="sxs-lookup"><span data-stu-id="44f4e-295">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="44f4e-296">Voici un exemple illustrant comment obtenir l’ensemble actuel des sommets d’un maillage de main.</span><span class="sxs-lookup"><span data-stu-id="44f4e-296">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="44f4e-297">Comme auparavant, le *currentState* variable représente une instance de [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="44f4e-297">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="44f4e-298">Contrairement à squelettes joints, l’API de maille main n’autorise pas vous permettent de spécifier un système de coordonnées pour les vertex.</span><span class="sxs-lookup"><span data-stu-id="44f4e-298">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="44f4e-299">Au lieu de cela, le [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) Spécifie le système de coordonnées qui les sommets sont fournies dans.</span><span class="sxs-lookup"><span data-stu-id="44f4e-299">Instead, the [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="44f4e-300">Vous pouvez ensuite obtenir une transformation de maille en appelant [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) et en spécifiant votre système de coordonnées de votre choix.</span><span class="sxs-lookup"><span data-stu-id="44f4e-300">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="44f4e-301">Vous devez utiliser cette transformation maillage chaque fois que vous travaillez avec les sommets.</span><span class="sxs-lookup"><span data-stu-id="44f4e-301">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="44f4e-302">Cette approche réduit la surcharge du processeur, en particulier si vous utilisez uniquement la maille à des fins de rendu.</span><span class="sxs-lookup"><span data-stu-id="44f4e-302">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="44f4e-303">Utilisation et validez les mouvements composites</span><span class="sxs-lookup"><span data-stu-id="44f4e-303">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="44f4e-304">Pour les applications utilisant le modèle d’entrée du pointage de regard-validation, en particulier sur HoloLens (première génération), l’API d’entrée Spatial fournit facultative [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) qui peut être utilisé à pour activer les mouvements composites, construits sur le 'select' événement.</span><span class="sxs-lookup"><span data-stu-id="44f4e-304">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="44f4e-305">En routage d’interactions à partir de la SpatialInteractionManager à SpatialGestureRecognizer d’un hologramme, applications peuvent détecter les événements Tap, blocage, la Manipulation et Navigation uniformément entre les mains, voix et périphériques d’entrée spatiales, sans avoir à gérer les activations et libère manuellement.</span><span class="sxs-lookup"><span data-stu-id="44f4e-305">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="44f4e-306">SpatialGestureRecognizer effectue uniquement la levée d’ambiguïté minimale entre l’ensemble des gestes que vous demandez.</span><span class="sxs-lookup"><span data-stu-id="44f4e-306">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="44f4e-307">Par exemple, si vous demandez simplement Tap, l’utilisateur peut maintenez son doigt en tant qu’ils le souhaitent et un drainage se produira toujours.</span><span class="sxs-lookup"><span data-stu-id="44f4e-307">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="44f4e-308">Si vous demandez à la fois maintenez sur, après environ une seconde d’enfoncée son doigt, promeut le mouvement à une suspension et un drainage ne se produit plus.</span><span class="sxs-lookup"><span data-stu-id="44f4e-308">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="44f4e-309">Pour utiliser SpatialGestureRecognizer, gérer la SpatialInteractionManager [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) événements et capture le SpatialPointerPose exposée il.</span><span class="sxs-lookup"><span data-stu-id="44f4e-309">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="44f4e-310">Utilisez ray regards principal de l’utilisateur à partir de cette pose à croiser avec l’hologrammes et surface mailles dans son environnement de l’utilisateur, afin de déterminer ce que l’utilisateur a l’intention d’interagir avec.</span><span class="sxs-lookup"><span data-stu-id="44f4e-310">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="44f4e-311">Ensuite, acheminer la SpatialInteraction dans les arguments d’événement pour SpatialGestureRecognizer de hologramme de cible, à l’aide de son [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) (méthode).</span><span class="sxs-lookup"><span data-stu-id="44f4e-311">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="44f4e-312">Cela démarre l’interprétation de cette interaction conformément à la [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) définies sur ce module de reconnaissance à l’heure de création - ou en [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span><span class="sxs-lookup"><span data-stu-id="44f4e-312">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="44f4e-313">Sur HoloLens (tout d’abord de la génération), interactions et des mouvements doivent dériver généralement leur ciblage à partir des regards principal de l’utilisateur, au lieu d’essayer restituer ou interagir directement à l’emplacement de la main.</span><span class="sxs-lookup"><span data-stu-id="44f4e-313">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="44f4e-314">Une fois démarrée, une interaction des mouvements relatifs de la main peuvent servir à contrôler le mouvement, comme avec le mouvement de Manipulation ou de Navigation.</span><span class="sxs-lookup"><span data-stu-id="44f4e-314">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="44f4e-315">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="44f4e-315">See also</span></span>
* [<span data-ttu-id="44f4e-316">HEAD et surveillez les regards dans DirectX</span><span class="sxs-lookup"><span data-stu-id="44f4e-316">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="44f4e-317">Modèle d’entrée de manipulation directe</span><span class="sxs-lookup"><span data-stu-id="44f4e-317">Direct manipulation input model</span></span>](direct-manipulation.md)
* [<span data-ttu-id="44f4e-318">Modèle d’entrée de point et validation</span><span class="sxs-lookup"><span data-stu-id="44f4e-318">Point-and-commit input model</span></span>](point-and-commit.md)
* [<span data-ttu-id="44f4e-319">Modèle d’entrée du pointage de regard et validation</span><span class="sxs-lookup"><span data-stu-id="44f4e-319">Gaze and commit input model</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="44f4e-320">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="44f4e-320">Motion controllers</span></span>](motion-controllers.md)
