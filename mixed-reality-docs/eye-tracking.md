---
title: Œil-point de regard
description: HoloLens 2 permet à un nouveau niveau de compréhension du contexte et de l’homme au sein de l’expérience holographique en offrant aux développeurs la possibilité d’utiliser des informations sur ce que les utilisateurs cherchent.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Suivi oculaire, réalité mixte, entrée, point de regard oculaire
ms.openlocfilehash: c847f7de2cf4492c89225a88aeaf189f51cfbc40
ms.sourcegitcommit: b0b1b8e1182cce93929d409706cdaa99ff24fdee
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 07/23/2019
ms.locfileid: "68387596"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="cfde8-104">Eye-point de regard sur HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="cfde8-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="cfde8-105">HoloLens 2 permet à un nouveau niveau de compréhension du contexte et de l’homme au sein de l’expérience holographique en offrant aux développeurs la possibilité d’utiliser des informations sur ce que les utilisateurs cherchent.</span><span class="sxs-lookup"><span data-stu-id="cfde8-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="cfde8-106">Cette page explique aux développeurs comment ils peuvent tirer parti du suivi oculaire pour divers cas d’usage, ainsi que des éléments à rechercher lors de la conception d’interfaces utilisateur orientées yeux.</span><span class="sxs-lookup"><span data-stu-id="cfde8-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="cfde8-107">Prise en charge des appareils</span><span class="sxs-lookup"><span data-stu-id="cfde8-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="cfde8-108"><strong>Fonctionnalité</strong></span><span class="sxs-lookup"><span data-stu-id="cfde8-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="cfde8-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1ère génération)</strong></a></span><span class="sxs-lookup"><span data-stu-id="cfde8-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="cfde8-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="cfde8-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="cfde8-111"><a href="immersive-headset-hardware-details.md"><strong>Casques immersifs</strong></a></span><span class="sxs-lookup"><span data-stu-id="cfde8-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="cfde8-112">Œil-point de regard</span><span class="sxs-lookup"><span data-stu-id="cfde8-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="cfde8-113">❌</span><span class="sxs-lookup"><span data-stu-id="cfde8-113">❌</span></span></td>
     <td><span data-ttu-id="cfde8-114">✔️</span><span class="sxs-lookup"><span data-stu-id="cfde8-114">✔️</span></span></td>
     <td><span data-ttu-id="cfde8-115">❌</span><span class="sxs-lookup"><span data-stu-id="cfde8-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="cfde8-116">Cas d’usage</span><span class="sxs-lookup"><span data-stu-id="cfde8-116">Use cases</span></span>
<span data-ttu-id="cfde8-117">L’eye-tracking permet aux applications de savoir où l’utilisateur regarde en temps réel.</span><span class="sxs-lookup"><span data-stu-id="cfde8-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="cfde8-118">Les cas d’usage suivants décrivent certaines interactions possibles avec le suivi oculaire en réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="cfde8-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="cfde8-119">N’oubliez pas que le [Kit d’outils de réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) est utile pour fournir plusieurs exemples intéressants et puissants pour l’utilisation du suivi oculaire, tels que des sélections de cibles rapides et faciles à prendre en charge par l’œil, ainsi que pour faire défiler automatiquement le texte en fonction de ce à quoi l’utilisateur regarde.</span><span class="sxs-lookup"><span data-stu-id="cfde8-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="cfde8-120">Intention de l’utilisateur</span><span class="sxs-lookup"><span data-stu-id="cfde8-120">User intent</span></span>    
<span data-ttu-id="cfde8-121">Des informations sur l’emplacement et le rôle d’un utilisateur fournissent un **contexte puissant pour d’autres entrées**, telles que la voix, les mains et les contrôleurs.</span><span class="sxs-lookup"><span data-stu-id="cfde8-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="cfde8-122">Cela peut être utile pour diverses tâches.</span><span class="sxs-lookup"><span data-stu-id="cfde8-122">This can be used for various tasks.</span></span>
<span data-ttu-id="cfde8-123">Par exemple, cette opération peut être effectuée rapidement et facilement **sur la** scène en regardant simplement un hologramme et en disant «sélectionner» (voir également le point d’insertion [et de validation](gaze-and-commit.md)de la tête) ou en disant «placer cela...», puis en regardant à l’endroit où l’utilisateur veut placer l’hologramme et dites «... là».</span><span class="sxs-lookup"><span data-stu-id="cfde8-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where the user wants to place the hologram and say "...there".</span></span> <span data-ttu-id="cfde8-124">Vous trouverez des exemples à ce sujet dans [Mixed Reality Toolkit - Sélection d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) et [Mixed Reality Toolkit - Positionnement d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="cfde8-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="cfde8-125">En outre, un exemple d’intention de l’utilisateur peut inclure des informations sur ce que les utilisateurs cherchent pour améliorer l’engagement avec des agents virtuels et des hologrammes interactifs.</span><span class="sxs-lookup"><span data-stu-id="cfde8-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="cfde8-126">Par exemple, les agents virtuels peuvent adapter les options disponibles et leur comportement en fonction du contenu actuellement affiché.</span><span class="sxs-lookup"><span data-stu-id="cfde8-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="cfde8-127">Actions implicites</span><span class="sxs-lookup"><span data-stu-id="cfde8-127">Implicit actions</span></span>
<span data-ttu-id="cfde8-128">La catégorie des actions implicites est étroitement liée à l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="cfde8-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="cfde8-129">L’idée est que les hologrammes ou les éléments d’interface utilisateur réagissent de façon quelque peu instinctual, qui peut même ne pas se comporter comme l’utilisateur qui interagit avec le système, mais plutôt que le système et l’utilisateur sont synchronisés. Un exemple est le **défilement automatique en regard de l’œil,** où l’utilisateur lit le texte lorsque le texte continue à faire défiler ou qu’il se synchronise avec le regard de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="cfde8-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user reads text as the text continues to scroll or flow in sync with with the user's gaze.</span></span> <span data-ttu-id="cfde8-130">Un aspect clé de cela est que la vitesse de défilement s’adapte à la vitesse de lecture de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="cfde8-130">A key aspect of this is that scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="cfde8-131">Un autre exemple est un **Zoom et un panoramique pris en charge par l’œil,** où l’utilisateur peut sembler se plonger exactement sur ce qu’il a le plus ciblé.</span><span class="sxs-lookup"><span data-stu-id="cfde8-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused o.</span></span> <span data-ttu-id="cfde8-132">Le déclenchement du zoom et du contrôle de la vitesse de zoom peut être contrôlé par des entrées vocales ou de la main, ce qui est important pour fournir à l’utilisateur le sentiment de contrôle tout en évitant d’être submergé.</span><span class="sxs-lookup"><span data-stu-id="cfde8-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="cfde8-133">Nous parlerons des instructions de conception plus en détail ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="cfde8-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="cfde8-134">Une fois le zoom avant effectué, l’utilisateur peut suivre facilement, par exemple, le cours d’une rue pour explorer son voisinage en utilisant simplement son regard.</span><span class="sxs-lookup"><span data-stu-id="cfde8-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="cfde8-135">Vous trouverez des démonstrations de ces types d’interaction dans l’exemple [Mixed Reality Toolkit - Navigation à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="cfde8-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="cfde8-136">Des cas d’usage supplémentaires pour les _actions implicites_ peuvent inclure:</span><span class="sxs-lookup"><span data-stu-id="cfde8-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="cfde8-137">**Notifications intelligentes :** Avez-vous déjà été ennuyé par des notifications qui apparaissent juste là où vous concentrez votre attention ?</span><span class="sxs-lookup"><span data-stu-id="cfde8-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="cfde8-138">En tenant compte de ce à quoi un utilisateur fait attention, vous pouvez améliorer cette expérience en décalant les notifications à partir de l’endroit où l’utilisateur est actuellement Gazing.</span><span class="sxs-lookup"><span data-stu-id="cfde8-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="cfde8-139">Cela limite les distractions et les ignore automatiquement une fois que l’utilisateur a terminé la lecture.</span><span class="sxs-lookup"><span data-stu-id="cfde8-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="cfde8-140">**Hologrammes attentifs :** Des hologrammes qui réagissent à la légère sur le regard.</span><span class="sxs-lookup"><span data-stu-id="cfde8-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="cfde8-141">Cela peut aller de quelques éléments d’interface utilisateur à une fleur très lente à un animal de compagnie virtuel, commençant à regarder l’utilisateur ou à essayer d’éviter l’oeil de l’utilisateur après une étoile prolongée.</span><span class="sxs-lookup"><span data-stu-id="cfde8-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="cfde8-142">Cette interaction peut fournir un sens intéressant de la connectivité et de la satisfaction dans votre application.</span><span class="sxs-lookup"><span data-stu-id="cfde8-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="cfde8-143">Suivi de l’attention</span><span class="sxs-lookup"><span data-stu-id="cfde8-143">Attention tracking</span></span>   
<span data-ttu-id="cfde8-144">Des informations sur l’emplacement ou les utilisateurs qui regardent sont un outil très puissant pour évaluer la convivialité des conceptions et pour identifier les problèmes dans les flux de travail efficaces.</span><span class="sxs-lookup"><span data-stu-id="cfde8-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="cfde8-145">La visualisation et l’analyse du suivi oculaire sont une pratique courante dans différents domaines d’application.</span><span class="sxs-lookup"><span data-stu-id="cfde8-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="cfde8-146">Avec HoloLens 2, nous fournissons une nouvelle dimension à cette compréhension, car les hologrammes 3D peuvent être placés dans des contextes réels et évalués en conséquence.</span><span class="sxs-lookup"><span data-stu-id="cfde8-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="cfde8-147">La [boîte à outils de la réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fournit des exemples de base pour la journalisation et le chargement des données de suivi visuel et comment les visualiser.</span><span class="sxs-lookup"><span data-stu-id="cfde8-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="cfde8-148">Les autres applications de cette zone peuvent inclure:</span><span class="sxs-lookup"><span data-stu-id="cfde8-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="cfde8-149">**Œil à distance-visualisation du regard:** Visualisez ce que les collaborateurs distants examinent pour vérifier si les instructions sont correctement comprises et suivies.</span><span class="sxs-lookup"><span data-stu-id="cfde8-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="cfde8-150">**Études de recherche sur les utilisateurs :** Le suivi de l’attention peut être utilisé pour explorer la manière dont les utilisateurs débutants ou expérimentés analysent le contenu visuellement, ou comment leur coordination manuelle pour les tâches complexes, telles que l’analyse des données médicales ou les machines à fonctionner.</span><span class="sxs-lookup"><span data-stu-id="cfde8-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="cfde8-151">**Simulations d’apprentissage et analyse des performances :** Entraînez-vous et optimisez l’exécution de certaines tâches en identifiant plus efficacement les goulots d’étranglement du flux d’exécution.</span><span class="sxs-lookup"><span data-stu-id="cfde8-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="cfde8-152">**Évaluations de conception, études publicitaires et marketing :** Le suivi oculaire est un outil courant pour les recherches sur le marché lors de l’évaluation des conceptions de site Web et de produit.</span><span class="sxs-lookup"><span data-stu-id="cfde8-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluateing website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="cfde8-153">Cas d’usage supplémentaires</span><span class="sxs-lookup"><span data-stu-id="cfde8-153">Additional use cases</span></span>
- <span data-ttu-id="cfde8-154">**Jeux :** Vous avez toujours souhaité avoir des super pouvoirs ?</span><span class="sxs-lookup"><span data-stu-id="cfde8-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="cfde8-155">Voilà votre chance !</span><span class="sxs-lookup"><span data-stu-id="cfde8-155">Here's your chance!</span></span> <span data-ttu-id="cfde8-156">Vous pouvez faire en lévitation les hologrammes.</span><span class="sxs-lookup"><span data-stu-id="cfde8-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="cfde8-157">Envoyez des rayons laser avec vos yeux.</span><span class="sxs-lookup"><span data-stu-id="cfde8-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="cfde8-158">Transformez des ennemis en pierres ou figez-les.</span><span class="sxs-lookup"><span data-stu-id="cfde8-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="cfde8-159">Utilisez votre vision à rayons X pour explorer des bâtiments.</span><span class="sxs-lookup"><span data-stu-id="cfde8-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="cfde8-160">La seule limite, c’est votre imagination !</span><span class="sxs-lookup"><span data-stu-id="cfde8-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="cfde8-161">**Avatars expressifs :** Outils de suivi oculaire dans des avatars 3D plus expressifs en utilisant le suivi des yeux en direct pour animer les yeux de l’avatar qui indiquent ce que l’utilisateur examine.</span><span class="sxs-lookup"><span data-stu-id="cfde8-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live-eye tracking date to animate the avatar's eyes that indicate what the user is looking at.</span></span> <span data-ttu-id="cfde8-162">Il permet également d’accroître l’expressivité en ajoutant des clins d’œil.</span><span class="sxs-lookup"><span data-stu-id="cfde8-162">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="cfde8-163">**Entrée de texte :** Le suivi oculaire peut être utilisé comme alternative pour une entrée de texte à faible effort, en particulier lorsque la parole ou les mains sont peu pratiques à utiliser.</span><span class="sxs-lookup"><span data-stu-id="cfde8-163">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="cfde8-164">API d’eye-tracking</span><span class="sxs-lookup"><span data-stu-id="cfde8-164">Eye tracking API</span></span>
<span data-ttu-id="cfde8-165">Avant de décrire en détail les règles de conception spécifiques pour l’interaction avec le regard des yeux, nous souhaitons rapidement souligner les fonctionnalités fournies par l’API de suivi oculaire HoloLens 2 aux développeurs.</span><span class="sxs-lookup"><span data-stu-id="cfde8-165">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 Eye Tracker API provides to developers.</span></span> <span data-ttu-id="cfde8-166">Il fournit un point d’origine et une direction orientés vers l’œil, fournissant des données à environ _30 images par seconde_.</span><span class="sxs-lookup"><span data-stu-id="cfde8-166">It provides a single eye-gaze--gaze origin and direction--providing data at approximately _30 FPS_.</span></span> 

<span data-ttu-id="cfde8-167">Le point de regard prédit se trouve dans l’autorité de certification.</span><span class="sxs-lookup"><span data-stu-id="cfde8-167">The predicted eye-gaze lies within ca.</span></span> <span data-ttu-id="cfde8-168">1,0-1,5 degrés dans l’angle visuel autour de la cible réelle.</span><span class="sxs-lookup"><span data-stu-id="cfde8-168">1.0 - 1.5 degrees in visual angle around the actual target.</span></span> <span data-ttu-id="cfde8-169">Comme de légères imprécisions sont attendues, vous devez prévoir une certaine marge autour de cette valeur de limite inférieure.</span><span class="sxs-lookup"><span data-stu-id="cfde8-169">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="cfde8-170">Nous en discuterons plus en détail ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="cfde8-170">We will discuss this more below.</span></span> <span data-ttu-id="cfde8-171">Pour que l’eye-tracking fonctionne avec précision, chaque utilisateur doit effectuer un étalonnage.</span><span class="sxs-lookup"><span data-stu-id="cfde8-171">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="cfde8-172">![Taille optimale de la cible à une distance de 2 mètres](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="cfde8-172">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="cfde8-173">*Taille de cible optimale à une distance de 2 mètres*</span><span class="sxs-lookup"><span data-stu-id="cfde8-173">*Optimal target size at a 2-meter distance*</span></span>
<br>
<br>
<span data-ttu-id="cfde8-174">L' [API de suivi oculaire](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) est accessible via: 'Windows. perception. People. EyesPose'.</span><span class="sxs-lookup"><span data-stu-id="cfde8-174">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: \`Windows.Perception.People.EyesPose'.</span></span> 

## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="cfde8-175">Conseils pour la conception des regards</span><span class="sxs-lookup"><span data-stu-id="cfde8-175">Eye-gaze design guidelines</span></span>
<span data-ttu-id="cfde8-176">Créer une interaction qui tire parti d’un ciblage oculaire rapide peut être une tâche difficile.</span><span class="sxs-lookup"><span data-stu-id="cfde8-176">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="cfde8-177">Dans cette section, nous résumerons les principaux avantages et défis à prendre en compte lors de la conception de votre application.</span><span class="sxs-lookup"><span data-stu-id="cfde8-177">In this section, we summarize the key advantages and challenges to take into account when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="cfde8-178">Avantages de l’entrée en regard des yeux</span><span class="sxs-lookup"><span data-stu-id="cfde8-178">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="cfde8-179">**Pointage à haute vitesse.**</span><span class="sxs-lookup"><span data-stu-id="cfde8-179">**High speed pointing.**</span></span> <span data-ttu-id="cfde8-180">Le muscle oculaire est le muscle le plus réactif de notre corps.</span><span class="sxs-lookup"><span data-stu-id="cfde8-180">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="cfde8-181">**Faible effort.**</span><span class="sxs-lookup"><span data-stu-id="cfde8-181">**Low effort.**</span></span> <span data-ttu-id="cfde8-182">Pratiquement aucun mouvement physique n’est nécessaire.</span><span class="sxs-lookup"><span data-stu-id="cfde8-182">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="cfde8-183">**Implicite.**</span><span class="sxs-lookup"><span data-stu-id="cfde8-183">**Implicitness.**</span></span> <span data-ttu-id="cfde8-184">Souvent décrits par les utilisateurs comme «sens de lecture», les informations relatives aux mouvements oculaires d’un utilisateur permettent au système de savoir à quelle cible l’utilisateur envisage de s’impliquer.</span><span class="sxs-lookup"><span data-stu-id="cfde8-184">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="cfde8-185">**Autre canal d’entrée.**</span><span class="sxs-lookup"><span data-stu-id="cfde8-185">**Alternative input channel.**</span></span> <span data-ttu-id="cfde8-186">L’œil-point de vue peut fournir une entrée de prise en charge puissante pour les entrées de main et vocales, basées sur des années d’expérience des utilisateurs en fonction de leur coordination manuelle.</span><span class="sxs-lookup"><span data-stu-id="cfde8-186">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="cfde8-187">**Attention visuelle.**</span><span class="sxs-lookup"><span data-stu-id="cfde8-187">**Visual attention.**</span></span> <span data-ttu-id="cfde8-188">Un autre avantage important est la possibilité de déduire ce à quoi un utilisateur fait attention.</span><span class="sxs-lookup"><span data-stu-id="cfde8-188">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="cfde8-189">Cela peut aider dans différents domaines d’application, allant de l’évaluation plus efficace de conceptions différentes à l’aide d’interfaces utilisateur plus intelligentes et de signaux sociaux améliorés pour la communication à distance.</span><span class="sxs-lookup"><span data-stu-id="cfde8-189">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="cfde8-190">Pour résumer, l’utilisation de l’œil en forme de point d’entrée offre un signal contextuel rapide et sans effort.</span><span class="sxs-lookup"><span data-stu-id="cfde8-190">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="cfde8-191">Cela est particulièrement puissant lorsqu’il est combiné à d’autres entrées, telles que la *voix* et l’entrée *manuelle* , pour confirmer l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="cfde8-191">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="cfde8-192">Défis de l’entrée</span><span class="sxs-lookup"><span data-stu-id="cfde8-192">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="cfde8-193">Avec un grand nombre d’énergie, la responsabilité est importante.</span><span class="sxs-lookup"><span data-stu-id="cfde8-193">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="cfde8-194">Bien qu’il soit possible d’utiliser le point de vue des yeux pour créer des expériences utilisateur satisfaisantes, il est également important de savoir ce qu’il n’est pas judicieux de faire pour en tenir compte.</span><span class="sxs-lookup"><span data-stu-id="cfde8-194">While eye-gaze can be used to create satisfying user experiences thata makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="cfde8-195">Ce qui suit présente certains *défis* à prendre en compte, ainsi que la façon de les résoudre quand vous travaillez avec des entrées de regard:</span><span class="sxs-lookup"><span data-stu-id="cfde8-195">The following discusses some *challenges* to take into account as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="cfde8-196">**Votre regard est «Always on»** Le moment où vous ouvrez vos couvercles oculaires, vos yeux commencent que sur les choses de l’environnement.</span><span class="sxs-lookup"><span data-stu-id="cfde8-196">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="cfde8-197">En réagissant à chaque fois que vous effectuez des actions et que vous émettez accidentellement des actions, parce que vous avez examiné un peu trop de temps, cela entraînerait une insatisfaction de l’expérience.</span><span class="sxs-lookup"><span data-stu-id="cfde8-197">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="cfde8-198">C’est la raison pour laquelle nous vous recommandons de combiner le regard des yeux avec une *commande vocale*, un *mouvement manuel*, un *clic de bouton* ou un logement étendu pour déclencher la sélection d’une cible.</span><span class="sxs-lookup"><span data-stu-id="cfde8-198">This is why we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="cfde8-199">Cette solution permet également à un mode dans lequel l’utilisateur peut effectuer des recherches librement sans être submergé par le déclenchement involontaire d’un événement.</span><span class="sxs-lookup"><span data-stu-id="cfde8-199">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="cfde8-200">Ce problème doit également être pris en compte durant la conception d’une rétroaction visuelle et auditive quand l’utilisateur regarde simplement une cible.</span><span class="sxs-lookup"><span data-stu-id="cfde8-200">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="cfde8-201">Ne surchargez pas l’utilisateur avec des effets immédiats d’ouverture dans une nouvelle fenêtre ou des sons de pointage.</span><span class="sxs-lookup"><span data-stu-id="cfde8-201">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="cfde8-202">La subtilité est essentielle.</span><span class="sxs-lookup"><span data-stu-id="cfde8-202">Subtlety is key.</span></span> <span data-ttu-id="cfde8-203">Nous allons aborder plus loin certaines bonnes pratiques quand nous évoquerons les recommandations de conception.</span><span class="sxs-lookup"><span data-stu-id="cfde8-203">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="cfde8-204">**Observation et contrôle** Imaginez que vous souhaitez redresser précisément une photographie sur votre mur.</span><span class="sxs-lookup"><span data-stu-id="cfde8-204">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="cfde8-205">Vous regardez les bords de la photo et ce qui se trouve à proximité pour voir si elle est bien alignée.</span><span class="sxs-lookup"><span data-stu-id="cfde8-205">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="cfde8-206">Imaginez maintenant comment procéder lorsque vous souhaitez utiliser le point de vue de l’œil pour déplacer l’image.</span><span class="sxs-lookup"><span data-stu-id="cfde8-206">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="cfde8-207">Difficile, n’est-ce pas ?</span><span class="sxs-lookup"><span data-stu-id="cfde8-207">Difficult, isn't it?</span></span> <span data-ttu-id="cfde8-208">Cela décrit le double rôle de regard pour les entrées et les contrôles.</span><span class="sxs-lookup"><span data-stu-id="cfde8-208">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="cfde8-209">**Quitter avant de cliquer :** Pour les sélections de cibles rapides, l’étude a montré que le point de vue de l’utilisateur peut se déplacer avant de conclure un clic manuel (par exemple, un airtap).</span><span class="sxs-lookup"><span data-stu-id="cfde8-209">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="cfde8-210">Par conséquent, une attention particulière doit être accordée à la synchronisation du signal rapide oeil-regard avec une entrée de contrôle plus lente (par exemple, voix, mains, contrôleur).</span><span class="sxs-lookup"><span data-stu-id="cfde8-210">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="cfde8-211">**Petites cibles :** Savez-vous le sentiment quand vous essayez de lire du texte qui est un peu trop petit pour être lu à l’aise?</span><span class="sxs-lookup"><span data-stu-id="cfde8-211">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortable?</span></span> <span data-ttu-id="cfde8-212">Ce sentiment de stress sur vos yeux peut vous amener à vous sentir fatigué et à s’en ressentir, car vous essayez de réajuster vos yeux pour mieux vous concentrer.</span><span class="sxs-lookup"><span data-stu-id="cfde8-212">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="cfde8-213">C’est un sentiment que vous pouvez appeler dans vos utilisateurs en les forçant à sélectionner des cibles qui sont trop petites dans votre application à l’aide d’un ciblage oculaire.</span><span class="sxs-lookup"><span data-stu-id="cfde8-213">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="cfde8-214">Durant la conception, si vous souhaitez créer une expérience utilisateur agréable et confortable, nous vous recommandons de privilégier des cibles ayant un angle de vue d’au moins 2°, sinon plus de préférence.</span><span class="sxs-lookup"><span data-stu-id="cfde8-214">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="cfde8-215">**Mouvements de regard en œil irrégulier** Nos yeux effectuent des mouvements rapides de la fixation à la fixation.</span><span class="sxs-lookup"><span data-stu-id="cfde8-215">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="cfde8-216">Si vous examinez un enregistrement des mouvements oculaires, vous pouvez voir qu’ils sont irréguliers.</span><span class="sxs-lookup"><span data-stu-id="cfde8-216">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="cfde8-217">Vos yeux bougent rapidement et sautent spontanément par rapport au *suivi de la tête* ou aux *mouvements de la main*.</span><span class="sxs-lookup"><span data-stu-id="cfde8-217">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="cfde8-218">**Fiabilité du suivi :** La précision de l’eye-tracking peut se dégrader légèrement quand la lumière change, car votre œil s’adapte aux nouvelles conditions.</span><span class="sxs-lookup"><span data-stu-id="cfde8-218">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="cfde8-219">Même si cela ne doit pas nécessairement affecter la conception de votre application, car la précision doit être comprise dans la limite de 2 °, il peut être nécessaire que l’utilisateur exécute un autre étalonnage.</span><span class="sxs-lookup"><span data-stu-id="cfde8-219">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to run another calibration.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="cfde8-220">Recommandations de conception</span><span class="sxs-lookup"><span data-stu-id="cfde8-220">Design recommendations</span></span>
<span data-ttu-id="cfde8-221">La liste suivante répertorie les recommandations de conception spécifiques en fonction des avantages et des défis décrits pour les entrées de regard:</span><span class="sxs-lookup"><span data-stu-id="cfde8-221">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="cfde8-222">**Œil-point de regard! = en-tête:**</span><span class="sxs-lookup"><span data-stu-id="cfde8-222">**Eye-gaze != Head-gaze:**</span></span>
    - <span data-ttu-id="cfde8-223">**Déterminez si des mouvements oculaires rapides mais irréguliers conviennent à votre tâche de saisie :** Tandis que nos mouvements oculaires rapides et irréguliers sont très utiles pour sélectionner rapidement des cibles dans notre champ de vision, elles sont moins applicables pour les tâches qui nécessitent des trajectoires d’entrée lisses (par exemple, des annotations de dessin ou de cercle).</span><span class="sxs-lookup"><span data-stu-id="cfde8-223">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view (FoV), it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="cfde8-224">Dans ce cas, le pointage à la main ou avec la tête est préférable.</span><span class="sxs-lookup"><span data-stu-id="cfde8-224">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="cfde8-225">**Évitez de joindre un texte directement à l’oeil de l’utilisateur (par exemple, un curseur ou un curseur).**</span><span class="sxs-lookup"><span data-stu-id="cfde8-225">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="cfde8-226">Dans le cas d’un curseur, cela peut entraîner l’effet de «curseur Fleeing» en raison de légers décalages dans le signal de point de regard projeté.</span><span class="sxs-lookup"><span data-stu-id="cfde8-226">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="cfde8-227">Dans le cas d’un curseur, il peut entrer en conflit avec le double rôle de contrôle du curseur avec vos yeux, tout en souhaitant vérifier si l’objet se trouve à l’emplacement approprié.</span><span class="sxs-lookup"><span data-stu-id="cfde8-227">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="cfde8-228">Pour résumer, les utilisateurs peuvent devenir submergés et perturbés, en particulier si le signal n’est pas précis pour cet utilisateur.</span><span class="sxs-lookup"><span data-stu-id="cfde8-228">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="cfde8-229">**Combinez les yeux avec d’autres entrées:** L’intégration du suivi oculaire avec d’autres entrées, telles que les gestes manuels, les commandes vocales ou les enfoncements de bouton, offre plusieurs avantages:</span><span class="sxs-lookup"><span data-stu-id="cfde8-229">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="cfde8-230">**Permettre une observation libre :** Étant donné que le rôle principal de nos yeux est d’observer notre environnement, il est important que les utilisateurs soient autorisés à regarder sans déclencher les commentaires ou les actions (visuel, audit, etc.).</span><span class="sxs-lookup"><span data-stu-id="cfde8-230">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="cfde8-231">La combinaison du suivi oculaire et d’un autre contrôle d’entrée permet une transition sans heurts entre l’observation du suivi oculaire et les modes de contrôle d’entrée.</span><span class="sxs-lookup"><span data-stu-id="cfde8-231">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="cfde8-232">**Fournisseur de contexte puissant :** L’utilisation d’informations sur l’emplacement et le rôle de l’utilisateur lors de la mise en circulation d’une commande vocale ou de l’exécution d’un mouvement manuel permet de canaliser en toute transparence l’entrée dans le champ de la vue.</span><span class="sxs-lookup"><span data-stu-id="cfde8-232">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="cfde8-233">Exemple : « Mettre ça là » pour sélectionner et positionner rapidement et facilement un hologramme dans la scène en regardant simplement une cible et une destination.</span><span class="sxs-lookup"><span data-stu-id="cfde8-233">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="cfde8-234">**Nécessité de synchroniser les entrées multimodales (problème du « quitter avant de cliquer ») :** La combinaison rapide de mouvements oculaires avec des entrées supplémentaires plus complexes, telles que des commandes vocales longues ou des gestes de main, risque de poursuivre votre attention avant de terminer la commande d’entrée supplémentaire.</span><span class="sxs-lookup"><span data-stu-id="cfde8-234">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="cfde8-235">Ainsi, si vous créez vos propres contrôles d’entrée (mouvements des mains personnalisés, par exemple), veillez à journaliser le début de cette entrée ou sa durée approximative pour la corréler avec ce que l’utilisateur a fixé antérieurement.</span><span class="sxs-lookup"><span data-stu-id="cfde8-235">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="cfde8-236">**Rétroaction subtile pour une entrée par eye-tracking :** Il est utile de fournir des commentaires lorsqu’une cible est examinée pour indiquer que le système fonctionne comme prévu, mais doit rester discret.</span><span class="sxs-lookup"><span data-stu-id="cfde8-236">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended, but should be kept subtle.</span></span> <span data-ttu-id="cfde8-237">Cela peut inclure la fusion lente, l’in et l’extraction, les surbrillances visuelles ou l’exécution d’autres comportements de cible subtils, tels que des mouvements lents, tels que l’amélioration de la cible, pour indiquer que le système a détecté correctement que l’utilisateur regarde une cible sans interruption inutile du flux de travail actuel de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="cfde8-237">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="cfde8-238">**Évitez d’appliquer des mouvements oculaires artificiels en tant qu’entrées :** Ne forcez pas les utilisateurs à effectuer des mouvements d’oeil spécifiques (mouvements de regard) pour déclencher des actions dans votre application.</span><span class="sxs-lookup"><span data-stu-id="cfde8-238">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="cfde8-239">**Tenez compte des imprécisions :** Nous distingueons deux types d’imprécisions qui sont perceptibles pour les utilisateurs: décalage et instabilité.</span><span class="sxs-lookup"><span data-stu-id="cfde8-239">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="cfde8-240">Le moyen le plus simple de traiter un décalage consiste à fournir des cibles suffisamment volumineuses pour interagir avec.</span><span class="sxs-lookup"><span data-stu-id="cfde8-240">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="cfde8-241">Il est recommandé d’utiliser un angle visuel supérieur à 2 ° comme référence.</span><span class="sxs-lookup"><span data-stu-id="cfde8-241">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="cfde8-242">Par exemple, votre miniature est d’environ 2 ° dans l’angle visuel lorsque vous étirez votre bras.</span><span class="sxs-lookup"><span data-stu-id="cfde8-242">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="cfde8-243">Il en résulte les conseils d’aide suivants :</span><span class="sxs-lookup"><span data-stu-id="cfde8-243">This leads to the following guidance:</span></span>
    - <span data-ttu-id="cfde8-244">Ne forcez pas les utilisateurs à sélectionner des cibles minuscules.</span><span class="sxs-lookup"><span data-stu-id="cfde8-244">Do not force users to select tiny targets.</span></span> <span data-ttu-id="cfde8-245">La recherche a montré que si les cibles sont suffisamment volumineuses et que le système est bien conçu, les utilisateurs décrivent leurs interactions sans effort et magique.</span><span class="sxs-lookup"><span data-stu-id="cfde8-245">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="cfde8-246">Si les cibles deviennent trop petites, les utilisateurs décrivent l’expérience comme étant fatigante et frustrante.</span><span class="sxs-lookup"><span data-stu-id="cfde8-246">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="cfde8-247">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="cfde8-247">See also</span></span>
* [<span data-ttu-id="cfde8-248">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="cfde8-248">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="cfde8-249">Tête et œil-pointez avec le regard dans DirectX</span><span class="sxs-lookup"><span data-stu-id="cfde8-249">Head and eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="cfde8-250">Œil-point d’interfaut</span><span class="sxs-lookup"><span data-stu-id="cfde8-250">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="cfde8-251">Mouvements des mains</span><span class="sxs-lookup"><span data-stu-id="cfde8-251">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="cfde8-252">Entrée vocale</span><span class="sxs-lookup"><span data-stu-id="cfde8-252">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="cfde8-253">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="cfde8-253">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="cfde8-254">Confort</span><span class="sxs-lookup"><span data-stu-id="cfde8-254">Comfort</span></span>](comfort.md)
