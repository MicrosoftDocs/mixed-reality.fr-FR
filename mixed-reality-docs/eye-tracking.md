---
title: Suivi de le œil
description: Suivi de le œil
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Suivi des yeux, mixte réalité, entrée, surveillez les regards
ms.openlocfilehash: d41b9973ede323e842d7187becb1220ba9980a5d
ms.sourcegitcommit: 5b4292ef786447549c0199003e041ca48bb454cd
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 05/30/2019
ms.locfileid: "66402351"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="b75e5-104">Yeux sur HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="b75e5-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="b75e5-105">HoloLens 2 permet un niveau inédite de contexte et la compréhension humaine dans le Holographic expérience en fournissant aux développeurs la possibilité d’incroyable de l’utilisation d’informations sur ce que les utilisateurs regardez.</span><span class="sxs-lookup"><span data-stu-id="b75e5-105">HoloLens 2 allows for a whole new level of context and human understanding within the Holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="b75e5-106">Cette page donne un aperçu de comment les développeurs peuvent tirer profit suivi d’oeil pour différents cas d’utilisation et les solutions à prendre en compte lors de la conception d’interfaces utilisateur basées sur des regards yeux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="b75e5-107">Cas d’utilisation</span><span class="sxs-lookup"><span data-stu-id="b75e5-107">Use cases</span></span>
<span data-ttu-id="b75e5-108">Suivi de le œil permet aux applications d’effectuer le suivi de la recherche dans laquelle l’utilisateur en temps réel.</span><span class="sxs-lookup"><span data-stu-id="b75e5-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="b75e5-109">Cette section décrit certaines des utilisations potentielles et interactions nouvelle qui devient possibles avec les yeux dans la réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="b75e5-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="b75e5-110">Avant de commencer, dans l’exemple suivant nous mentionne le [Toolkit de réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) plusieurs fois car il fournit plusieurs exemples intéressantes et puissantes pour l’utilisation du suivi des yeux comme rapide et sans effort cible pris en charge des yeux sélections et faire défiler automatiquement texte selon où examine l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="b75e5-111">Intention de l’utilisateur</span><span class="sxs-lookup"><span data-stu-id="b75e5-111">User intent</span></span>    
<span data-ttu-id="b75e5-112">Plus d’informations sur l’endroit où un utilisateur examine fournit un puissant **contexte pour les autres entrées**, comme la voix, mains et contrôleurs.</span><span class="sxs-lookup"><span data-stu-id="b75e5-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="b75e5-113">Cela peut servir pour diverses tâches.</span><span class="sxs-lookup"><span data-stu-id="b75e5-113">This can be used for various tasks.</span></span>
<span data-ttu-id="b75e5-114">Par exemple, cela peut aller de rapidement et sans effort **ciblant** entre la scène en examinant un hologramme simplement et en indiquant que « select » (voir également [regards de tête et de validation](gaze-and-commit.md)) ou en disant « placez ceci... », puis qui regarde par-dessus où vous voulez placer l’hologramme et dire »... « There ».</span><span class="sxs-lookup"><span data-stu-id="b75e5-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="b75e5-115">Vous trouverez des exemples pour ce dans [Toolkit de réalité mixte - sélection de la cible pris en charge des yeux](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) et [Toolkit de réalité mixte - prise en charge des yeux le positionnement de cible](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="b75e5-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="b75e5-116">Un exemple supplémentaire pour l’intention de l’utilisateur peut inclure à l’aide des informations sur les utilisateurs ayant consulté pour améliorer l’engagement avec des agents virtuels incorporées et hologrammes interactives.</span><span class="sxs-lookup"><span data-stu-id="b75e5-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="b75e5-117">Par exemple, les agents virtuels peuvent adapter les options disponibles et leur comportement selon actuellement affiché le contenu.</span><span class="sxs-lookup"><span data-stu-id="b75e5-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="b75e5-118">Actions implicites</span><span class="sxs-lookup"><span data-stu-id="b75e5-118">Implicit actions</span></span>
<span data-ttu-id="b75e5-119">La catégorie d’actions implicites est étroitement lié à l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="b75e5-120">L’idée est que hologrammes ou éléments d’interface utilisateur réagissent de manière quelque peu instinctual qui semble ne peut-être pas encore comme vous interagissez avec le système du tout, mais plutôt que le système et l’utilisateur sont synchronisés. Par exemple, un exemple très réussi est **défilement automatique en fonction des regards yeux**.</span><span class="sxs-lookup"><span data-stu-id="b75e5-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="b75e5-121">L’idée est aussi simple : L’utilisateur lit un texte et peut simplement continuer la lecture.</span><span class="sxs-lookup"><span data-stu-id="b75e5-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="b75e5-122">Le texte progressivement déplace vers le haut informer les utilisateurs dans leurs flux de lecture.</span><span class="sxs-lookup"><span data-stu-id="b75e5-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="b75e5-123">Un aspect clé est que la vitesse de défilement s’adapte à la vitesse de lecture de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="b75e5-124">Un autre exemple est **prise en charge des yeux un zoom avant et panoramique** pour lequel l’utilisateur peut s’apparentent à vous plonger exactement vers qu’il se concentre sur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="b75e5-125">Déclencher le zoom et en contrôlant la vitesse de zoom peuvent être contrôlés par le biais de voix ou transmettre d’entrée, ce qui est importante à fournir le sentiment de contrôle et éviter de surcharger l’utilisateur (nous aborderons ces instructions de conception plus en détail ci-dessous).</span><span class="sxs-lookup"><span data-stu-id="b75e5-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="b75e5-126">Une fois qu’un zoom avant, l’utilisateur peut ensuite sans heurts suivre, par exemple, au cours d’une rue pour Explorer son voisinage simplement à l’aide de leurs regards yeux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="b75e5-127">Vous trouverez des exemples de démonstration pour ces types d’interactions dans les [Toolkit de réalité mixte – Navigation pris en charge des yeux](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) exemple.</span><span class="sxs-lookup"><span data-stu-id="b75e5-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="b75e5-128">Autres utilisations pour _actions implicites_ peuvent inclure :</span><span class="sxs-lookup"><span data-stu-id="b75e5-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="b75e5-129">**Notifications actives :** Jamais obtenir aurait ennuyé par les notifications dépilant là où vous concentraient ?</span><span class="sxs-lookup"><span data-stu-id="b75e5-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="b75e5-130">En prenant en compte dans lequel un utilisateur est actuellement attention à, vous pouvez l’améliorer !</span><span class="sxs-lookup"><span data-stu-id="b75e5-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="b75e5-131">Afficher les notifications décalée par rapport à où l’utilisateur est actuellement à limiter les distractions et automatiquement les ignorer une fois fini sa lecture.</span><span class="sxs-lookup"><span data-stu-id="b75e5-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="b75e5-132">**Hologrammes attentifs :** Hologrammes légèrement réagissent lorsque regardée.</span><span class="sxs-lookup"><span data-stu-id="b75e5-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="b75e5-133">Cela peut aller à partir des éléments d’interface utilisateur légèrement lumineux, une fleur lentement florissant a de départ compagnie virtuel garder à vous ou essayant d’éviter des regards de vos yeux après un fera prolongée.</span><span class="sxs-lookup"><span data-stu-id="b75e5-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="b75e5-134">Cela peut indiquer une idée intéressante de satisfaction dans votre application et de connectivité.</span><span class="sxs-lookup"><span data-stu-id="b75e5-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="b75e5-135">Attention de suivi</span><span class="sxs-lookup"><span data-stu-id="b75e5-135">Attention tracking</span></span>   
<span data-ttu-id="b75e5-136">Savoir où rechercher des utilisateurs à est un outil très puissant pour évaluer la facilité d’utilisation de conceptions et à identifier les problèmes de flux de travail efficace.</span><span class="sxs-lookup"><span data-stu-id="b75e5-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="b75e5-137">À ce stade, les yeux de visualisation et analytique sont déjà une pratique courante dans différents domaines d’application.</span><span class="sxs-lookup"><span data-stu-id="b75e5-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="b75e5-138">Avec 2 HoloLens, nous fournissons une nouvelle dimension à cette présentation comme hologrammes 3D peuvent être placés dans des contextes concrets et évalués en même temps que.</span><span class="sxs-lookup"><span data-stu-id="b75e5-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="b75e5-139">Le [Toolkit de réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fournit des exemples simples pour la journalisation et le chargement des données de suivi de le œil et pour savoir comment les afficher.</span><span class="sxs-lookup"><span data-stu-id="b75e5-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="b75e5-140">Autres applications dans ce domaine peuvent inclure :</span><span class="sxs-lookup"><span data-stu-id="b75e5-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="b75e5-141">**Visualisation des regards œil à distance :** Visualiser les collaborateurs à distance examinez, par exemple, vérifiez si des instructions sont correctement interprétées et suivies.</span><span class="sxs-lookup"><span data-stu-id="b75e5-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="b75e5-142">**Études de recherche d’utilisateur :** Attention suivi peut servir à Explorer la manière dont novice ou les utilisateurs experts analyser visuellement le contenu ou leur coordination yeux disponible pour les tâches complexes (par exemple, pour l’analyse des données médicales ou en exploitant des machines).</span><span class="sxs-lookup"><span data-stu-id="b75e5-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="b75e5-143">**Analyse des performances et des simulations de formation :** Entraînez-vous et optimiser l’exécution de tâches en identifiant les goulots d’étranglement plus efficacement dans le flux d’exécution.</span><span class="sxs-lookup"><span data-stu-id="b75e5-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="b75e5-144">**Concevoir des évaluations, de publicité et de recherche en marketing :** Suivi de le œil est un outil commun pour plusieurs études de marché évaluer les conceptions de site Web et de produit.</span><span class="sxs-lookup"><span data-stu-id="b75e5-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="b75e5-145">Cas d’utilisation supplémentaires</span><span class="sxs-lookup"><span data-stu-id="b75e5-145">Additional use cases</span></span>
- <span data-ttu-id="b75e5-146">**Jeux :** Avez-vous déjà souhaité avoir super-pouvoirs ?</span><span class="sxs-lookup"><span data-stu-id="b75e5-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="b75e5-147">Voici votre chance !</span><span class="sxs-lookup"><span data-stu-id="b75e5-147">Here's your chance!</span></span> <span data-ttu-id="b75e5-148">Levitate hologrammes en fixant les.</span><span class="sxs-lookup"><span data-stu-id="b75e5-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="b75e5-149">Dépanner des faisceaux laser de vos yeux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="b75e5-150">Transformer des ennemis en pierre ou figez-les !</span><span class="sxs-lookup"><span data-stu-id="b75e5-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="b75e5-151">Utilisez votre vision x-Ray pour explorer des bâtiments.</span><span class="sxs-lookup"><span data-stu-id="b75e5-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="b75e5-152">La limite est de votre imagination !</span><span class="sxs-lookup"><span data-stu-id="b75e5-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="b75e5-153">**Avatars expressifs :** Yeux contribue à la plus expressifs avatars 3D à l’aide de la date de suivi de le œil en direct pour animer les yeux de l’avatar pour indiquer que l’utilisateur est actuellement affiché.</span><span class="sxs-lookup"><span data-stu-id="b75e5-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="b75e5-154">Il ajoute également l’expressivité plus en ajoutant clins de œil et clignote.</span><span class="sxs-lookup"><span data-stu-id="b75e5-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="b75e5-155">**Entrée de texte :** Suivi de le œil utilisable comme une alternative intéressante pour l’entrée de texte de l’effort faible en particulier lors de la reconnaissance vocale ou des mains sont peu pratiques à utiliser.</span><span class="sxs-lookup"><span data-stu-id="b75e5-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="b75e5-156">API de suivi des yeux</span><span class="sxs-lookup"><span data-stu-id="b75e5-156">Eye tracking API</span></span>
<span data-ttu-id="b75e5-157">Avant d’aborder en détail les règles de conception spécifiques pour l’interaction d’OCULAIRE, nous souhaitons brièvement pointent vers les fonctionnalités qui fournit le dispositif de suivi HoloLens 2 yeux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="b75e5-158">Le [API de suivi des yeux](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) est accessible via : `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="b75e5-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="b75e5-159">Il fournit un rayon de regards yeux unique (regards origine et la direction) pour les développeurs.</span><span class="sxs-lookup"><span data-stu-id="b75e5-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="b75e5-160">Le suivi de l’oeil fournit des données sur _30 i/s_.</span><span class="sxs-lookup"><span data-stu-id="b75e5-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="b75e5-161">Les regards prédite yeux se trouve dans l’autorité de certification.</span><span class="sxs-lookup"><span data-stu-id="b75e5-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="b75e5-162">1.0-1,5 degrés visual angle autour du texte réel effectue la recherche sur la cible.</span><span class="sxs-lookup"><span data-stu-id="b75e5-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="b75e5-163">Légères imprécisions sont normalement, vous devez planifier une marge autour de cette valeur de limite inférieure.</span><span class="sxs-lookup"><span data-stu-id="b75e5-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="b75e5-164">Nous aborderons cela plus ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="b75e5-164">We will discuss this more below.</span></span> <span data-ttu-id="b75e5-165">Pour les yeux pour fonctionner correctement, chaque utilisateur est requise à passer par un œil suivi d’étalonnage de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="b75e5-166">![Taille cible optimal à distance de compteur 2](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="b75e5-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="b75e5-167">*Taille cible optimal à distance de compteur 2*</span><span class="sxs-lookup"><span data-stu-id="b75e5-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="b75e5-168">Instructions de conception yeux du pointage de regard</span><span class="sxs-lookup"><span data-stu-id="b75e5-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="b75e5-169">Création d’une interaction qui tire parti de ciblage yeux déplacement rapide peut s’avérer difficile.</span><span class="sxs-lookup"><span data-stu-id="b75e5-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="b75e5-170">Dans cette section, nous résumons les principaux avantages et les défis à prendre en compte lors de la conception de votre application.</span><span class="sxs-lookup"><span data-stu-id="b75e5-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="b75e5-171">Avantages de l’entrée des regards œil</span><span class="sxs-lookup"><span data-stu-id="b75e5-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="b75e5-172">**Haute vitesse pointe.**</span><span class="sxs-lookup"><span data-stu-id="b75e5-172">**High speed pointing.**</span></span> <span data-ttu-id="b75e5-173">Le muscle œil est le muscle réaction plus rapide dans notre corps.</span><span class="sxs-lookup"><span data-stu-id="b75e5-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="b75e5-174">**Effort faible.**</span><span class="sxs-lookup"><span data-stu-id="b75e5-174">**Low effort.**</span></span> <span data-ttu-id="b75e5-175">À peine les mouvements physiques sont nécessaires.</span><span class="sxs-lookup"><span data-stu-id="b75e5-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="b75e5-176">**Implicitness.**</span><span class="sxs-lookup"><span data-stu-id="b75e5-176">**Implicitness.**</span></span> <span data-ttu-id="b75e5-177">Souvent décrits par les utilisateurs comme « n’oubliez pas d’informations », plus d’informations sur les mouvements des yeux d’un utilisateur informe le système cible les plans utilisateur de s’engager avec.</span><span class="sxs-lookup"><span data-stu-id="b75e5-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="b75e5-178">**Autre canal d’entrée.**</span><span class="sxs-lookup"><span data-stu-id="b75e5-178">**Alternative input channel.**</span></span> <span data-ttu-id="b75e5-179">Les regards yeux peuvent fournir une entrée de la prise en charge puissante pour la main et la voix d’entrée création sur des années d’expérience à partir des utilisateurs en fonction de leur coordination main noir.</span><span class="sxs-lookup"><span data-stu-id="b75e5-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="b75e5-180">**Attention visuelle.**</span><span class="sxs-lookup"><span data-stu-id="b75e5-180">**Visual attention.**</span></span> <span data-ttu-id="b75e5-181">Un autre avantage important est la possibilité de déduire ce que l’utilisateur s’intéresse aux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="b75e5-182">Cela peut être utile dans différents domaines d’application en allant plus efficacement l’évaluation des conceptions différentes pour cadrer dans les Interfaces utilisateur plus intelligentes et améliorée des signaux sociales pour la communication à distance.</span><span class="sxs-lookup"><span data-stu-id="b75e5-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="b75e5-183">En bref, à l’aide du pointage de regard yeux comme une entrée offre potentiellement un signal contextuel rapide et sans effort - c’est particulièrement puissant en combinaison avec d’autres entrées comme *voix* et *manuelle* entrée Confirmer l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="b75e5-184">Défis de œil les regards en tant qu’entrée</span><span class="sxs-lookup"><span data-stu-id="b75e5-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="b75e5-185">Beaucoup d’énergie, s’accompagne un grand nombre de responsabilité : Si les regards yeux peuvent être utilisé pour créer des expériences utilisateur magique une sensation un super héros, il est également important de savoir qu’il n’est pas judicieux au compte pour ce en conséquence.</span><span class="sxs-lookup"><span data-stu-id="b75e5-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="b75e5-186">Dans l’exemple suivant, nous aborderons certaines *défis* à prendre en compte et comment les résoudre lorsque vous travaillez avec une entrée du pointage de regard œil :</span><span class="sxs-lookup"><span data-stu-id="b75e5-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="b75e5-187">**Votre regard yeux est « always on »** au moment où vous ouvrez votre couvercles yeux, vos yeux démarrer fixation des choses dans votre environnement.</span><span class="sxs-lookup"><span data-stu-id="b75e5-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="b75e5-188">Réagir à chaque rechercher marque et émission d’actions potentiellement accidentellement, car vous avez examiné quelque chose pour trop longtemps entraînerait une expérience terrible !</span><span class="sxs-lookup"><span data-stu-id="b75e5-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="b75e5-189">C’est pourquoi nous recommandons combinant des regards yeux avec un *commande vocale*, *main mouvement*, *clic* ou la durée d’affichage étendue pour déclencher la sélection d’une cible.</span><span class="sxs-lookup"><span data-stu-id="b75e5-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="b75e5-190">Cette solution permet également d’un mode dans lequel l’utilisateur peut librement cherchez sans le sentiment écrasant de déclenchement involontaire d’un élément.</span><span class="sxs-lookup"><span data-stu-id="b75e5-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="b75e5-191">Ce problème doit également prendre en compte lors de la conception visuelle et auditive commentaires lorsque vous consultez simplement une cible.</span><span class="sxs-lookup"><span data-stu-id="b75e5-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="b75e5-192">Ne pas surcharger les effets immédiats pop-out à l’utilisateur ou pointez les sons.</span><span class="sxs-lookup"><span data-stu-id="b75e5-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="b75e5-193">Subtilité est clé !</span><span class="sxs-lookup"><span data-stu-id="b75e5-193">Subtlety is key!</span></span> <span data-ttu-id="b75e5-194">Lorsque nous parlons de recommandations de conception, nous allons décrire quelques-unes des meilleures pratiques pour cet élément ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="b75e5-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="b75e5-195">**Observation et contrôle** Imaginez que vous souhaitez aligner précisément une photo sur votre mur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="b75e5-196">Vous examinez ses bordures et ses environs pour voir si elle s’aligne également.</span><span class="sxs-lookup"><span data-stu-id="b75e5-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="b75e5-197">Imaginez maintenant comment cela lorsqu’en même temps que vous souhaitez utiliser votre regard œil en tant qu’entrée pour déplacer l’image.</span><span class="sxs-lookup"><span data-stu-id="b75e5-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="b75e5-198">Difficile, non ?</span><span class="sxs-lookup"><span data-stu-id="b75e5-198">Difficult, isn't it?</span></span> <span data-ttu-id="b75e5-199">Cette section décrit le rôle double des regards d’yeux lorsque cela est nécessaire à la fois pour l’entrée et de contrôle.</span><span class="sxs-lookup"><span data-stu-id="b75e5-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="b75e5-200">**Laissez cette option avant de cliquer sur :** Pour les sélections de cible rapide, des études ont montré que regards des yeux d’un utilisateur peut passer avant de conclure un manuel, cliquez sur (par exemple, un airtap).</span><span class="sxs-lookup"><span data-stu-id="b75e5-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="b75e5-201">Par conséquent, une attention particulière doit être accordée à synchroniser le signal de regards œil rapide avec l’entrée de contrôle plus lente (par exemple, voix, mains, contrôleur).</span><span class="sxs-lookup"><span data-stu-id="b75e5-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="b75e5-202">**Petite cibles :** Connaissez-vous le sentiment lorsque vous tentez de lire le texte qui est juste un peu trop petit pour lire correctement ?</span><span class="sxs-lookup"><span data-stu-id="b75e5-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="b75e5-203">Ce sentiment de surcharger les yeux qui provoquent vous se sentir fatigué et hors étant donné que vous essayez de réajuster les yeux de mieux se concentrer ?</span><span class="sxs-lookup"><span data-stu-id="b75e5-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="b75e5-204">Il s’agit d’un sentiment que vous pouvez appeler vos utilisateurs lorsque les forcer à sélectionner les cibles trop petites dans votre application utilisant le ciblage des yeux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="b75e5-205">Pour votre conception, pour créer une expérience agréable et à l’aise pour vos utilisateurs, nous recommandons que les cibles doivent être au moins 2° dans l’angle visual, de préférence supérieure.</span><span class="sxs-lookup"><span data-stu-id="b75e5-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="b75e5-206">**En drapeau mouvements des regards yeux** nos yeux effectuer des mouvements rapides de fixation à par fixation.</span><span class="sxs-lookup"><span data-stu-id="b75e5-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="b75e5-207">Si vous examinez les chemins d’accès de l’analyse des mouvements des yeux enregistrée, vous pouvez voir leur apparence déséquilibrées.</span><span class="sxs-lookup"><span data-stu-id="b75e5-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="b75e5-208">Les yeux déplacement rapidement et de sauts spontanés par rapport à *regards principal* ou *les mouvements de main*.</span><span class="sxs-lookup"><span data-stu-id="b75e5-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="b75e5-209">**Fiabilité de suivi :** Suivi de précision de le œil peut dégrader un peu lors de la modification de lumière comme vos yeux adapter aux nouvelles conditions.</span><span class="sxs-lookup"><span data-stu-id="b75e5-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="b75e5-210">Bien que cela ne doit pas affecter nécessairement la conception de votre application, comme la précision ne doit pas dépasser la limitation à 2° mentionnée ci-dessus.</span><span class="sxs-lookup"><span data-stu-id="b75e5-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="b75e5-211">Cela peut signifier que l’utilisateur doit s’exécuter une autre d’étalonnage.</span><span class="sxs-lookup"><span data-stu-id="b75e5-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="b75e5-212">Recommandations de conception</span><span class="sxs-lookup"><span data-stu-id="b75e5-212">Design recommendations</span></span>
<span data-ttu-id="b75e5-213">Dans l’exemple suivant, nous indiquons les recommandations de conception spécifiques basées sur les avantages décrits et défis pour les yeux les regards entrée :</span><span class="sxs-lookup"><span data-stu-id="b75e5-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="b75e5-214">**Les regards œil ! = regards de tête :**</span><span class="sxs-lookup"><span data-stu-id="b75e5-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="b75e5-215">**Prenez en compte si rapide encore yeux déséquilibrées mouvements ajuster votre tâche d’entrée :** Bien que notre mouvements d’oeil rapide et déséquilibrées soient très utile de sélectionner rapidement les cibles sur notre champ de vision, il est moins pertinents pour les tâches qui nécessitent des trajectoires lisses d’entrée (par exemple, pour le dessin ou tournant annotations).</span><span class="sxs-lookup"><span data-stu-id="b75e5-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="b75e5-216">Dans ce cas, manuellement ou head pointant doit être préféré.</span><span class="sxs-lookup"><span data-stu-id="b75e5-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="b75e5-217">**Évitez de quelque chose association directe au regard d’yeux de l’utilisateur (par exemple, un slider ou un curseur).**</span><span class="sxs-lookup"><span data-stu-id="b75e5-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="b75e5-218">Dans le cas d’un curseur, cela peut entraîner l’effet « fuite curseur » en raison des décalages légères dans le signal de regards yeux projetée.</span><span class="sxs-lookup"><span data-stu-id="b75e5-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="b75e5-219">Dans le cas d’un curseur, il est en conflit avec le rôle de double de contrôler le curseur avec les yeux tout en voulant également vérifier si l’objet est à l’emplacement correct.</span><span class="sxs-lookup"><span data-stu-id="b75e5-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="b75e5-220">En bref, les utilisateurs peuvent rapidement avoir l’impression submergée et gênés, en particulier si le signal est imprécis pour cet utilisateur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="b75e5-221">**Combiner les yeux regards avec les autres entrées :** L’intégration de suivi des yeux avec les autres entrées, telles que les mouvements de main, les commandes vocales ou appuie sur le bouton, a plusieurs avantages :</span><span class="sxs-lookup"><span data-stu-id="b75e5-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="b75e5-222">**Autoriser l’observation gratuitement :** Étant donné que le rôle principal de nos yeux consiste à observer notre environnement, il est important de permettre aux utilisateurs d’observer cet onglet sans déclencher une (visuels, auditifs,...) des commentaires ou des actions.</span><span class="sxs-lookup"><span data-stu-id="b75e5-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="b75e5-223">Permet de combiner ET avec un autre contrôle d’entrée pour la transition sans heurts entre les modes de contrôle d’entrée et de d’observation ET.</span><span class="sxs-lookup"><span data-stu-id="b75e5-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="b75e5-224">**Fournisseur de contexte puissantes :** À l’aide d’informations sur où l’utilisateur consulte lors de la mise en circulation d’une commande vocale ou effectuant un mouvement de la main permet d’acheminement sans effort de l’entrée dans le champ de vision.</span><span class="sxs-lookup"><span data-stu-id="b75e5-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="b75e5-225">Par exemple : « Put qui il » rapidement et aisément sélectionner et positionner un hologramme entre la scène en consultant simplement à une cible et une destination.</span><span class="sxs-lookup"><span data-stu-id="b75e5-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="b75e5-226">**Nécessaire pour la synchronisation des entrées multimodales (« ne pas avant de cliquer sur » problème) :** Combinant les mouvements rapides des yeux avec des entrées supplémentaires plus complexes (par exemple, les commandes vocales long ou les mouvements de main) assume le risque de déplacement avec votre regard yeux avant la fin de la commande d’entrée supplémentaire.</span><span class="sxs-lookup"><span data-stu-id="b75e5-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="b75e5-227">Par conséquent, si vous créez vos propres contrôles d’entrée (par exemple, les mouvements de main), veillez à ouvrir une session l’apparition de cette durée d’entrée ou approximative à corréler avec qu’un utilisateur avait fixated sur dans le passé.</span><span class="sxs-lookup"><span data-stu-id="b75e5-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="b75e5-228">**Commentaires subtiles pour l’entrée de suivi de le œil :** Il est utile fournir des commentaires si une cible est examinée (pour indiquer que le système fonctionne comme prévu) mais doit être conservée subtile.</span><span class="sxs-lookup"><span data-stu-id="b75e5-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="b75e5-229">Cela peut inclure une fusion lentement en entrée/sortie mises en surbrillance visual ou effectuer d’autres comportements cible subtiles, telles que les mouvements lente (par exemple, légèrement augmentant ainsi la cible) pour indiquer que le système correctement a détecté que l’utilisateur consulte une cible, toutefois, sans inutilement interrompre le flux de travail actuel de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="b75e5-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="b75e5-230">**Éviter l’application des mouvements des yeux non naturelles en tant qu’entrée :** Ne forcez pas aux utilisateurs d’effectuer des mouvements des yeux spécifique (mouvements regards) pour déclencher des actions dans votre application.</span><span class="sxs-lookup"><span data-stu-id="b75e5-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="b75e5-231">**Compte pour enregistrer les imprécisions dans :** Nous faisons la distinction deux types d’imprécisions qui sont visibles pour les utilisateurs : Décalage et d’instabilité.</span><span class="sxs-lookup"><span data-stu-id="b75e5-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="b75e5-232">Le moyen le plus simple aux décalages de l’adresse est de fournir des cibles suffisamment grands pour interagir avec (2° > dans l’angle visual – en tant que référence : votre miniature est environ 2° dans l’angle visual lorsque vous agrandissez votre arm (1)).</span><span class="sxs-lookup"><span data-stu-id="b75e5-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="b75e5-233">Il en résulte les conseils suivants :</span><span class="sxs-lookup"><span data-stu-id="b75e5-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="b75e5-234">Ne forcez pas aux utilisateurs de sélectionner des cibles minuscules : Research a montré que si les cibles sont suffisamment grandes (et le système est bien conçu), les utilisateurs décrivent l’interaction sans effort et magique.</span><span class="sxs-lookup"><span data-stu-id="b75e5-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="b75e5-235">Si les cibles deviennent trop petites, les utilisateurs décrivent l’expérience comme fatigante et frustrante.</span><span class="sxs-lookup"><span data-stu-id="b75e5-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
    
## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="b75e5-236">Instructions de conception yeux du pointage de regard</span><span class="sxs-lookup"><span data-stu-id="b75e5-236">Eye gaze design guidelines</span></span>

<span data-ttu-id="b75e5-237">Avec 2 HoloLens, nous avons l’occasion idéale pour améliorer les regards & validation plus rapide et plus à l’aise en utilisant des regards de œil au lieu de regards principal.</span><span class="sxs-lookup"><span data-stu-id="b75e5-237">With HoloLens 2, we have the great opportunity to make gaze & commit faster and more comfortable by using eye gaze instead of head gaze.</span></span> <span data-ttu-id="b75e5-238">Toutefois, les regards yeux se comportement différemment de regards principal d’une certaine façon et, par conséquent, est fourni avec un nombre de défis uniques.</span><span class="sxs-lookup"><span data-stu-id="b75e5-238">However, eye gaze behaves very differently to head gaze in certain ways and hence comes with a number of unique challenges.</span></span> <span data-ttu-id="b75e5-239">Dans règles de conception les regards yeux, nous résumons les avantages et les défis à prendre en compte lorsque vous utilisez le suivi des yeux comme un moyen d’entrée dans votre application HOLOGRAPHIQUE.</span><span class="sxs-lookup"><span data-stu-id="b75e5-239">In Eye Gaze Design Guidelines, we summarize general advantages and challenges to take into account when using eye tracking as an input medium in your holographic app.</span></span> <span data-ttu-id="b75e5-240">Dans cette section, nous nous concentrons sur les considérations de conception spécifiques pour les regards yeux & validation.</span><span class="sxs-lookup"><span data-stu-id="b75e5-240">In this section, we focus on the specific design considerations for eye gaze & commit.</span></span> <span data-ttu-id="b75e5-241">Tout d’abord, nos yeux extrêmement vite et est donc idéales au ciblage rapidement sur la vue.</span><span class="sxs-lookup"><span data-stu-id="b75e5-241">First, our eyes move incredibly fast and thus are great at quickly targeting across the view.</span></span> <span data-ttu-id="b75e5-242">Cela rend les yeux utilisation idéal pour les regards rapide & Valider les actions en particulier lorsqu’elles sont combinées avec des validations rapides comme un appui en l’air ou bouton press.</span><span class="sxs-lookup"><span data-stu-id="b75e5-242">This makes eye gaze ideal for quick gaze & commit actions especially when combined with fast commits such as an air-tap or button press.</span></span>

<span data-ttu-id="b75e5-243">Ne pas afficher un curseur : S’il est presque impossible d’interagir sans un curseur lors de l’utilisation de tête les regards, le curseur se transforme rapidement parasites et agaçante lors de l’utilisation du pointage de regard yeux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-243">Do not show a cursor: While it is nearly impossible to interact without a cursor when using head gaze, the cursor becomes quickly distracting and annoying when using eye gaze.</span></span> <span data-ttu-id="b75e5-244">Au lieu d’utiliser un curseur pour informer l’utilisateur si le suivi de le œil fonctionne et a correctement détecté actuellement consultés sur la cible, visual subtiles utilisation met en évidence (plus de détails ci-dessous).</span><span class="sxs-lookup"><span data-stu-id="b75e5-244">Instead of relying on a cursor to inform the user whether eye tracking is working and has correctly detected the currently looked at target, use subtle visual highlights (more details below).</span></span>

<span data-ttu-id="b75e5-245">À tout prix des commentaires subtiles pointage combinées : Ce qui paraît excellent retour visuel pour les regards principal peut entraîner une terrible, écrasant expériences à l’aide du pointage de regard yeux.</span><span class="sxs-lookup"><span data-stu-id="b75e5-245">Strive for subtle blended hover feedback: What seems great visual feedback for head gaze can result in terrible, overwhelming experiences using eye gaze.</span></span> <span data-ttu-id="b75e5-246">N’oubliez pas que les yeux sont extrêmement rapides, darting rapidement entre les points de votre champ de vision.</span><span class="sxs-lookup"><span data-stu-id="b75e5-246">Remember that your eyes are enormously fast, quickly darting across points in your field-of-view.</span></span> <span data-ttu-id="b75e5-247">Commentaires flickery peuvent entraîner des modifications de mise en surbrillance soudaine rapide (activé/désactivé) lors de la recherche.</span><span class="sxs-lookup"><span data-stu-id="b75e5-247">Quick sudden highlight changes (on/off) may result in flickery feedback when looking around.</span></span> <span data-ttu-id="b75e5-248">Par conséquent, lorsque vous fournissez des commentaires de pointage, nous vous recommandons d’utiliser une mise en surbrillance correctement fusionnés dans (et fusionnée à la sortie lors de la recherche de suite).</span><span class="sxs-lookup"><span data-stu-id="b75e5-248">So, when providing hover feedback, we recommend using a smoothly blended-in highlight (and blended-out when looking away).</span></span> <span data-ttu-id="b75e5-249">Cela signifie que dans un premier temps vous à peine remarquerait les commentaires lorsque vous examinez une cible.</span><span class="sxs-lookup"><span data-stu-id="b75e5-249">This means that at first you would barely notice the feedback when looking at a target.</span></span> <span data-ttu-id="b75e5-250">Au cours de 500 à 1000 ms, la mise en surbrillance augmenterait en intensité.</span><span class="sxs-lookup"><span data-stu-id="b75e5-250">Over the course of 500-1000 ms the highlight would increase in intensity.</span></span> <span data-ttu-id="b75e5-251">Tandis que les utilisateurs novices peuvent continuer à chercher à la cible pour vous assurer que le système a déterminé correctement la cible ayant le focus, les utilisateurs expérimentés pourraient rapidement les regards & sont validées sans attendre que les commentaires sont à son intensité complète.</span><span class="sxs-lookup"><span data-stu-id="b75e5-251">While novice users could keep looking at the target to ensure that the system has correctly determined the focused target, expert users could quickly gaze & commit without waiting until the feedback is at its full intensity.</span></span> <span data-ttu-id="b75e5-252">En outre, nous vous recommandons également d’à l’aide de blend montée lorsque atténuant progressivement les commentaires de pointage.</span><span class="sxs-lookup"><span data-stu-id="b75e5-252">In addition, we also recommend using a blend-out when fading out the hover feedback.</span></span> <span data-ttu-id="b75e5-253">Research a montré que les modifications rapides de mouvement et contraste sont très visibles dans votre vision périphérique (par conséquent, la zone de votre champ visuel où vous cherchez pas).</span><span class="sxs-lookup"><span data-stu-id="b75e5-253">Research has shown that quick motion and contrast changes are very noticeable in your peripheral vision (so, the area of your visual field where you are not looking).</span></span> <span data-ttu-id="b75e5-254">Le fondu ne doit pas être lentes en tant que blend dans.</span><span class="sxs-lookup"><span data-stu-id="b75e5-254">The fade-out doesn't have to be as slow as the blend-in.</span></span> <span data-ttu-id="b75e5-255">Cela est essentiel uniquement lorsque vous avez un contraste élevé ou des modifications de couleur pour votre mise en surbrillance.</span><span class="sxs-lookup"><span data-stu-id="b75e5-255">This is only critical when you have high contrast or color changes for your highlight.</span></span> <span data-ttu-id="b75e5-256">Si les commentaires de pointage étaient assez subtile pour commencer, vous ne constaterez certainement une différence.</span><span class="sxs-lookup"><span data-stu-id="b75e5-256">If the hover feedback was pretty subtle to begin with, you probably won't notice a difference.</span></span>

<span data-ttu-id="b75e5-257">Rechercher des signaux regards et validation de synchronisation : La synchronisation des signaux d’entrée est peut-être moins difficile pour les regards simple & validation, par conséquent, ne vous inquiétez pas !</span><span class="sxs-lookup"><span data-stu-id="b75e5-257">Look out for synchronizing gaze and commit signals: The synchronization of input signals may be less of a challenge for simple gaze & commit, so, don't worry!</span></span> <span data-ttu-id="b75e5-258">Il est quelque chose à prendre en compte au cas où vous souhaitez utiliser des actions de validation plus complexes que qui peut impliquer des commandes vocales long ou mouvements de main compliqué.</span><span class="sxs-lookup"><span data-stu-id="b75e5-258">It is something to look out for in case you want to use more complicated commit actions though that may involve long voice commands or complicated hand gestures.</span></span> <span data-ttu-id="b75e5-259">Imaginez que vous examinez cible et prononcez une commande longue vocale.</span><span class="sxs-lookup"><span data-stu-id="b75e5-259">Imagine you look at target and utter a long voice command.</span></span> <span data-ttu-id="b75e5-260">Prise en compte l’heure à laquelle vous avez besoin de parler et l’heure à laquelle le système nécessaires pour détecter ce que vous l’avez dit, votre regard yeux est généralement long passé à une nouvelle cible dans la scène.</span><span class="sxs-lookup"><span data-stu-id="b75e5-260">Taken into account the time that you needed to speak and the time that the system needed to detect what you said, your eye gaze has usually long moved on to some new target in the scene.</span></span> <span data-ttu-id="b75e5-261">Par conséquent, apportez vos utilisateurs qu’ils peuvent pas besoin de continuer à chercher à une cible jusqu'à ce que la commande a été reconnue ou gérer l’entrée de manière à déterminer le début de la commande et ce que l’utilisateur avait été regardez à l’époque.</span><span class="sxs-lookup"><span data-stu-id="b75e5-261">Hence, either make your users aware that they may need to keep looking at a target until the command has been recognized or handle the input in a way to determine the onset of the command and what the user had been looking at back then.</span></span>

## <a name="see-also"></a><span data-ttu-id="b75e5-262">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="b75e5-262">See also</span></span>
* [<span data-ttu-id="b75e5-263">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="b75e5-263">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="b75e5-264">Mouvements</span><span class="sxs-lookup"><span data-stu-id="b75e5-264">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="b75e5-265">Commander avec la voix</span><span class="sxs-lookup"><span data-stu-id="b75e5-265">Voice commanding</span></span>](voice-design.md)
* [<span data-ttu-id="b75e5-266">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="b75e5-266">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="b75e5-267">Confort</span><span class="sxs-lookup"><span data-stu-id="b75e5-267">Comfort</span></span>](comfort.md)
