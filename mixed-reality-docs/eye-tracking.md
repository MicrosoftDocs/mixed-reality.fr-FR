---
title: Eye-tracking
description: HoloLens 2 permet d’accéder à un nouveau niveau de compréhension contextuelle et humaine au sein de l’expérience holographique en offrant aux développeurs la capacité d’utiliser des informations sur ce que les utilisateurs regardent.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Suivi oculaire, réalité mixte, entrée, point de regard, étalonnage
ms.openlocfilehash: 60de5ceb9f55ca7e2f74856af9bd75567763e382
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441117"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="bae6b-104">Eye-tracking sur HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="bae6b-104">Eye tracking on HoloLens 2</span></span>

![Démonstration du suivi oculaire dans MRTK](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="bae6b-106">HoloLens 2 permet d’accéder à un nouveau niveau de compréhension contextuelle et humaine au sein de l’expérience holographique en offrant aux développeurs la capacité d’utiliser des informations sur ce que les utilisateurs regardent.</span><span class="sxs-lookup"><span data-stu-id="bae6b-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="bae6b-107">Cette page fournit une vue d’ensemble de cette nouvelle fonctionnalité destinée aux développeurs et aux concepteurs sur la façon dont ils peuvent tirer parti du suivi oculaire pour divers cas d’usage et des conseils de base pour les développeurs.</span><span class="sxs-lookup"><span data-stu-id="bae6b-107">This page provides an overview of this new capability to developers and designers on how they can benefit from eye tracking for various use cases and basic developer guidance.</span></span> 


## <a name="calibration"></a><span data-ttu-id="bae6b-108">Auto</span><span class="sxs-lookup"><span data-stu-id="bae6b-108">Calibration</span></span> 
<span data-ttu-id="bae6b-109">Pour que le suivi des yeux fonctionne correctement, chaque utilisateur doit passer par un [étalonnage d’utilisateur de suivi oculaire](calibration.md) pour lequel l’utilisateur doit examiner un ensemble de cibles holographiques.</span><span class="sxs-lookup"><span data-stu-id="bae6b-109">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="bae6b-110">Cela permet à l’appareil d’ajuster le système pour une expérience d’affichage plus confortable et de meilleure qualité pour l’utilisateur et pour garantir un suivi visuel précis en même temps.</span><span class="sxs-lookup"><span data-stu-id="bae6b-110">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="bae6b-111">Le suivi oculaire doit fonctionner pour la plupart des utilisateurs, mais dans de rares cas, un utilisateur peut ne pas être en mesure de l’étalonner correctement.</span><span class="sxs-lookup"><span data-stu-id="bae6b-111">Eye tracking should work for most users, but there are rare cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="bae6b-112">Pour en savoir plus sur l’étalonnage et sur la façon de garantir une expérience sans heurts, consultez notre page d’étalonnage de l' [utilisateur de suivi oculaire](calibration.md) .</span><span class="sxs-lookup"><span data-stu-id="bae6b-112">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>


## <a name="device-support"></a><span data-ttu-id="bae6b-113">Périphériques pris en charge</span><span class="sxs-lookup"><span data-stu-id="bae6b-113">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="bae6b-114"><strong>Fonctionnalité</strong></span><span class="sxs-lookup"><span data-stu-id="bae6b-114"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="bae6b-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1ère génération)</strong></a></span><span class="sxs-lookup"><span data-stu-id="bae6b-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="bae6b-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="bae6b-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="bae6b-117"><a href="immersive-headset-hardware-details.md"><strong>Casques immersifs</strong></a></span><span class="sxs-lookup"><span data-stu-id="bae6b-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="bae6b-118">Œil-point de regard</span><span class="sxs-lookup"><span data-stu-id="bae6b-118">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="bae6b-119">✔️</span><span class="sxs-lookup"><span data-stu-id="bae6b-119">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="bae6b-120">Données de suivi oculaire disponibles</span><span class="sxs-lookup"><span data-stu-id="bae6b-120">Available eye tracking data</span></span>
<span data-ttu-id="bae6b-121">Avant de passer en revue les cas d’utilisation spécifiques pour les entrées de regard oculaire, nous souhaitons rapidement souligner les fonctionnalités fournies par l' [API de suivi oculaire](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="bae6b-121">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="bae6b-122">Les développeurs accèdent à un seul point d’accès en regard (origine du regard et direction) à environ _30 i/s (30 Hz)_ .</span><span class="sxs-lookup"><span data-stu-id="bae6b-122">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="bae6b-123">Pour plus d’informations sur la façon d’accéder aux données de suivi oculaire, reportez-vous à nos guides pour développeurs sur l’utilisation de la fonction [Eye-pointer](gaze-in-directx.md) dans le regard sur [Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="bae6b-123">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="bae6b-124">Le point de regard prédit est approximativement de 1,5 degrés d’angle visuel autour de la cible réelle (Voir l’illustration ci-dessous).</span><span class="sxs-lookup"><span data-stu-id="bae6b-124">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="bae6b-125">Les développeurs doivent prévoir une marge autour de cette valeur limite inférieure (par exemple, 2,0-3,0 degrés peut se traduire par une expérience bien plus confortable).</span><span class="sxs-lookup"><span data-stu-id="bae6b-125">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="bae6b-126">Nous verrons comment traiter la sélection de petites cibles plus en détail ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="bae6b-126">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="bae6b-127">Pour que l’eye-tracking fonctionne avec précision, chaque utilisateur doit effectuer un étalonnage.</span><span class="sxs-lookup"><span data-stu-id="bae6b-127">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="bae6b-128">![Taille optimale de la cible à une distance de 2 mètres](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="bae6b-128">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="bae6b-129">*Taille de cible optimale à une distance de 2 mètres*</span><span class="sxs-lookup"><span data-stu-id="bae6b-129">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="bae6b-130">Cas d’utilisation</span><span class="sxs-lookup"><span data-stu-id="bae6b-130">Use cases</span></span>
<span data-ttu-id="bae6b-131">L’eye-tracking permet aux applications de savoir où l’utilisateur regarde en temps réel.</span><span class="sxs-lookup"><span data-stu-id="bae6b-131">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="bae6b-132">Les cas d’usage suivants décrivent certaines interactions possibles avec le suivi oculaire sur HoloLens 2 en réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="bae6b-132">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="bae6b-133">Veuillez noter que ces cas d’utilisation ne font pas encore partie de l’expérience d’interpréteur de commandes holographique (c’est-à-dire, l’interface que vous voyez lorsque vous démarrez votre HoloLens 2).</span><span class="sxs-lookup"><span data-stu-id="bae6b-133">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="bae6b-134">Vous pouvez essayer certaines d’entre elles dans la [boîte à outils de la réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) , qui fournit plusieurs exemples intéressants et puissants pour l’utilisation du suivi oculaire, tels que les sélections de cibles rapides et faciles à utiliser par l’œil, ainsi que le défilement automatique dans le texte. sur ce que l’utilisateur examine.</span><span class="sxs-lookup"><span data-stu-id="bae6b-134">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="bae6b-135">Intention de l’utilisateur</span><span class="sxs-lookup"><span data-stu-id="bae6b-135">User intent</span></span>    
<span data-ttu-id="bae6b-136">Des informations sur l’emplacement et le rôle d’un utilisateur fournissent un **contexte puissant pour d’autres entrées**, telles que la voix, les mains et les contrôleurs.</span><span class="sxs-lookup"><span data-stu-id="bae6b-136">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="bae6b-137">Cela peut être utile pour diverses tâches.</span><span class="sxs-lookup"><span data-stu-id="bae6b-137">This can be used for various tasks.</span></span>
<span data-ttu-id="bae6b-138">Par exemple, cette opération peut être effectuée rapidement et facilement **sur la** scène en regardant simplement un hologramme et en disant *« Sélectionner »* (voir également le point d’interrogation et de [validation](gaze-and-commit.md)) ou en disant *« Placer cela... »* , puis en consultant l’emplacement où l’utilisateur veut placer l’hologramme et indiquer *«... là»* .</span><span class="sxs-lookup"><span data-stu-id="bae6b-138">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="bae6b-139">Vous trouverez des exemples à ce sujet dans [Mixed Reality Toolkit - Sélection d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) et [Mixed Reality Toolkit - Positionnement d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="bae6b-139">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="bae6b-140">En outre, un exemple d’intention de l’utilisateur peut inclure des informations sur ce que les utilisateurs cherchent pour améliorer l’engagement avec des agents virtuels et des hologrammes interactifs.</span><span class="sxs-lookup"><span data-stu-id="bae6b-140">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="bae6b-141">Par exemple, les agents virtuels peuvent adapter les options disponibles et leur comportement en fonction du contenu actuellement affiché.</span><span class="sxs-lookup"><span data-stu-id="bae6b-141">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="bae6b-142">Actions implicites</span><span class="sxs-lookup"><span data-stu-id="bae6b-142">Implicit actions</span></span>
<span data-ttu-id="bae6b-143">La catégorie des actions implicites est étroitement liée à l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="bae6b-143">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="bae6b-144">L’idée est que les hologrammes ou les éléments d’interface utilisateur réagissent de manière instinctuale, qui peut ne pas avoir l’impression que l’utilisateur interagit avec le système, mais plutôt que le système et l’utilisateur sont synchronisés. Par exemple, le **défilement automatique orienté vers le regard** de l’utilisateur peut lire un texte long qui commence automatiquement à faire défiler une fois que l’utilisateur accède au bas de la zone de texte pour que l’utilisateur reste dans le sens de la lecture sans soulever de doigt.</span><span class="sxs-lookup"><span data-stu-id="bae6b-144">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="bae6b-145">Un aspect clé de cela est que la vitesse de défilement s’adapte à la vitesse de lecture de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="bae6b-145">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="bae6b-146">Un autre exemple est un **Zoom et un panoramique pris en charge par l’œil,** où l’utilisateur peut sembler se plonger exactement sur ce qu’il est concentré.</span><span class="sxs-lookup"><span data-stu-id="bae6b-146">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="bae6b-147">Le déclenchement du zoom et du contrôle de la vitesse de zoom peut être contrôlé par des entrées vocales ou de la main, ce qui est important pour fournir à l’utilisateur le sentiment de contrôle tout en évitant d’être submergé.</span><span class="sxs-lookup"><span data-stu-id="bae6b-147">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="bae6b-148">Nous parlerons de ces considérations de conception plus en détail ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="bae6b-148">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="bae6b-149">Une fois le zoom avant effectué, l’utilisateur peut suivre facilement, par exemple, le cours d’une rue pour explorer son voisinage en utilisant simplement son regard.</span><span class="sxs-lookup"><span data-stu-id="bae6b-149">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="bae6b-150">Vous trouverez des démonstrations de ces types d’interaction dans l’exemple [Mixed Reality Toolkit - Navigation à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="bae6b-150">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="bae6b-151">Il existe d’autres cas d’usage supplémentaires pour les _actions implicites_ :</span><span class="sxs-lookup"><span data-stu-id="bae6b-151">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="bae6b-152">**Notifications intelligentes :** Vous vous êtes-vous en désen être informé par des notifications qui se trouvent en haut de la recherche ?</span><span class="sxs-lookup"><span data-stu-id="bae6b-152">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="bae6b-153">En tenant compte de ce à quoi un utilisateur fait attention, vous pouvez améliorer cette expérience en décalant les notifications à partir de l’endroit où l’utilisateur est actuellement Gazing.</span><span class="sxs-lookup"><span data-stu-id="bae6b-153">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="bae6b-154">Cela limite les distractions et les ignore automatiquement une fois que l’utilisateur a terminé la lecture.</span><span class="sxs-lookup"><span data-stu-id="bae6b-154">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="bae6b-155">**Hologrammes précis :** Des hologrammes qui réagissent à la légère sur le regard.</span><span class="sxs-lookup"><span data-stu-id="bae6b-155">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="bae6b-156">Cela peut aller d’un léger éclat aux éléments de l’interface utilisateur, une fleur très lente à un chien virtuel qui commence à regarder l’utilisateur et wagging sa queue.</span><span class="sxs-lookup"><span data-stu-id="bae6b-156">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="bae6b-157">Cette interaction peut fournir un sens intéressant de la connectivité et de la satisfaction dans votre application.</span><span class="sxs-lookup"><span data-stu-id="bae6b-157">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="bae6b-158">Suivi de l’attention</span><span class="sxs-lookup"><span data-stu-id="bae6b-158">Attention tracking</span></span>   
<span data-ttu-id="bae6b-159">Des informations sur l’emplacement ou les utilisateurs qui regardent sont un outil très puissant pour évaluer la convivialité des conceptions et pour identifier les problèmes dans les flux de travail efficaces.</span><span class="sxs-lookup"><span data-stu-id="bae6b-159">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="bae6b-160">La visualisation et l’analyse du suivi oculaire sont une pratique courante dans différents domaines d’application.</span><span class="sxs-lookup"><span data-stu-id="bae6b-160">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="bae6b-161">Avec HoloLens 2, nous fournissons une nouvelle dimension à cette compréhension, car les hologrammes 3D peuvent être placés dans des contextes réels et évalués en conséquence.</span><span class="sxs-lookup"><span data-stu-id="bae6b-161">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="bae6b-162">La [boîte à outils de la réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fournit des exemples de base pour la journalisation et le chargement des données de suivi visuel et comment les visualiser.</span><span class="sxs-lookup"><span data-stu-id="bae6b-162">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>

<span data-ttu-id="bae6b-163">Autres applications possibles dans ce domaine :</span><span class="sxs-lookup"><span data-stu-id="bae6b-163">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="bae6b-164">**Œil à distance-visualisation du regard :** Visualisez ce que les collaborateurs distants examinent pour améliorer la compréhension partagée.</span><span class="sxs-lookup"><span data-stu-id="bae6b-164">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to increase shared understanding.</span></span>
-   <span data-ttu-id="bae6b-165">**Études de recherche des utilisateurs :** Le suivi de l’attention peut vous aider à mieux comprendre la façon dont nous percevons et faisons appel à notre environnement, qui peut aider à améliorer les modèles d’intention de l’homme pour plus d’instinctual.</span><span class="sxs-lookup"><span data-stu-id="bae6b-165">**User research studies:** Attention tracking can help better understanding how we perceive and engage with our environment which may help in better human intent models for more instinctual human-computer-interactions.</span></span> 
-   <span data-ttu-id="bae6b-166">**Formation :** Amélioration de la formation des novices grâce à une meilleure compréhension des modèles de recherche visuelle des experts et de leur coordination manuelle pour les tâches complexes, telles que l’analyse des données médicales ou les machines à fonctionner.</span><span class="sxs-lookup"><span data-stu-id="bae6b-166">**Training:** Improved training of novices by better understanding experts' visual search patterns and their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="bae6b-167">**Évaluations de la conception et recherche sur le marché :** Le suivi oculaire est un outil courant pour les recherches sur le marché lors de l’évaluation des conceptions de site Web et de produit.</span><span class="sxs-lookup"><span data-stu-id="bae6b-167">**Design evaluations and market research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span> <span data-ttu-id="bae6b-168">Avec HoloLens 2, nous pouvons l’étendre aux espaces 3D en fusionnant les variantes de conception de produits numériques avec l’environnement physique.</span><span class="sxs-lookup"><span data-stu-id="bae6b-168">With HoloLens 2, we can extend this to 3D spaces by merging digital product design variants with the physical environment.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="bae6b-169">Cas d’usage supplémentaires</span><span class="sxs-lookup"><span data-stu-id="bae6b-169">Additional use cases</span></span>
- <span data-ttu-id="bae6b-170">**Jeux :** Avez-vous déjà souhaité des superalimentations ?</span><span class="sxs-lookup"><span data-stu-id="bae6b-170">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="bae6b-171">Voilà votre chance !</span><span class="sxs-lookup"><span data-stu-id="bae6b-171">Here's your chance!</span></span> <span data-ttu-id="bae6b-172">Vous pouvez faire en lévitation les hologrammes.</span><span class="sxs-lookup"><span data-stu-id="bae6b-172">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="bae6b-173">Prenez des faisceaux laser de vos yeux, essayez-le dans [RoboRaid pour HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span><span class="sxs-lookup"><span data-stu-id="bae6b-173">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="bae6b-174">Transformez des ennemis en pierres ou figez-les.</span><span class="sxs-lookup"><span data-stu-id="bae6b-174">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="bae6b-175">Utilisez votre vision à rayons X pour explorer des bâtiments.</span><span class="sxs-lookup"><span data-stu-id="bae6b-175">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="bae6b-176">La seule limite, c’est votre imagination !</span><span class="sxs-lookup"><span data-stu-id="bae6b-176">Your imagination is the limit!</span></span>
<span data-ttu-id="bae6b-177">ATTENTION : pour en savoir plus, consultez nos [instructions relatives à la conception d’entrées](eye-gaze-interaction.md)orientées regard.</span><span class="sxs-lookup"><span data-stu-id="bae6b-177">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="bae6b-178">**Avatars expressifs :** Le suivi des yeux permet d’obtenir des avatars 3D plus expressifs en utilisant des données de suivi visuel actif pour animer les yeux de l’avatar qui indiquent ce que l’utilisateur examine.</span><span class="sxs-lookup"><span data-stu-id="bae6b-178">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="bae6b-179">**Entrée de texte :** Le suivi oculaire peut être utilisé comme alternative pour une entrée de texte à faible effort, en particulier lorsque la parole ou les mains sont peu pratiques à utiliser.</span><span class="sxs-lookup"><span data-stu-id="bae6b-179">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="bae6b-180">Utilisation de l’œil en regard de l’interaction</span><span class="sxs-lookup"><span data-stu-id="bae6b-180">Using eye-gaze for interaction</span></span>
<span data-ttu-id="bae6b-181">La création d’une interaction qui tire parti du ciblage visuel à déplacement rapide peut être difficile.</span><span class="sxs-lookup"><span data-stu-id="bae6b-181">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="bae6b-182">D’un côté, les yeux se déplacent tellement vite que vous devez être attentif à l’utilisation de l’entrée de regard, car sinon l’utilisateur peut trouver l’expérience écrasante ou gênante.</span><span class="sxs-lookup"><span data-stu-id="bae6b-182">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise user may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="bae6b-183">En revanche, vous pouvez également créer des expériences véritablement magiques qui exciteront vos utilisateurs !</span><span class="sxs-lookup"><span data-stu-id="bae6b-183">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="bae6b-184">Pour vous aider, consultez notre présentation des principaux avantages, défis et recommandations de conception pour [une interaction](eye-gaze-interaction.md)avec les yeux.</span><span class="sxs-lookup"><span data-stu-id="bae6b-184">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 

<br>
 
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="bae6b-185">Guide de développement : que se passe-t-il si le suivi oculaire n’est pas disponible ?</span><span class="sxs-lookup"><span data-stu-id="bae6b-185">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="bae6b-186">Dans certaines situations, votre application ne recevra peut-être aucune donnée de suivi oculaire pour différentes raisons, notamment :</span><span class="sxs-lookup"><span data-stu-id="bae6b-186">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="bae6b-187">L’utilisateur a ignoré l’étalonnage du suivi oculaire.</span><span class="sxs-lookup"><span data-stu-id="bae6b-187">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="bae6b-188">L’utilisateur a étalonné, mais a décidé de ne pas accorder à votre application l’autorisation d’utiliser ses données de suivi visuel.</span><span class="sxs-lookup"><span data-stu-id="bae6b-188">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="bae6b-189">L’utilisateur dispose de lunettes uniques ou d’une condition oculaire que le système ne prend pas encore en charge.</span><span class="sxs-lookup"><span data-stu-id="bae6b-189">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="bae6b-190">Facteurs externes qui empêchent le suivi des yeux fiables, tels que les taches sur le Visor ou les lunettes, les lumières et les occlusions directs du soleil en raison des cheveux devant les yeux.</span><span class="sxs-lookup"><span data-stu-id="bae6b-190">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="bae6b-191">Pour vous, en tant que développeur d’applications, cela signifie que vous devez prendre en compte la prise en charge des utilisateurs pour lesquels les données de suivi oculaire peuvent ne pas être disponibles.</span><span class="sxs-lookup"><span data-stu-id="bae6b-191">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="bae6b-192">Nous vous expliquons tout d’abord comment détecter si le suivi oculaire est disponible et comment résoudre le cas où il n’est pas disponible pour différentes applications.</span><span class="sxs-lookup"><span data-stu-id="bae6b-192">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="bae6b-193">1. Comment détecter que le suivi oculaire est disponible</span><span class="sxs-lookup"><span data-stu-id="bae6b-193">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="bae6b-194">Quelques vérifications permettent de déterminer si les données de suivi visuel sont disponibles.</span><span class="sxs-lookup"><span data-stu-id="bae6b-194">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="bae6b-195">Vérifier si...</span><span class="sxs-lookup"><span data-stu-id="bae6b-195">Check whether...</span></span>
* <span data-ttu-id="bae6b-196">... le système prend en charge le suivi visuel.</span><span class="sxs-lookup"><span data-stu-id="bae6b-196">... the system supports eye tracking at all.</span></span> <span data-ttu-id="bae6b-197">Appelez la *méthode*suivante : [Windows. perception. People. EyesPose. IsSupported ()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="bae6b-197">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="bae6b-198">... l’utilisateur est étalonné.</span><span class="sxs-lookup"><span data-stu-id="bae6b-198">... the user is calibrated.</span></span> <span data-ttu-id="bae6b-199">Appelez la *propriété*suivante : [Windows. perception. People. EyesPose. IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="bae6b-199">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="bae6b-200">... l’utilisateur a donné à votre application l’autorisation d’utiliser ses données de suivi visuel : récupérez le _« GazeInputAccessStatus »_ actuel.</span><span class="sxs-lookup"><span data-stu-id="bae6b-200">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="bae6b-201">Vous trouverez un exemple de la procédure à suivre pour [demander l’accès aux entrées de regard](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span><span class="sxs-lookup"><span data-stu-id="bae6b-201">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="bae6b-202">En outre, vous souhaiterez peut-être vérifier que vos données de suivi oculaire ne sont pas obsolètes en ajoutant un délai d’expiration entre les mises à jour reçues des données de suivi oculaire et en configurant le point de vue dans le point de vue ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="bae6b-202">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="bae6b-203">Comme décrit ci-dessus, il existe plusieurs raisons pour lesquelles les données de suivi oculaire peuvent ne pas être disponibles.</span><span class="sxs-lookup"><span data-stu-id="bae6b-203">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="bae6b-204">Alors que certains utilisateurs peuvent avoir des axent décidés de révoquer l’accès à leurs données de suivi visuel et qu’ils sont OK avec le compromis d’une expérience utilisateur inférieure à la confidentialité de ne pas fournir l’accès à leurs données de suivi visuel, dans certains cas cela peut être involontaire.</span><span class="sxs-lookup"><span data-stu-id="bae6b-204">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="bae6b-205">Par conséquent, si votre application utilise le suivi oculaire et qu’il s’agit d’une partie importante de l’expérience, nous vous recommandons de le communiquer clairement à l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="bae6b-205">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="bae6b-206">En informant l’utilisateur, pourquoi le suivi des yeux est essentiel pour votre application (peut-être même répertorier certaines fonctionnalités améliorées) afin de tirer le meilleur parti de votre application, peut aider l’utilisateur à mieux comprendre ce qu’il abandonne.</span><span class="sxs-lookup"><span data-stu-id="bae6b-206">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="bae6b-207">Aidez l’utilisateur à identifier la raison pour laquelle le suivi oculaire peut ne pas fonctionner (sur la base des vérifications ci-dessus) et propose des suggestions pour résoudre rapidement les problèmes potentiels.</span><span class="sxs-lookup"><span data-stu-id="bae6b-207">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="bae6b-208">Par exemple, si vous pouvez détecter que le système prend en charge le suivi oculaire, l’utilisateur est étalonné et même a donné son autorisation, mais aucune donnée de suivi oculaire n’est reçue, alors cela peut pointer vers d’autres problèmes tels que les traînées ou les yeux bloqués.</span><span class="sxs-lookup"><span data-stu-id="bae6b-208">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="bae6b-209">Notez cependant qu’il y a de rares cas d’utilisateurs pour lesquels le suivi oculaire peut simplement ne pas fonctionner.</span><span class="sxs-lookup"><span data-stu-id="bae6b-209">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="bae6b-210">Par conséquent, n’hésitez pas à le faire en autorisant à ignorer ou même à désactiver les rappels pour activer le suivi visuel dans votre application.</span><span class="sxs-lookup"><span data-stu-id="bae6b-210">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="bae6b-211">2. la solution de secours pour les applications utilisant des yeux en forme de point d’entrée principal</span><span class="sxs-lookup"><span data-stu-id="bae6b-211">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="bae6b-212">Si votre application utilise le point d’entrée de l’œil pour sélectionner rapidement des hologrammes dans la scène, mais que les données de suivi oculaire ne sont pas disponibles, nous vous recommandons de revenir à la tête de regard et de commencer à montrer le curseur en tête.</span><span class="sxs-lookup"><span data-stu-id="bae6b-212">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="bae6b-213">Nous vous recommandons d’utiliser un délai d’expiration (par exemple, 500 – 1500 ms) pour déterminer s’il faut basculer ou non.</span><span class="sxs-lookup"><span data-stu-id="bae6b-213">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="bae6b-214">Cela permet d’éviter de faire apparaître un curseur à chaque fois que le système risque de perdre brièvement le suivi en raison de mouvements oculaires rapides ou de clignotements.</span><span class="sxs-lookup"><span data-stu-id="bae6b-214">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="bae6b-215">Si vous êtes un développeur Unity, la solution de secours automatique à la tête de regard est déjà gérée dans le kit de développement de la réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="bae6b-215">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="bae6b-216">Si vous êtes un développeur DirectX, vous devez gérer ce commutateur vous-même.</span><span class="sxs-lookup"><span data-stu-id="bae6b-216">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="bae6b-217">3. secours pour d’autres applications spécifiques au suivi des yeux</span><span class="sxs-lookup"><span data-stu-id="bae6b-217">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="bae6b-218">Votre application peut utiliser des regards à l’aide d’une méthode unique adaptée aux yeux, par exemple pour animer les yeux d’un avatar ou pour attirer l’attention sur les yeux cartes thermiques en se basant sur des informations précises sur l’attention visuelle.</span><span class="sxs-lookup"><span data-stu-id="bae6b-218">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="bae6b-219">Dans ce cas, il n’y a pas de secours clair.</span><span class="sxs-lookup"><span data-stu-id="bae6b-219">In this case, there is no clear fallback.</span></span> <span data-ttu-id="bae6b-220">Si le suivi oculaire n’est pas disponible, il se peut que vous deviez simplement désactiver ces fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="bae6b-220">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="bae6b-221">Là encore, nous vous recommandons de communiquer clairement à l’utilisateur qui ne sait pas que la fonctionnalité ne fonctionne pas.</span><span class="sxs-lookup"><span data-stu-id="bae6b-221">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="bae6b-222">Cette page vous a espérons vous fournir une bonne vue d’ensemble pour vous aider à comprendre le rôle du suivi oculaire et l’entrée de regard pour HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="bae6b-222">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="bae6b-223">Pour commencer à développer, consultez nos informations sur le rôle de l' [oeil pour l’interaction avec les hologrammes](eye-gaze-interaction.md), le [point de regard sur Unity](https://aka.ms/mrtk-eyes) et les [yeux dans DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="bae6b-223">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="bae6b-224">Articles associés</span><span class="sxs-lookup"><span data-stu-id="bae6b-224">See also</span></span>
* [<span data-ttu-id="bae6b-225">Étalonnage</span><span class="sxs-lookup"><span data-stu-id="bae6b-225">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="bae6b-226">Confort</span><span class="sxs-lookup"><span data-stu-id="bae6b-226">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="bae6b-227">Interaction avec l’œil-regard</span><span class="sxs-lookup"><span data-stu-id="bae6b-227">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="bae6b-228">Œil-point de regard sur DirectX</span><span class="sxs-lookup"><span data-stu-id="bae6b-228">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="bae6b-229">Œil-point d’interfaut</span><span class="sxs-lookup"><span data-stu-id="bae6b-229">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="bae6b-230">Point de regard et validation</span><span class="sxs-lookup"><span data-stu-id="bae6b-230">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="bae6b-231">Entrée vocale</span><span class="sxs-lookup"><span data-stu-id="bae6b-231">Voice input</span></span>](voice-design.md)


