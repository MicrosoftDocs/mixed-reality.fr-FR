---
title: Eye-tracking
description: Eye-tracking
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Eye Tracking, eye-tracking, oculométrie, suivi rétinien, suivi du mouvement des yeux, réalité mixte, entrée, suivi du regard, pointage du regard
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453703"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="1d472-104">Eye-tracking sur HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="1d472-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="1d472-105">HoloLens 2 permet d’accéder à un tout nouveau niveau de compréhension contextuelle et humaine au sein de l’expérience holographique en offrant aux développeurs l’incroyable capacité d’utiliser des informations sur ce que les utilisateurs regardent.</span><span class="sxs-lookup"><span data-stu-id="1d472-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="1d472-106">Cette page fournit une vue d’ensemble des avantages dont peuvent tirer parti les développeurs dans le domaine de l’eye-tracking pour divers cas d’usage. Elle décrit également les éléments à prendre en compte durant la conception d’interfaces utilisateur basées sur le suivi du regard.</span><span class="sxs-lookup"><span data-stu-id="1d472-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="1d472-107">Cas d’utilisation</span><span class="sxs-lookup"><span data-stu-id="1d472-107">Use cases</span></span>
<span data-ttu-id="1d472-108">L’eye-tracking permet aux applications de savoir où l’utilisateur regarde en temps réel.</span><span class="sxs-lookup"><span data-stu-id="1d472-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="1d472-109">Cette section décrit certains cas d’usage potentiels ainsi que les nouvelles interactions possibles liées à l’eye-tracking dans le domaine de la réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="1d472-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="1d472-110">Avant de commencer, sachez que nous allons mentionner à plusieurs reprises le [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html), car il fournit de nombreux exemples intéressants et puissants d’utilisation de l’eye-tracking, par exemple le ciblage oculaire rapide et sans effort ainsi que le défilement automatique d’un texte en fonction de l’endroit où l’utilisateur regarde.</span><span class="sxs-lookup"><span data-stu-id="1d472-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="1d472-111">Intention de l’utilisateur</span><span class="sxs-lookup"><span data-stu-id="1d472-111">User intent</span></span>    
<span data-ttu-id="1d472-112">Les informations relatives aux mouvements oculaires d’un utilisateur fournissent un **contexte puissant pour d’autres entrées**, par exemple la voix, les mains et les contrôleurs.</span><span class="sxs-lookup"><span data-stu-id="1d472-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="1d472-113">Cela peut être utile pour diverses tâches.</span><span class="sxs-lookup"><span data-stu-id="1d472-113">This can be used for various tasks.</span></span>
<span data-ttu-id="1d472-114">Par exemple, cela peut aller du **ciblage** rapide et sans effort en regardant simplement un hologramme et en disant « sélectionner » (consultez également [Suivre de la tête et valider](gaze-and-commit.md)), ou en disant « mettre ceci... », puis en regardant là où vous souhaitez placer l’hologramme, et en disant « là ».</span><span class="sxs-lookup"><span data-stu-id="1d472-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="1d472-115">Vous trouverez des exemples à ce sujet dans [Mixed Reality Toolkit - Sélection d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) et [Mixed Reality Toolkit - Positionnement d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="1d472-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="1d472-116">Il existe un autre exemple possible d’intention de l’utilisateur. Il consiste à tirer parti des informations relatives à ce que recherchent les utilisateurs pour améliorer l’engagement avec les agents virtuels incorporés et les hologrammes interactifs.</span><span class="sxs-lookup"><span data-stu-id="1d472-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="1d472-117">Par exemple, les agents virtuels peuvent adapter les options disponibles et leur comportement en fonction du contenu visualisé.</span><span class="sxs-lookup"><span data-stu-id="1d472-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="1d472-118">Actions implicites</span><span class="sxs-lookup"><span data-stu-id="1d472-118">Implicit actions</span></span>
<span data-ttu-id="1d472-119">La catégorie des actions implicites est étroitement liée à l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="1d472-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="1d472-120">L’idée consiste à faire en sorte que les hologrammes ou les éléments d’interface utilisateur réagissent de manière plus ou moins instinctive. Ainsi, il n’est plus vraiment question d’une interaction avec le système mais plutôt d’une synchronisation entre le système et l’utilisateur. Dans ce domaine, le **défilement automatique basé sur le suivi du regard** est un exemple très réussi.</span><span class="sxs-lookup"><span data-stu-id="1d472-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="1d472-121">L’idée est simple : L’utilisateur lit un texte et peut simplement continuer sa lecture.</span><span class="sxs-lookup"><span data-stu-id="1d472-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="1d472-122">Le texte défile progressivement en permettant aux utilisateurs de conserver leur flux de lecture.</span><span class="sxs-lookup"><span data-stu-id="1d472-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="1d472-123">La vitesse de défilement est un aspect clé, car elle s’adapte à la vitesse de lecture de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="1d472-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="1d472-124">La fonctionnalité de **zoom et défilement panoramique à l’aide du regard** est un autre exemple pour lequel l’utilisateur peut avoir l’impression de plonger exactement vers ce sur quoi il se concentre.</span><span class="sxs-lookup"><span data-stu-id="1d472-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="1d472-125">Le déclenchement du zoom et le réglage de la vitesse du zoom peuvent être contrôlés par entrée vocale ou manuelle, ce qui est important pour donner une impression de contrôle et éviter de surcharger l’utilisateur (nous en parlerons plus en détail dans les recommandations de conception ci-dessous).</span><span class="sxs-lookup"><span data-stu-id="1d472-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="1d472-126">Une fois le zoom effectué, l’utilisateur peut suivre en douceur le parcours d’une rue, par exemple, pour explorer son quartier juste par suivi du regard.</span><span class="sxs-lookup"><span data-stu-id="1d472-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="1d472-127">Vous trouverez des démonstrations de ces types d’interaction dans l’exemple [Mixed Reality Toolkit - Navigation à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="1d472-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="1d472-128">Il existe d’autres cas d’usage supplémentaires pour les _actions implicites_ :</span><span class="sxs-lookup"><span data-stu-id="1d472-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="1d472-129">**Notifications intelligentes :** Avez-vous déjà été ennuyé par des notifications qui apparaissent juste là où vous concentrez votre attention ?</span><span class="sxs-lookup"><span data-stu-id="1d472-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="1d472-130">En tenant compte de l’endroit où un utilisateur concentre son attention, vous pouvez améliorer son expérience !</span><span class="sxs-lookup"><span data-stu-id="1d472-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="1d472-131">Affichez des notifications décalées par rapport à l’endroit où l’utilisateur concentre son attention pour limiter les distractions et les masquer automatiquement une fois la lecture terminée.</span><span class="sxs-lookup"><span data-stu-id="1d472-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="1d472-132">**Hologrammes attentifs :** Hologrammes qui réagissent subtilement quand vous les regardez.</span><span class="sxs-lookup"><span data-stu-id="1d472-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="1d472-133">Cela peut aller d’éléments d’IU légèrement brillants ou d’une fleur qui éclot lentement à un animal de compagnie virtuel qui vous rend votre regard ou, au contraire, essaie de l’éviter quand vous le fixez avec insistance.</span><span class="sxs-lookup"><span data-stu-id="1d472-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="1d472-134">Cela peut donner un sentiment intéressant de connectivité et de satisfaction à l’utilisateur de votre application.</span><span class="sxs-lookup"><span data-stu-id="1d472-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="1d472-135">Suivi de l’attention</span><span class="sxs-lookup"><span data-stu-id="1d472-135">Attention tracking</span></span>   
<span data-ttu-id="1d472-136">Les informations sur les endroits où regardent les utilisateurs constituent un outil extrêmement puissant, qui permet d’évaluer la convivialité de la conception d’une interface et d’identifier les problèmes d’efficacité des flux de travail.</span><span class="sxs-lookup"><span data-stu-id="1d472-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="1d472-137">Aujourd’hui, la visualisation et l’analyse des données d’eye-tracking sont une pratique courante dans divers domaines d’application.</span><span class="sxs-lookup"><span data-stu-id="1d472-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="1d472-138">Avec HoloLens 2, nous fournissons une nouvelle dimension à cette compréhension, car les hologrammes 3D peuvent être placés dans des contextes concrets et évalués en même temps.</span><span class="sxs-lookup"><span data-stu-id="1d472-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="1d472-139">[Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fournit des exemples de base pour la journalisation et le chargement des données d’eye-tracking ainsi que leur visualisation.</span><span class="sxs-lookup"><span data-stu-id="1d472-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="1d472-140">Autres applications possibles dans ce domaine :</span><span class="sxs-lookup"><span data-stu-id="1d472-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="1d472-141">**Visualisation du suivi du regard à distance :** Visualisez ce que les collaborateurs distants regardent. Par exemple, vérifiez que les instructions sont correctement comprises et suivies.</span><span class="sxs-lookup"><span data-stu-id="1d472-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="1d472-142">**Études de recherche sur les utilisateurs :** Le suivi de l’attention permet de comparer les utilisateurs novices aux utilisateurs experts sur la façon dont ils analysent visuellement du contenu ou sur leur coordination œil-main pour des tâches complexes (l’analyse de données médicales ou le maniement de certains appareils, par exemple).</span><span class="sxs-lookup"><span data-stu-id="1d472-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="1d472-143">**Simulations d’apprentissage et analyse des performances :** Entraînez-vous et optimisez l’exécution de certaines tâches en identifiant plus efficacement les goulots d’étranglement du flux d’exécution.</span><span class="sxs-lookup"><span data-stu-id="1d472-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="1d472-144">**Évaluations de conception, études publicitaires et marketing :** L’eye-tracking (ou « suivi oculaire ») est un outil répandu d’étude de marché qui permet d’évaluer l’ergonomie des sites web et des produits.</span><span class="sxs-lookup"><span data-stu-id="1d472-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="1d472-145">Cas d’usage supplémentaires</span><span class="sxs-lookup"><span data-stu-id="1d472-145">Additional use cases</span></span>
- <span data-ttu-id="1d472-146">**Jeux :** Vous avez toujours souhaité avoir des super pouvoirs ?</span><span class="sxs-lookup"><span data-stu-id="1d472-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="1d472-147">Voilà votre chance !</span><span class="sxs-lookup"><span data-stu-id="1d472-147">Here's your chance!</span></span> <span data-ttu-id="1d472-148">Faites léviter les hologrammes en les fixant.</span><span class="sxs-lookup"><span data-stu-id="1d472-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="1d472-149">Envoyez des rayons laser avec vos yeux.</span><span class="sxs-lookup"><span data-stu-id="1d472-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="1d472-150">Transformez vos ennemis en pierre ou gelez-les !</span><span class="sxs-lookup"><span data-stu-id="1d472-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="1d472-151">Utilisez votre vision à rayons X pour explorer des bâtiments.</span><span class="sxs-lookup"><span data-stu-id="1d472-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="1d472-152">La seule limite, c’est votre imagination !</span><span class="sxs-lookup"><span data-stu-id="1d472-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="1d472-153">**Avatars expressifs :** L’eye-tracking contribue à créer des avatars 3D plus expressifs en utilisant des données d’eye-tracking en temps réel pour animer les yeux de l’avatar et indiquer ce que l’utilisateur regarde.</span><span class="sxs-lookup"><span data-stu-id="1d472-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="1d472-154">Il permet également d’accroître l’expressivité en ajoutant des clins d’œil.</span><span class="sxs-lookup"><span data-stu-id="1d472-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="1d472-155">**Entrée de texte :** L’eye-tracking peut représenter une solution intéressante pour saisir du texte sans effort, en particulier quand l’usage de la voix ou des mains n’est pas pratique.</span><span class="sxs-lookup"><span data-stu-id="1d472-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="1d472-156">API d’eye-tracking</span><span class="sxs-lookup"><span data-stu-id="1d472-156">Eye tracking API</span></span>
<span data-ttu-id="1d472-157">Avant d’entrer dans les détails des recommandations de conception spécifiques à l’interaction par suivi du regard, nous souhaitons souligner brièvement les capacités offertes par le suiveur oculaire HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="1d472-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="1d472-158">L’[API d’eye-tracking](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) est accessible via `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="1d472-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="1d472-159">Elle fournit aux développeurs un seul rayon de suivi du regard (origine et direction du pointage du regard).</span><span class="sxs-lookup"><span data-stu-id="1d472-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="1d472-160">Le suiveur oculaire fournit des données à raison de _30 FPS_ (images par seconde) environ.</span><span class="sxs-lookup"><span data-stu-id="1d472-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="1d472-161">Le suivi du regard prévu se situe</span><span class="sxs-lookup"><span data-stu-id="1d472-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="1d472-162">dans un angle visuel compris entre 1,0 et 1,5 degrés autour de la cible observée.</span><span class="sxs-lookup"><span data-stu-id="1d472-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="1d472-163">Comme de légères imprécisions sont attendues, vous devez prévoir une certaine marge autour de cette valeur de limite inférieure.</span><span class="sxs-lookup"><span data-stu-id="1d472-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="1d472-164">Nous en discuterons plus en détail ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="1d472-164">We will discuss this more below.</span></span> <span data-ttu-id="1d472-165">Pour que l’eye-tracking fonctionne avec précision, chaque utilisateur doit effectuer un étalonnage.</span><span class="sxs-lookup"><span data-stu-id="1d472-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="1d472-166">![Taille optimale de la cible à une distance de 2 mètres](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="1d472-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="1d472-167">*Taille optimale de la cible à une distance de 2 mètres*</span><span class="sxs-lookup"><span data-stu-id="1d472-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="1d472-168">Recommandations de conception pour le suivi du regard</span><span class="sxs-lookup"><span data-stu-id="1d472-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="1d472-169">Créer une interaction qui tire parti d’un ciblage oculaire rapide peut être une tâche difficile.</span><span class="sxs-lookup"><span data-stu-id="1d472-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="1d472-170">Dans cette section, nous récapitulons les principaux avantages et défis à prendre en compte durant la conception de votre application.</span><span class="sxs-lookup"><span data-stu-id="1d472-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="1d472-171">Avantages liés à l’entrée par suivi du regard</span><span class="sxs-lookup"><span data-stu-id="1d472-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="1d472-172">**Pointage à haute vitesse.**</span><span class="sxs-lookup"><span data-stu-id="1d472-172">**High speed pointing.**</span></span> <span data-ttu-id="1d472-173">Le muscle oculaire est le muscle le plus réactif de notre corps.</span><span class="sxs-lookup"><span data-stu-id="1d472-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="1d472-174">**Faible effort.**</span><span class="sxs-lookup"><span data-stu-id="1d472-174">**Low effort.**</span></span> <span data-ttu-id="1d472-175">Pratiquement aucun mouvement physique n’est nécessaire.</span><span class="sxs-lookup"><span data-stu-id="1d472-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="1d472-176">**Implicite.**</span><span class="sxs-lookup"><span data-stu-id="1d472-176">**Implicitness.**</span></span> <span data-ttu-id="1d472-177">Souvent décrites par les utilisateurs comme une « lecture de l’esprit », les informations relatives aux mouvements oculaires d’un utilisateur permettent au système de savoir quelle est la cible de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="1d472-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="1d472-178">**Autre canal d’entrée.**</span><span class="sxs-lookup"><span data-stu-id="1d472-178">**Alternative input channel.**</span></span> <span data-ttu-id="1d472-179">Le suivi du regard peut contribuer de manière importante aux entrées manuelle et vocale grâce aux années d’expérience accumulées dans le domaine de la coordination œil-main des utilisateurs.</span><span class="sxs-lookup"><span data-stu-id="1d472-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="1d472-180">**Attention visuelle.**</span><span class="sxs-lookup"><span data-stu-id="1d472-180">**Visual attention.**</span></span> <span data-ttu-id="1d472-181">Pouvoir déduire ce qui intéresse l’utilisateur est un autre avantage important.</span><span class="sxs-lookup"><span data-stu-id="1d472-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="1d472-182">Cela peut être utile dans divers domaines d’application, allant de l’évaluation plus efficace de différentes conceptions à la création d’interfaces utilisateur plus intelligentes et à l’amélioration des signaux sociaux pour la communication à distance.</span><span class="sxs-lookup"><span data-stu-id="1d472-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="1d472-183">En bref, le suivi du regard permet de fournir un signal contextuel rapide et sans effort. Ce signal est particulièrement puissant s’il est utilisé en combinaison avec d’autres entrées telles que les entrées *vocale* et *manuelle* pour confirmer l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="1d472-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="1d472-184">Les défis de l’entrée par suivi du regard</span><span class="sxs-lookup"><span data-stu-id="1d472-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="1d472-185">Un grand pouvoir implique de grandes responsabilités : Bien que le suivi du regard permette de créer des émotions proches de celles d’un super-héros, il est également important d’en connaître les risques pour l’utiliser de manière appropriée.</span><span class="sxs-lookup"><span data-stu-id="1d472-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="1d472-186">Dans ce qui suit, nous allons aborder certains *défis* à prendre en compte ainsi que la manière de les résoudre quand vous utilisez l’entrée par suivi du regard :</span><span class="sxs-lookup"><span data-stu-id="1d472-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="1d472-187">**Votre suivi du regard est « toujours actif »**  : dès que vous ouvrez les paupières, vos yeux fixent les objets de votre environnement.</span><span class="sxs-lookup"><span data-stu-id="1d472-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="1d472-188">Si tout ce que vous regardez donne lieu à des actions et si votre regard s’attarde trop sur certaines choses, il peut en résulter des effets indésirables et une expérience utilisateur déplaisante !</span><span class="sxs-lookup"><span data-stu-id="1d472-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="1d472-189">C’est la raison pour laquelle nous recommandons de combiner le suivi du regard avec une *commande vocale*, un *mouvement de la main*, un *clic sur un bouton* ou un temps d’arrêt prolongé pour déclencher la sélection d’une cible.</span><span class="sxs-lookup"><span data-stu-id="1d472-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="1d472-190">Cette solution permet également d’accéder à un mode dans lequel l’utilisateur peut librement regarder autour de lui sans avoir l’impression constante de déclencher quelque chose involontairement.</span><span class="sxs-lookup"><span data-stu-id="1d472-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="1d472-191">Ce problème doit également être pris en compte durant la conception d’une rétroaction visuelle et auditive quand l’utilisateur regarde simplement une cible.</span><span class="sxs-lookup"><span data-stu-id="1d472-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="1d472-192">Ne surchargez pas l’utilisateur avec des effets immédiats d’ouverture dans une nouvelle fenêtre ou des sons de pointage.</span><span class="sxs-lookup"><span data-stu-id="1d472-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="1d472-193">De la subtilité, voilà la clé !</span><span class="sxs-lookup"><span data-stu-id="1d472-193">Subtlety is key!</span></span> <span data-ttu-id="1d472-194">Nous allons aborder plus loin certaines bonnes pratiques quand nous évoquerons les recommandations de conception.</span><span class="sxs-lookup"><span data-stu-id="1d472-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="1d472-195">**Observation et contrôle** : imaginez que vous souhaitiez aligner avec précision une photo sur un mur.</span><span class="sxs-lookup"><span data-stu-id="1d472-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="1d472-196">Vous regardez les bords de la photo et ce qui se trouve à proximité pour voir si elle est bien alignée.</span><span class="sxs-lookup"><span data-stu-id="1d472-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="1d472-197">Maintenant, imaginez comment procéder quand vous souhaitez déplacer l’image par suivi du regard.</span><span class="sxs-lookup"><span data-stu-id="1d472-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="1d472-198">Difficile, n’est-ce pas ?</span><span class="sxs-lookup"><span data-stu-id="1d472-198">Difficult, isn't it?</span></span> <span data-ttu-id="1d472-199">Cela décrit le double rôle du suivi du regard quand il est nécessaire à la fois pour l’entrée et pour le contrôle.</span><span class="sxs-lookup"><span data-stu-id="1d472-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="1d472-200">**Quitter avant de cliquer :** Pour les sélections rapides de cibles, des recherches ont montré que le suivi du regard de l’utilisateur se déplace parfois avant un clic manuel (par exemple, un clic aérien).</span><span class="sxs-lookup"><span data-stu-id="1d472-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="1d472-201">Il est donc nécessaire d’accorder une attention particulière à la synchronisation du signal rapide donné par le suivi du regard avec une entrée de commande plus lente (par exemple la voix, les mains, un contrôleur).</span><span class="sxs-lookup"><span data-stu-id="1d472-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="1d472-202">**Petites cibles :** Avez-vous déjà ressenti cette désagréable sensation quand vous essayez de lire un texte trop petit pour être lu confortablement ?</span><span class="sxs-lookup"><span data-stu-id="1d472-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="1d472-203">Cette sensation de tension oculaire qui vous fatigue et vous épuise, car vous essayez d’adapter votre vue pour mieux vous concentrer ?</span><span class="sxs-lookup"><span data-stu-id="1d472-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="1d472-204">Vous risquez de provoquer cette sensation chez vos utilisateurs quand vous les obligez à sélectionner des cibles trop petites dans votre application à l’aide du ciblage oculaire.</span><span class="sxs-lookup"><span data-stu-id="1d472-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="1d472-205">Durant la conception, si vous souhaitez créer une expérience utilisateur agréable et confortable, nous vous recommandons de privilégier des cibles ayant un angle de vue d’au moins 2°, sinon plus de préférence.</span><span class="sxs-lookup"><span data-stu-id="1d472-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="1d472-206">**Mouvements de suivi du regard irréguliers** : nos yeux effectuent des mouvements rapides de fixation en fixation.</span><span class="sxs-lookup"><span data-stu-id="1d472-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="1d472-207">Si vous examinez un enregistrement des mouvements oculaires, vous pouvez voir qu’ils sont irréguliers.</span><span class="sxs-lookup"><span data-stu-id="1d472-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="1d472-208">Vos yeux bougent rapidement et sautent spontanément par rapport au *suivi de la tête* ou aux *mouvements de la main*.</span><span class="sxs-lookup"><span data-stu-id="1d472-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="1d472-209">**Fiabilité du suivi :** La précision de l’eye-tracking peut se dégrader légèrement quand la lumière change, car votre œil s’adapte aux nouvelles conditions.</span><span class="sxs-lookup"><span data-stu-id="1d472-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="1d472-210">Bien que cela n’affecte pas nécessairement la conception de votre application, la précision ne doit pas dépasser la limite mentionnée ci-dessus de 2°.</span><span class="sxs-lookup"><span data-stu-id="1d472-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="1d472-211">Cela peut signifier que l’utilisateur doit exécuter un autre étalonnage.</span><span class="sxs-lookup"><span data-stu-id="1d472-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="1d472-212">Recommandations de conception</span><span class="sxs-lookup"><span data-stu-id="1d472-212">Design recommendations</span></span>
<span data-ttu-id="1d472-213">Dans ce qui suit, nous énumérons des recommandations de conception spécifiques basées sur les avantages et les défis relatifs au suivi du regard :</span><span class="sxs-lookup"><span data-stu-id="1d472-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="1d472-214">**Suivi du regard != Suivi de la tête :**</span><span class="sxs-lookup"><span data-stu-id="1d472-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="1d472-215">**Déterminez si des mouvements oculaires rapides mais irréguliers conviennent à votre tâche de saisie :** Nos mouvements oculaires rapides et irréguliers sont parfaits pour sélectionner rapidement des cibles dans notre champ de vision, mais ils sont moins utiles pour les tâches nécessitant des trajectoires d’entrée lisses (par exemple, dessiner ou entourer des annotations).</span><span class="sxs-lookup"><span data-stu-id="1d472-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="1d472-216">Dans ce cas, le pointage à la main ou avec la tête est préférable.</span><span class="sxs-lookup"><span data-stu-id="1d472-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="1d472-217">**Évitez d’associer directement quelque chose au suivi du regard de l’utilisateur (par exemple un curseur).**</span><span class="sxs-lookup"><span data-stu-id="1d472-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="1d472-218">Dans le cas d’un curseur, cela peut entraîner un effet de « curseur fuyant » en raison de légers décalages dans le signal de suivi du regard projeté.</span><span class="sxs-lookup"><span data-stu-id="1d472-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="1d472-219">Dans le cas d’un curseur, cela entre en conflit avec le double rôle qui consiste à contrôler le curseur à l’aide des yeux tout en souhaitant également vérifier si l’objet se trouve au bon emplacement.</span><span class="sxs-lookup"><span data-stu-id="1d472-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="1d472-220">En bref, les utilisateurs peuvent rapidement se sentir submergés et gênés, en particulier si le signal est imprécis.</span><span class="sxs-lookup"><span data-stu-id="1d472-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="1d472-221">**Combiner le suivi du regard avec d’autres entrées :** L’intégration de l’eye-tracking à d’autres entrées, par exemple les mouvements des mains, les commandes vocales ou les actions visant à appuyer sur un bouton présente plusieurs avantages :</span><span class="sxs-lookup"><span data-stu-id="1d472-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="1d472-222">**Permettre une observation libre :** Étant donné que le rôle principal de nos yeux est d’observer notre environnement, il est important de permettre aux utilisateurs de regarder autour d’eux sans déclencher de rétroactions ou d’actions (visuelles, auditives, etc.).</span><span class="sxs-lookup"><span data-stu-id="1d472-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="1d472-223">La combinaison de l’eye-tracking avec un autre contrôle d’entrée permet une transition en douceur entre les modes d’observation par eye-tracking et de contrôle d’entrée.</span><span class="sxs-lookup"><span data-stu-id="1d472-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="1d472-224">**Fournisseur de contexte puissant :** L’utilisation d’informations liées au regard de l’utilisateur en même temps que l’émission d’une commande vocale ou l’exécution d’un mouvement de la main permet de canaliser sans effort l’entrée dans le champ de vision.</span><span class="sxs-lookup"><span data-stu-id="1d472-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="1d472-225">Par exemple : « Mettre ça là » pour sélectionner et positionner rapidement et facilement un hologramme dans la scène en regardant simplement une cible et une destination.</span><span class="sxs-lookup"><span data-stu-id="1d472-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="1d472-226">**Nécessité de synchroniser les entrées multimodales (problème du « quitter avant de cliquer ») :** Si des mouvements oculaires rapides sont combinés avec des entrées supplémentaires plus complexes (par exemple des commandes vocales longues ou des mouvements des mains), l’utilisateur risque de suivre autre chose du regard avant d’achever la commande d’entrée supplémentaire.</span><span class="sxs-lookup"><span data-stu-id="1d472-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="1d472-227">Ainsi, si vous créez vos propres contrôles d’entrée (mouvements des mains personnalisés, par exemple), veillez à journaliser le début de cette entrée ou sa durée approximative pour la corréler avec ce que l’utilisateur a fixé antérieurement.</span><span class="sxs-lookup"><span data-stu-id="1d472-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="1d472-228">**Rétroaction subtile pour une entrée par eye-tracking :** Il est utile de fournir une rétroaction à l’utilisateur s’il regarde une cible (pour indiquer que le système fonctionne comme prévu), mais celle-ci doit rester subtile.</span><span class="sxs-lookup"><span data-stu-id="1d472-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="1d472-229">Cela peut inclure des apparitions/disparitions en fondu ou d’autres comportements subtils de la cible, par exemple des mouvements lents (léger grossissement de la cible) pour indiquer que le système a correctement détecté que l’utilisateur regarde une cible, sans toutefois interrompre inutilement son flux de travail.</span><span class="sxs-lookup"><span data-stu-id="1d472-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="1d472-230">**Évitez d’appliquer des mouvements oculaires artificiels en tant qu’entrées :** Ne forcez pas les utilisateurs à effectuer des mouvements oculaires spécifiques (mouvements par pointage du regard) pour déclencher des actions dans votre application.</span><span class="sxs-lookup"><span data-stu-id="1d472-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="1d472-231">**Tenez compte des imprécisions :** Nous distinguons deux types d’imprécision perceptibles par les utilisateurs : le décalage et l’instabilité.</span><span class="sxs-lookup"><span data-stu-id="1d472-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="1d472-232">Le moyen le plus simple de gérer les décalages consiste à fournir des cibles suffisamment grandes pour rendre une interaction possible (angle visuel > 2° : à titre de référence, votre ongle de pouce a un angle visuel d’environ 2° quand vous tendez le bras (1)).</span><span class="sxs-lookup"><span data-stu-id="1d472-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="1d472-233">Il en résulte les conseils d’aide suivants :</span><span class="sxs-lookup"><span data-stu-id="1d472-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="1d472-234">Ne forcez pas les utilisateurs à sélectionner des cibles minuscules : Des recherches ont montré que si les cibles sont suffisamment grandes (et si le système est bien conçu), les utilisateurs décrivent l’interaction comme étant magique et sans effort.</span><span class="sxs-lookup"><span data-stu-id="1d472-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="1d472-235">Si les cibles deviennent trop petites, les utilisateurs décrivent l’expérience comme étant fatigante et frustrante.</span><span class="sxs-lookup"><span data-stu-id="1d472-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="1d472-236">Voir également</span><span class="sxs-lookup"><span data-stu-id="1d472-236">See also</span></span>
* [<span data-ttu-id="1d472-237">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="1d472-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="1d472-238">Suivre de la tête et du regard dans DirectX</span><span class="sxs-lookup"><span data-stu-id="1d472-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="1d472-239">Suivi du regard dans Unity (Mixed Reality Toolkit)</span><span class="sxs-lookup"><span data-stu-id="1d472-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="1d472-240">Mouvements des mains</span><span class="sxs-lookup"><span data-stu-id="1d472-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="1d472-241">Entrée vocale</span><span class="sxs-lookup"><span data-stu-id="1d472-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="1d472-242">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="1d472-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="1d472-243">Confort</span><span class="sxs-lookup"><span data-stu-id="1d472-243">Comfort</span></span>](comfort.md)
