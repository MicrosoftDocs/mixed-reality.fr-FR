---
title: Œil-point de regard
description: HoloLens 2 permet d’accéder à un nouveau niveau de compréhension contextuelle et humaine au sein de l’expérience holographique en offrant aux développeurs la capacité d’utiliser des informations sur ce que les utilisateurs regardent.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Suivi oculaire, réalité mixte, entrée, point de regard
ms.openlocfilehash: 51779b7b210522aa4d19b5a32d7df6ccb2cb3a35
ms.sourcegitcommit: ff330a7e36e5ff7ae0e9a08c0e99eb7f3f81361f
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/28/2019
ms.locfileid: "70122064"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="d5512-104">Eye-point de regard sur HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="d5512-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="d5512-105">HoloLens 2 permet d’accéder à un nouveau niveau de compréhension contextuelle et humaine au sein de l’expérience holographique en offrant aux développeurs la capacité d’utiliser des informations sur ce que les utilisateurs regardent.</span><span class="sxs-lookup"><span data-stu-id="d5512-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="d5512-106">Cette page explique aux développeurs comment ils peuvent tirer parti du suivi oculaire pour divers cas d’usage, ainsi que des éléments à rechercher lors de la conception d’interfaces utilisateur orientées yeux.</span><span class="sxs-lookup"><span data-stu-id="d5512-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="d5512-107">Prise en charge des appareils</span><span class="sxs-lookup"><span data-stu-id="d5512-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="d5512-108"><strong>Fonctionnalité</strong></span><span class="sxs-lookup"><span data-stu-id="d5512-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="d5512-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1ère génération)</strong></a></span><span class="sxs-lookup"><span data-stu-id="d5512-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="d5512-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="d5512-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="d5512-111"><a href="immersive-headset-hardware-details.md"><strong>Casques immersifs</strong></a></span><span class="sxs-lookup"><span data-stu-id="d5512-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="d5512-112">Œil-point de regard</span><span class="sxs-lookup"><span data-stu-id="d5512-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="d5512-113">❌</span><span class="sxs-lookup"><span data-stu-id="d5512-113">❌</span></span></td>
     <td><span data-ttu-id="d5512-114">✔️</span><span class="sxs-lookup"><span data-stu-id="d5512-114">✔️</span></span></td>
     <td><span data-ttu-id="d5512-115">❌</span><span class="sxs-lookup"><span data-stu-id="d5512-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="d5512-116">Cas d’usage</span><span class="sxs-lookup"><span data-stu-id="d5512-116">Use cases</span></span>
<span data-ttu-id="d5512-117">L’eye-tracking permet aux applications de savoir où l’utilisateur regarde en temps réel.</span><span class="sxs-lookup"><span data-stu-id="d5512-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="d5512-118">Les cas d’usage suivants décrivent certaines interactions possibles avec le suivi oculaire en réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="d5512-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="d5512-119">N’oubliez pas que le [Kit d’outils de réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) est utile pour fournir plusieurs exemples intéressants et puissants pour l’utilisation du suivi oculaire, tels que des sélections de cibles rapides et faciles à prendre en charge par l’œil, ainsi que pour faire défiler automatiquement le texte en fonction de ce à quoi l’utilisateur regarde.</span><span class="sxs-lookup"><span data-stu-id="d5512-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="d5512-120">Intention de l’utilisateur</span><span class="sxs-lookup"><span data-stu-id="d5512-120">User intent</span></span>    
<span data-ttu-id="d5512-121">Des informations sur l’emplacement et le rôle d’un utilisateur fournissent un **contexte puissant pour d’autres entrées**, telles que la voix, les mains et les contrôleurs.</span><span class="sxs-lookup"><span data-stu-id="d5512-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="d5512-122">Cela peut être utile pour diverses tâches.</span><span class="sxs-lookup"><span data-stu-id="d5512-122">This can be used for various tasks.</span></span>
<span data-ttu-id="d5512-123">Par exemple, cette opération peut être effectuée rapidement et facilement **sur la** scène en regardant simplement un hologramme et en disant « sélectionner » (voir également le point d’interrogation [et de validation](gaze-and-commit.md)) ou en disant *« Placer cela... »* , puis en consultant l’emplacement où l’utilisateur veut placer l’hologramme et indiquer *«... là»* .</span><span class="sxs-lookup"><span data-stu-id="d5512-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="d5512-124">Vous trouverez des exemples à ce sujet dans [Mixed Reality Toolkit - Sélection d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) et [Mixed Reality Toolkit - Positionnement d’une cible à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="d5512-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="d5512-125">En outre, un exemple d’intention de l’utilisateur peut inclure des informations sur ce que les utilisateurs cherchent pour améliorer l’engagement avec des agents virtuels et des hologrammes interactifs.</span><span class="sxs-lookup"><span data-stu-id="d5512-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="d5512-126">Par exemple, les agents virtuels peuvent adapter les options disponibles et leur comportement en fonction du contenu actuellement affiché.</span><span class="sxs-lookup"><span data-stu-id="d5512-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="d5512-127">Actions implicites</span><span class="sxs-lookup"><span data-stu-id="d5512-127">Implicit actions</span></span>
<span data-ttu-id="d5512-128">La catégorie des actions implicites est étroitement liée à l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="d5512-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="d5512-129">L’idée est que les hologrammes ou les éléments d’interface utilisateur réagissent de façon quelque peu instinctual, qui peut même ne pas se comporter comme l’utilisateur qui interagit avec le système, mais plutôt que le système et l’utilisateur sont synchronisés. Par exemple, le **défilement automatique orienté vers le regard** de l’utilisateur peut lire un texte long qui commence automatiquement à faire défiler une fois que l’utilisateur accède au bas de la zone de texte pour que l’utilisateur reste dans le sens de la lecture sans soulever de doigt.</span><span class="sxs-lookup"><span data-stu-id="d5512-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="d5512-130">Un aspect clé de cela est que la vitesse de défilement s’adapte à la vitesse de lecture de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="d5512-130">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="d5512-131">Un autre exemple est un **Zoom et un panoramique pris en charge par l’œil,** où l’utilisateur peut sembler se plonger exactement sur ce qu’il est concentré.</span><span class="sxs-lookup"><span data-stu-id="d5512-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="d5512-132">Le déclenchement du zoom et du contrôle de la vitesse de zoom peut être contrôlé par des entrées vocales ou de la main, ce qui est important pour fournir à l’utilisateur le sentiment de contrôle tout en évitant d’être submergé.</span><span class="sxs-lookup"><span data-stu-id="d5512-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="d5512-133">Nous parlerons des instructions de conception plus en détail ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="d5512-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="d5512-134">Une fois le zoom avant effectué, l’utilisateur peut suivre facilement, par exemple, le cours d’une rue pour explorer son voisinage en utilisant simplement son regard.</span><span class="sxs-lookup"><span data-stu-id="d5512-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="d5512-135">Vous trouverez des démonstrations de ces types d’interaction dans l’exemple [Mixed Reality Toolkit - Navigation à l’aide du regard](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="d5512-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="d5512-136">Des cas d’usage supplémentaires pour les _actions implicites_ peuvent inclure :</span><span class="sxs-lookup"><span data-stu-id="d5512-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="d5512-137">**Notifications intelligentes :** Avez-vous déjà été ennuyé par des notifications qui apparaissent juste là où vous concentrez votre attention ?</span><span class="sxs-lookup"><span data-stu-id="d5512-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="d5512-138">En tenant compte de ce à quoi un utilisateur fait attention, vous pouvez améliorer cette expérience en décalant les notifications à partir de l’endroit où l’utilisateur est actuellement Gazing.</span><span class="sxs-lookup"><span data-stu-id="d5512-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="d5512-139">Cela limite les distractions et les ignore automatiquement une fois que l’utilisateur a terminé la lecture.</span><span class="sxs-lookup"><span data-stu-id="d5512-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="d5512-140">**Hologrammes attentifs :** Des hologrammes qui réagissent à la légère sur le regard.</span><span class="sxs-lookup"><span data-stu-id="d5512-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="d5512-141">Cela peut aller de quelques éléments d’interface utilisateur à une fleur très lente à un animal de compagnie virtuel, commençant à regarder l’utilisateur ou à essayer d’éviter l’oeil de l’utilisateur après une étoile prolongée.</span><span class="sxs-lookup"><span data-stu-id="d5512-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="d5512-142">Cette interaction peut fournir un sens intéressant de la connectivité et de la satisfaction dans votre application.</span><span class="sxs-lookup"><span data-stu-id="d5512-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="d5512-143">Suivi de l’attention</span><span class="sxs-lookup"><span data-stu-id="d5512-143">Attention tracking</span></span>   
<span data-ttu-id="d5512-144">Des informations sur l’emplacement ou les utilisateurs qui regardent sont un outil très puissant pour évaluer la convivialité des conceptions et pour identifier les problèmes dans les flux de travail efficaces.</span><span class="sxs-lookup"><span data-stu-id="d5512-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="d5512-145">La visualisation et l’analyse du suivi oculaire sont une pratique courante dans différents domaines d’application.</span><span class="sxs-lookup"><span data-stu-id="d5512-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="d5512-146">Avec HoloLens 2, nous fournissons une nouvelle dimension à cette compréhension, car les hologrammes 3D peuvent être placés dans des contextes réels et évalués en conséquence.</span><span class="sxs-lookup"><span data-stu-id="d5512-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="d5512-147">La [boîte à outils de la réalité mixte](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) fournit des exemples de base pour la journalisation et le chargement des données de suivi visuel et comment les visualiser.</span><span class="sxs-lookup"><span data-stu-id="d5512-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="d5512-148">Les autres applications de cette zone peuvent inclure :</span><span class="sxs-lookup"><span data-stu-id="d5512-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="d5512-149">**Œil à distance-visualisation du regard :** Visualisez ce que les collaborateurs distants examinent pour vérifier si les instructions sont correctement comprises et suivies.</span><span class="sxs-lookup"><span data-stu-id="d5512-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="d5512-150">**Études de recherche sur les utilisateurs :** Le suivi de l’attention peut être utilisé pour explorer la manière dont les utilisateurs débutants ou expérimentés analysent le contenu visuellement, ou comment leur coordination manuelle pour les tâches complexes, telles que l’analyse des données médicales ou les machines à fonctionner.</span><span class="sxs-lookup"><span data-stu-id="d5512-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="d5512-151">**Simulations d’apprentissage et analyse des performances :** Entraînez-vous et optimisez l’exécution de certaines tâches en identifiant plus efficacement les goulots d’étranglement du flux d’exécution.</span><span class="sxs-lookup"><span data-stu-id="d5512-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="d5512-152">**Évaluations de conception, études publicitaires et marketing :** Le suivi oculaire est un outil courant pour les recherches sur le marché lors de l’évaluation des conceptions de site Web et de produit.</span><span class="sxs-lookup"><span data-stu-id="d5512-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="d5512-153">Cas d’usage supplémentaires</span><span class="sxs-lookup"><span data-stu-id="d5512-153">Additional use cases</span></span>
- <span data-ttu-id="d5512-154">**Jeux :** Vous avez toujours souhaité avoir des super pouvoirs ?</span><span class="sxs-lookup"><span data-stu-id="d5512-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="d5512-155">Voilà votre chance !</span><span class="sxs-lookup"><span data-stu-id="d5512-155">Here's your chance!</span></span> <span data-ttu-id="d5512-156">Vous pouvez faire en lévitation les hologrammes.</span><span class="sxs-lookup"><span data-stu-id="d5512-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="d5512-157">Envoyez des rayons laser avec vos yeux.</span><span class="sxs-lookup"><span data-stu-id="d5512-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="d5512-158">Transformez des ennemis en pierres ou figez-les.</span><span class="sxs-lookup"><span data-stu-id="d5512-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="d5512-159">Utilisez votre vision à rayons X pour explorer des bâtiments.</span><span class="sxs-lookup"><span data-stu-id="d5512-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="d5512-160">La seule limite, c’est votre imagination !</span><span class="sxs-lookup"><span data-stu-id="d5512-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="d5512-161">**Avatars expressifs :** Le suivi des yeux permet d’obtenir des avatars 3D plus expressifs en utilisant des données de suivi visuel actif pour animer les yeux de l’avatar qui indiquent ce que l’utilisateur examine.</span><span class="sxs-lookup"><span data-stu-id="d5512-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="d5512-162">**Entrée de texte :** Le suivi oculaire peut être utilisé comme alternative pour une entrée de texte à faible effort, en particulier lorsque la parole ou les mains sont peu pratiques à utiliser.</span><span class="sxs-lookup"><span data-stu-id="d5512-162">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="available-eye-tracking-data"></a><span data-ttu-id="d5512-163">Données de suivi oculaire disponibles</span><span class="sxs-lookup"><span data-stu-id="d5512-163">Available eye tracking data</span></span>
<span data-ttu-id="d5512-164">Avant de décrire en détail les règles de conception spécifiques pour l’interaction avec le regard des yeux, nous souhaitons rapidement souligner les fonctionnalités fournies par l' [API de suivi oculaire](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="d5512-164">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="d5512-165">Les développeurs accèdent à un seul point d’accès en regard (origine du regard et direction) à environ _30 i/s (60 Hz)_ .</span><span class="sxs-lookup"><span data-stu-id="d5512-165">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (60 Hz)_.</span></span>
<span data-ttu-id="d5512-166">Pour plus d’informations sur la façon d’accéder aux données de suivi oculaire, reportez-vous à nos guides pour développeurs sur l’utilisation de la fonction [Eye-pointer](gaze-in-directx.md) dans le regard sur [Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="d5512-166">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="d5512-167">Le point de regard prédit est approximativement de 1,5 degrés d’angle visuel autour de la cible réelle (Voir l’illustration ci-dessous).</span><span class="sxs-lookup"><span data-stu-id="d5512-167">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="d5512-168">Les développeurs doivent prévoir une marge autour de cette valeur limite inférieure (par exemple, 2,0-3,0 degrés peut se traduire par une expérience bien plus confortable).</span><span class="sxs-lookup"><span data-stu-id="d5512-168">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="d5512-169">Nous verrons comment traiter la sélection de petites cibles plus en détail ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="d5512-169">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="d5512-170">Pour que l’eye-tracking fonctionne avec précision, chaque utilisateur doit effectuer un étalonnage.</span><span class="sxs-lookup"><span data-stu-id="d5512-170">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="d5512-171">![Taille optimale de la cible à une distance de 2 mètres](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="d5512-171">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="d5512-172">*Taille de cible optimale à une distance de 2 mètres*</span><span class="sxs-lookup"><span data-stu-id="d5512-172">*Optimal target size at a 2-meter distance*</span></span>

## <a name="calibration"></a><span data-ttu-id="d5512-173">Auto</span><span class="sxs-lookup"><span data-stu-id="d5512-173">Calibration</span></span> 
<span data-ttu-id="d5512-174">Pour que le suivi des yeux fonctionne correctement, chaque utilisateur doit passer par un [étalonnage d’utilisateur de suivi oculaire](calibration.md) pour lequel l’utilisateur doit examiner un ensemble de cibles holographiques.</span><span class="sxs-lookup"><span data-stu-id="d5512-174">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="d5512-175">Cela permet à l’appareil d’ajuster le système pour une expérience d’affichage plus confortable et de meilleure qualité pour l’utilisateur et pour garantir un suivi visuel précis en même temps.</span><span class="sxs-lookup"><span data-stu-id="d5512-175">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="d5512-176">Le suivi oculaire doit fonctionner pour la plupart des utilisateurs, mais dans certains cas, il se peut qu’un utilisateur ne puisse pas l’étalonner correctement.</span><span class="sxs-lookup"><span data-stu-id="d5512-176">Eye tracking should work for most users, but there are cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="d5512-177">Pour en savoir plus sur l’étalonnage, vérifiez l' [étalonnage](calibration.md).</span><span class="sxs-lookup"><span data-stu-id="d5512-177">To learn more about the calibration, please check [Calibration](calibration.md).</span></span>

## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="d5512-178">Conseils pour la conception d’entrées de regard</span><span class="sxs-lookup"><span data-stu-id="d5512-178">Eye-gaze input design guidelines</span></span>
<span data-ttu-id="d5512-179">La création d’une interaction qui tire parti du ciblage visuel à déplacement rapide peut être difficile.</span><span class="sxs-lookup"><span data-stu-id="d5512-179">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="d5512-180">Dans cette section, nous résumerons les principaux avantages et défis à prendre en compte lors de la conception de votre application.</span><span class="sxs-lookup"><span data-stu-id="d5512-180">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="d5512-181">Avantages de l’entrée en regard des yeux</span><span class="sxs-lookup"><span data-stu-id="d5512-181">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="d5512-182">**Pointage à haute vitesse.**</span><span class="sxs-lookup"><span data-stu-id="d5512-182">**High speed pointing.**</span></span> <span data-ttu-id="d5512-183">Le muscle oculaire est le muscle le plus rapide dans le corps humain.</span><span class="sxs-lookup"><span data-stu-id="d5512-183">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="d5512-184">**Faible effort.**</span><span class="sxs-lookup"><span data-stu-id="d5512-184">**Low effort.**</span></span> <span data-ttu-id="d5512-185">Pratiquement aucun mouvement physique n’est nécessaire.</span><span class="sxs-lookup"><span data-stu-id="d5512-185">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="d5512-186">**Implicite.**</span><span class="sxs-lookup"><span data-stu-id="d5512-186">**Implicitness.**</span></span> <span data-ttu-id="d5512-187">Souvent décrits par les utilisateurs comme « sens de lecture », les informations relatives aux mouvements oculaires d’un utilisateur permettent au système de savoir à quelle cible l’utilisateur envisage de s’impliquer.</span><span class="sxs-lookup"><span data-stu-id="d5512-187">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="d5512-188">**Autre canal d’entrée.**</span><span class="sxs-lookup"><span data-stu-id="d5512-188">**Alternative input channel.**</span></span> <span data-ttu-id="d5512-189">L’œil-point de vue peut fournir une entrée de prise en charge puissante pour les entrées de main et vocales, basées sur des années d’expérience des utilisateurs en fonction de leur coordination manuelle.</span><span class="sxs-lookup"><span data-stu-id="d5512-189">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="d5512-190">**Attention visuelle.**</span><span class="sxs-lookup"><span data-stu-id="d5512-190">**Visual attention.**</span></span> <span data-ttu-id="d5512-191">Un autre avantage important est la possibilité de déduire ce à quoi un utilisateur fait attention.</span><span class="sxs-lookup"><span data-stu-id="d5512-191">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="d5512-192">Cela peut aider dans différents domaines d’application, allant de l’évaluation plus efficace de conceptions différentes à l’aide d’interfaces utilisateur plus intelligentes et de signaux sociaux améliorés pour la communication à distance.</span><span class="sxs-lookup"><span data-stu-id="d5512-192">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="d5512-193">Pour résumer, l’utilisation de l’œil en forme de point d’entrée offre un signal contextuel rapide et sans effort.</span><span class="sxs-lookup"><span data-stu-id="d5512-193">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="d5512-194">Cela est particulièrement puissant lorsqu’il est combiné à d’autres entrées, telles que la *voix* et l’entrée *manuelle* , pour confirmer l’intention de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="d5512-194">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="d5512-195">Défis de l’entrée</span><span class="sxs-lookup"><span data-stu-id="d5512-195">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="d5512-196">Avec un grand nombre d’énergie, la responsabilité est importante.</span><span class="sxs-lookup"><span data-stu-id="d5512-196">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="d5512-197">Bien qu’il soit possible d’utiliser des yeux pour créer des expériences utilisateur satisfaisantes, il est également important de savoir ce qu’il n’est pas judicieux de prendre en compte.</span><span class="sxs-lookup"><span data-stu-id="d5512-197">While eye-gaze can be used to create satisfying user experiences that makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="d5512-198">Ce qui suit présente certains *défis* à prendre en compte, ainsi que la façon de les résoudre quand vous travaillez avec des entrées de regard :</span><span class="sxs-lookup"><span data-stu-id="d5512-198">The following discusses some *challenges* to consider as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="d5512-199">**Votre regard est « Always on »** Le moment où vous ouvrez vos couvercles oculaires, vos yeux commencent que sur les choses de l’environnement.</span><span class="sxs-lookup"><span data-stu-id="d5512-199">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="d5512-200">En réagissant à chaque fois que vous effectuez des actions et que vous émettez accidentellement des actions, parce que vous avez examiné un peu trop de temps, cela entraînerait une insatisfaction de l’expérience.</span><span class="sxs-lookup"><span data-stu-id="d5512-200">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="d5512-201">Par conséquent, nous vous recommandons de combiner Eye-regard avec une *commande vocale*, un *mouvement manuel*, un *clic de bouton* ou un logement étendu pour déclencher la sélection d’une cible.</span><span class="sxs-lookup"><span data-stu-id="d5512-201">Therefore we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="d5512-202">Cette solution permet également à un mode dans lequel l’utilisateur peut effectuer des recherches librement sans être submergé par le déclenchement involontaire d’un événement.</span><span class="sxs-lookup"><span data-stu-id="d5512-202">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="d5512-203">Ce problème doit également être pris en compte lors de la conception de commentaires visuels et auditifs quand vous examinez simplement une cible.</span><span class="sxs-lookup"><span data-stu-id="d5512-203">This issue should also be considered when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="d5512-204">Ne surchargez pas l’utilisateur avec des effets immédiats d’ouverture dans une nouvelle fenêtre ou des sons de pointage.</span><span class="sxs-lookup"><span data-stu-id="d5512-204">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="d5512-205">La subtilité est essentielle.</span><span class="sxs-lookup"><span data-stu-id="d5512-205">Subtlety is key.</span></span> <span data-ttu-id="d5512-206">Nous allons aborder plus loin certaines bonnes pratiques quand nous évoquerons les recommandations de conception.</span><span class="sxs-lookup"><span data-stu-id="d5512-206">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="d5512-207">**Observation et contrôle** Imaginez que vous souhaitez redresser précisément une photographie sur votre mur.</span><span class="sxs-lookup"><span data-stu-id="d5512-207">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="d5512-208">Vous regardez les bords de la photo et ce qui se trouve à proximité pour voir si elle est bien alignée.</span><span class="sxs-lookup"><span data-stu-id="d5512-208">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="d5512-209">Imaginez maintenant comment procéder lorsque vous souhaitez utiliser le point de vue de l’œil pour déplacer l’image.</span><span class="sxs-lookup"><span data-stu-id="d5512-209">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="d5512-210">Difficile, n’est-ce pas ?</span><span class="sxs-lookup"><span data-stu-id="d5512-210">Difficult, isn't it?</span></span> <span data-ttu-id="d5512-211">Cela décrit le double rôle de regard pour les entrées et les contrôles.</span><span class="sxs-lookup"><span data-stu-id="d5512-211">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="d5512-212">**Quitter avant de cliquer :** Pour les sélections de cibles rapides, l’étude a montré que le point de vue de l’utilisateur peut se déplacer avant de conclure un clic manuel (par exemple, un airtap).</span><span class="sxs-lookup"><span data-stu-id="d5512-212">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="d5512-213">Par conséquent, une attention particulière doit être accordée à la synchronisation du signal rapide oeil-regard avec une entrée de contrôle plus lente (par exemple, voix, mains, contrôleur).</span><span class="sxs-lookup"><span data-stu-id="d5512-213">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="d5512-214">**Petites cibles :** Savez-vous le sentiment quand vous essayez de lire du texte qui est un peu trop petit pour le lire confortablement ?</span><span class="sxs-lookup"><span data-stu-id="d5512-214">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="d5512-215">Ce sentiment de stress sur vos yeux peut vous amener à vous sentir fatigué et à s’en ressentir, car vous essayez de réajuster vos yeux pour mieux vous concentrer.</span><span class="sxs-lookup"><span data-stu-id="d5512-215">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="d5512-216">C’est un sentiment que vous pouvez appeler dans vos utilisateurs en les forçant à sélectionner des cibles qui sont trop petites dans votre application à l’aide d’un ciblage oculaire.</span><span class="sxs-lookup"><span data-stu-id="d5512-216">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="d5512-217">Durant la conception, si vous souhaitez créer une expérience utilisateur agréable et confortable, nous vous recommandons de privilégier des cibles ayant un angle de vue d’au moins 2°, sinon plus de préférence.</span><span class="sxs-lookup"><span data-stu-id="d5512-217">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="d5512-218">**Mouvements de regard en œil irrégulier** Nos yeux effectuent des mouvements rapides de la fixation à la fixation.</span><span class="sxs-lookup"><span data-stu-id="d5512-218">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="d5512-219">Si vous examinez un enregistrement des mouvements oculaires, vous pouvez voir qu’ils sont irréguliers.</span><span class="sxs-lookup"><span data-stu-id="d5512-219">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="d5512-220">Vos yeux se déplacent rapidement et dans des passages spontanés par rapport aux mouvements du point de vue de la *main*ou du *regard* .</span><span class="sxs-lookup"><span data-stu-id="d5512-220">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="d5512-221">**Fiabilité du suivi :** La précision de l’eye-tracking peut se dégrader légèrement quand la lumière change, car votre œil s’adapte aux nouvelles conditions.</span><span class="sxs-lookup"><span data-stu-id="d5512-221">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="d5512-222">Même si cela ne doit pas nécessairement affecter la conception de votre application, car la précision doit être comprise dans la limite de 2 °, il peut être nécessaire que l’utilisateur l’étalonne à nouveau.</span><span class="sxs-lookup"><span data-stu-id="d5512-222">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="d5512-223">Recommandations de conception</span><span class="sxs-lookup"><span data-stu-id="d5512-223">Design recommendations</span></span>
<span data-ttu-id="d5512-224">La liste suivante répertorie les recommandations de conception spécifiques en fonction des avantages et des défis décrits pour les entrées de regard :</span><span class="sxs-lookup"><span data-stu-id="d5512-224">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="d5512-225">**L’œil-point de regard n’est pas le même que le point de regard :**</span><span class="sxs-lookup"><span data-stu-id="d5512-225">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="d5512-226">**Déterminez si des mouvements oculaires rapides mais irréguliers conviennent à votre tâche de saisie :** Si nos mouvements oculaires rapides et irréguliers sont très utiles pour sélectionner rapidement des cibles dans notre champ de vue, elles sont moins applicables aux tâches qui nécessitent des trajectoires d’entrée lisses (par exemple, des annotations de dessin ou de cercle).</span><span class="sxs-lookup"><span data-stu-id="d5512-226">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="d5512-227">Dans ce cas, le pointage à la main ou avec la tête est préférable.</span><span class="sxs-lookup"><span data-stu-id="d5512-227">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="d5512-228">**Évitez de joindre un texte directement à l’oeil de l’utilisateur (par exemple, un curseur ou un curseur).**</span><span class="sxs-lookup"><span data-stu-id="d5512-228">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="d5512-229">Dans le cas d’un curseur, cela peut entraîner l’effet de « curseur Fleeing » en raison de légers décalages dans le signal de point de regard projeté.</span><span class="sxs-lookup"><span data-stu-id="d5512-229">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="d5512-230">Dans le cas d’un curseur, il peut entrer en conflit avec le double rôle de contrôle du curseur avec vos yeux, tout en souhaitant vérifier si l’objet se trouve à l’emplacement approprié.</span><span class="sxs-lookup"><span data-stu-id="d5512-230">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="d5512-231">Pour résumer, les utilisateurs peuvent devenir submergés et perturbés, en particulier si le signal n’est pas précis pour cet utilisateur.</span><span class="sxs-lookup"><span data-stu-id="d5512-231">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="d5512-232">**Combinez les yeux avec d’autres entrées :** L’intégration du suivi oculaire avec d’autres entrées, telles que les gestes manuels, les commandes vocales ou les enfoncements de bouton, offre plusieurs avantages :</span><span class="sxs-lookup"><span data-stu-id="d5512-232">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="d5512-233">**Permettre une observation libre :** Étant donné que le rôle principal de nos yeux est d’observer notre environnement, il est important que les utilisateurs soient autorisés à regarder sans déclencher les commentaires ou les actions (visuel, audit, etc.).</span><span class="sxs-lookup"><span data-stu-id="d5512-233">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="d5512-234">La combinaison du suivi oculaire et d’un autre contrôle d’entrée permet une transition sans heurts entre l’observation du suivi oculaire et les modes de contrôle d’entrée.</span><span class="sxs-lookup"><span data-stu-id="d5512-234">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="d5512-235">**Fournisseur de contexte puissant :** L’utilisation d’informations sur l’emplacement et le rôle de l’utilisateur lors de la mise en circulation d’une commande vocale ou de l’exécution d’un mouvement manuel permet de canaliser en toute transparence l’entrée dans le champ de la vue.</span><span class="sxs-lookup"><span data-stu-id="d5512-235">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="d5512-236">Exemple : « Mettre ça là » pour sélectionner et positionner rapidement et facilement un hologramme dans la scène en regardant simplement une cible et une destination.</span><span class="sxs-lookup"><span data-stu-id="d5512-236">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="d5512-237">**Nécessité de synchroniser les entrées multimodales (problème du « quitter avant de cliquer ») :** La combinaison rapide de mouvements oculaires avec des entrées supplémentaires plus complexes, telles que des commandes vocales longues ou des gestes de main, risque de poursuivre votre attention avant de terminer la commande d’entrée supplémentaire.</span><span class="sxs-lookup"><span data-stu-id="d5512-237">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="d5512-238">Par conséquent, si vous créez vos propres contrôles d’entrée (par exemple, des gestes personnalisés), veillez à consigner le début de cette entrée ou la durée approximative pour la corréler avec ce qu’un utilisateur a regardé dans le passé.</span><span class="sxs-lookup"><span data-stu-id="d5512-238">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="d5512-239">**Rétroaction subtile pour une entrée par eye-tracking :** Il est utile de fournir des commentaires lorsqu’une cible est examinée pour indiquer que le système fonctionne comme prévu, mais qu’il doit rester discret.</span><span class="sxs-lookup"><span data-stu-id="d5512-239">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="d5512-240">Cela peut inclure la fusion lente, l’inversion et l’extraction, les surbrillances visuelles ou l’exécution d’autres comportements de cible subtils, tels que des mouvements lents, tels que l’amélioration de la taille cible, pour indiquer que le système a détecté correctement que l’utilisateur regarde une cible sans interruption inutile du flux de travail actuel de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="d5512-240">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="d5512-241">**Évitez d’appliquer des mouvements oculaires artificiels en tant qu’entrées :** Ne forcez pas les utilisateurs à effectuer des mouvements d’oeil spécifiques (mouvements de regard) pour déclencher des actions dans votre application.</span><span class="sxs-lookup"><span data-stu-id="d5512-241">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="d5512-242">**Tenez compte des imprécisions :** Nous distingueons deux types d’imprécisions qui sont perceptibles pour les utilisateurs : décalage et instabilité.</span><span class="sxs-lookup"><span data-stu-id="d5512-242">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="d5512-243">Le moyen le plus simple de traiter un décalage consiste à fournir des cibles suffisamment volumineuses pour interagir avec.</span><span class="sxs-lookup"><span data-stu-id="d5512-243">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="d5512-244">Il est recommandé d’utiliser un angle visuel supérieur à 2 ° comme référence.</span><span class="sxs-lookup"><span data-stu-id="d5512-244">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="d5512-245">Par exemple, votre miniature est d’environ 2 ° dans l’angle visuel lorsque vous étirez votre bras.</span><span class="sxs-lookup"><span data-stu-id="d5512-245">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="d5512-246">Il en résulte les conseils d’aide suivants :</span><span class="sxs-lookup"><span data-stu-id="d5512-246">This leads to the following guidance:</span></span>
    - <span data-ttu-id="d5512-247">Ne forcez pas les utilisateurs à sélectionner des cibles minuscules.</span><span class="sxs-lookup"><span data-stu-id="d5512-247">Do not force users to select tiny targets.</span></span> <span data-ttu-id="d5512-248">La recherche a montré que si les cibles sont suffisamment volumineuses et que le système est bien conçu, les utilisateurs décrivent leurs interactions sans effort et magique.</span><span class="sxs-lookup"><span data-stu-id="d5512-248">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="d5512-249">Si les cibles deviennent trop petites, les utilisateurs décrivent l’expérience comme étant fatigante et frustrante.</span><span class="sxs-lookup"><span data-stu-id="d5512-249">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="d5512-250">Guide de développement : Que se passe-t-il si le suivi oculaire n’est pas disponible ?</span><span class="sxs-lookup"><span data-stu-id="d5512-250">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="d5512-251">Dans certaines situations, votre application ne recevra peut-être aucune donnée de suivi oculaire pour différentes raisons, notamment :</span><span class="sxs-lookup"><span data-stu-id="d5512-251">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="d5512-252">L’utilisateur a ignoré l’étalonnage du suivi oculaire.</span><span class="sxs-lookup"><span data-stu-id="d5512-252">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="d5512-253">L’utilisateur a étalonné, mais a décidé de ne pas accorder à votre application l’autorisation d’utiliser ses données de suivi visuel.</span><span class="sxs-lookup"><span data-stu-id="d5512-253">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="d5512-254">L’utilisateur dispose de lunettes uniques ou d’une condition oculaire que le système ne prend pas encore en charge.</span><span class="sxs-lookup"><span data-stu-id="d5512-254">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="d5512-255">Facteurs externes qui empêchent le suivi des yeux fiables, tels que les taches sur le Visor ou les lunettes, les lumières et les occlusions directs du soleil en raison des cheveux devant les yeux.</span><span class="sxs-lookup"><span data-stu-id="d5512-255">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="d5512-256">Pour vous, en tant que développeur d’applications, cela signifie que vous devez prendre en compte la prise en charge des utilisateurs pour lesquels les données de suivi oculaire peuvent ne pas être disponibles.</span><span class="sxs-lookup"><span data-stu-id="d5512-256">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="d5512-257">Nous vous expliquons tout d’abord comment détecter si le suivi oculaire est disponible et comment résoudre le cas où il n’est pas disponible pour différentes applications.</span><span class="sxs-lookup"><span data-stu-id="d5512-257">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="d5512-258">1. Comment détecter que le suivi oculaire est disponible</span><span class="sxs-lookup"><span data-stu-id="d5512-258">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="d5512-259">Quelques vérifications permettent de déterminer si les données de suivi visuel sont disponibles.</span><span class="sxs-lookup"><span data-stu-id="d5512-259">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="d5512-260">Vérifier si...</span><span class="sxs-lookup"><span data-stu-id="d5512-260">Check whether...</span></span>
* <span data-ttu-id="d5512-261">... le système prend en charge le suivi visuel.</span><span class="sxs-lookup"><span data-stu-id="d5512-261">... the system supports eye tracking at all.</span></span> <span data-ttu-id="d5512-262">Appelez la *méthode*suivante : [Windows. perception. People. EyesPose. IsSupported ()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="d5512-262">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="d5512-263">... l’utilisateur est étalonné.</span><span class="sxs-lookup"><span data-stu-id="d5512-263">... the user is calibrated.</span></span> <span data-ttu-id="d5512-264">Appelez la *propriété*suivante : [Windows. perception. People. EyesPose. IsCalibrationValid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="d5512-264">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="d5512-265">... l’utilisateur a donné à votre application l’autorisation d’utiliser ses données de suivi visuel : Récupère le _« GazeInputAccessStatus »_ actuel.</span><span class="sxs-lookup"><span data-stu-id="d5512-265">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="d5512-266">Vous trouverez un exemple de la procédure à suivre pour [demander l’accès aux entrées de regard](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span><span class="sxs-lookup"><span data-stu-id="d5512-266">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="d5512-267">En outre, vous souhaiterez peut-être vérifier que vos données de suivi oculaire ne sont pas obsolètes en ajoutant un délai d’expiration entre les mises à jour reçues des données de suivi oculaire et en configurant le point de vue dans le point de vue ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="d5512-267">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="d5512-268">Comme décrit ci-dessus, il existe plusieurs raisons pour lesquelles les données de suivi oculaire peuvent ne pas être disponibles.</span><span class="sxs-lookup"><span data-stu-id="d5512-268">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="d5512-269">Alors que certains utilisateurs peuvent avoir des axent décidés de révoquer l’accès à leurs données de suivi visuel et qu’ils sont OK avec le compromis d’une expérience utilisateur inférieure à la confidentialité de ne pas fournir l’accès à leurs données de suivi visuel, dans certains cas cela peut être involontaire.</span><span class="sxs-lookup"><span data-stu-id="d5512-269">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="d5512-270">Par conséquent, si votre application utilise le suivi oculaire et qu’il s’agit d’une partie importante de l’expérience, nous vous recommandons de le communiquer clairement à l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="d5512-270">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="d5512-271">En informant l’utilisateur, pourquoi le suivi des yeux est essentiel pour votre application (peut-être même répertorier certaines fonctionnalités améliorées) afin de tirer le meilleur parti de votre application, peut aider l’utilisateur à mieux comprendre ce qu’il abandonne.</span><span class="sxs-lookup"><span data-stu-id="d5512-271">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="d5512-272">Aidez l’utilisateur à identifier la raison pour laquelle le suivi oculaire peut ne pas fonctionner (sur la base des vérifications ci-dessus) et propose des suggestions pour résoudre rapidement les problèmes potentiels.</span><span class="sxs-lookup"><span data-stu-id="d5512-272">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="d5512-273">Par exemple, si vous pouvez détecter que le système prend en charge le suivi oculaire, l’utilisateur est étalonné et même a donné son autorisation, mais aucune donnée de suivi oculaire n’est reçue, alors cela peut pointer vers d’autres problèmes tels que les traînées ou les yeux bloqués.</span><span class="sxs-lookup"><span data-stu-id="d5512-273">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="d5512-274">Notez cependant qu’il y a de rares cas d’utilisateurs pour lesquels le suivi oculaire peut simplement ne pas fonctionner.</span><span class="sxs-lookup"><span data-stu-id="d5512-274">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="d5512-275">Par conséquent, n’hésitez pas à le faire en autorisant à ignorer ou même à désactiver les rappels pour activer le suivi visuel dans votre application.</span><span class="sxs-lookup"><span data-stu-id="d5512-275">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="d5512-276">2. Secours pour les applications utilisant des yeux en forme de point d’entrée principal</span><span class="sxs-lookup"><span data-stu-id="d5512-276">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="d5512-277">Si votre application utilise le point d’entrée de l’œil pour sélectionner rapidement des hologrammes dans la scène, mais que les données de suivi oculaire ne sont pas disponibles, nous vous recommandons de revenir à la tête de regard et de commencer à montrer le curseur en tête.</span><span class="sxs-lookup"><span data-stu-id="d5512-277">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="d5512-278">Nous vous recommandons d’utiliser un délai d’expiration (par exemple, 500 – 1500 ms) pour déterminer s’il faut basculer ou non.</span><span class="sxs-lookup"><span data-stu-id="d5512-278">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="d5512-279">Cela permet d’éviter de faire apparaître un curseur à chaque fois que le système risque de perdre brièvement le suivi en raison de mouvements oculaires rapides ou de clignotements.</span><span class="sxs-lookup"><span data-stu-id="d5512-279">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="d5512-280">Si vous êtes un développeur Unity, la solution de secours automatique à la tête de regard est déjà gérée dans le kit de développement de la réalité mixte.</span><span class="sxs-lookup"><span data-stu-id="d5512-280">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="d5512-281">Si vous êtes un développeur DirectX, vous devez gérer ce commutateur vous-même.</span><span class="sxs-lookup"><span data-stu-id="d5512-281">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="d5512-282">3. Secours pour d’autres applications spécifiques au suivi des yeux</span><span class="sxs-lookup"><span data-stu-id="d5512-282">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="d5512-283">Votre application peut utiliser des regards à l’aide d’une méthode unique adaptée aux yeux, par exemple pour animer les yeux d’un avatar ou pour attirer l’attention sur les yeux cartes thermiques en se basant sur des informations précises sur l’attention visuelle.</span><span class="sxs-lookup"><span data-stu-id="d5512-283">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="d5512-284">Dans ce cas, il n’y a pas de secours clair.</span><span class="sxs-lookup"><span data-stu-id="d5512-284">In this case, there is no clear fallback.</span></span> <span data-ttu-id="d5512-285">Si le suivi oculaire n’est pas disponible, il se peut que vous deviez simplement désactiver ces fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="d5512-285">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span> 

<br>

<span data-ttu-id="d5512-286">Cette page vous a espérons vous fournir une bonne vue d’ensemble pour vous aider à comprendre le rôle du suivi oculaire et l’entrée de regard pour HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="d5512-286">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="d5512-287">Pour commencer à développer, consultez les informations sur les [yeux](https://aka.ms/mrtk-eyes) et les [yeux dans DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="d5512-287">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="d5512-288">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="d5512-288">See also</span></span>
* [<span data-ttu-id="d5512-289">Œil-point de regard sur DirectX</span><span class="sxs-lookup"><span data-stu-id="d5512-289">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="d5512-290">Œil-point d’interfaut</span><span class="sxs-lookup"><span data-stu-id="d5512-290">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="d5512-291">Étalonnage</span><span class="sxs-lookup"><span data-stu-id="d5512-291">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="d5512-292">Suivre de la tête et valider</span><span class="sxs-lookup"><span data-stu-id="d5512-292">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="d5512-293">Mouvements de la main</span><span class="sxs-lookup"><span data-stu-id="d5512-293">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="d5512-294">Entrée vocale</span><span class="sxs-lookup"><span data-stu-id="d5512-294">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="d5512-295">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="d5512-295">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="d5512-296">Confort</span><span class="sxs-lookup"><span data-stu-id="d5512-296">Comfort</span></span>](comfort.md)
