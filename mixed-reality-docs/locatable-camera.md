---
title: Appareil photo localisable
description: Informations générales sur la caméra HoloLens, son fonctionnement et les profils et les solutions disponibles pour les développeurs.
author: cdedmonds
ms.author: wguyman, cdedmonds
ms.date: 06/12/2019
ms.topic: article
keywords: appareil photo, hololens, appareil photo de couleur, accessible sur des serveurs frontaux
ms.openlocfilehash: f661fc82fbeab9a870e8ccf7044c9bb375bed7e3
ms.sourcegitcommit: 30246ab9b9be44a3c707061753e53d4bf401eb6b
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 06/22/2019
ms.locfileid: "67326292"
---
# <a name="locatable-camera"></a><span data-ttu-id="c0ee4-104">Appareil photo localisable</span><span class="sxs-lookup"><span data-stu-id="c0ee4-104">Locatable camera</span></span>

<span data-ttu-id="c0ee4-105">HoloLens inclut une caméra world à l’avant de l’appareil qui permet aux applications voir ce que voit l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-105">HoloLens includes a world-facing camera mounted on the front of the device which enables apps to see what the user sees.</span></span> <span data-ttu-id="c0ee4-106">Les développeurs ont accès et le contrôle de l’appareil photo comme ils le feraient pour des caméras de couleur sur les smartphones, les ordinateurs portables et postes de travail.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-106">Developers have access to and control of the camera just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="c0ee4-107">Les mêmes fenêtres universelles [de capture de média](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) et windows media API qui fonctionnent sur desktop et mobile travaux sur HoloLens.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="c0ee4-108">Unity [a encapsulé également ces API windows](locatable-camera-in-unity.md) d’abstraire la simple utilisation de la caméra sur HoloLens pour des tâches comme prenant régulières photos et vidéos (avec ou sans hologrammes) et de localisation du point de vue et la position de la caméra dans sur le scène.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="c0ee4-109">Informations sur l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="c0ee4-110">HoloLens (première génération)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="c0ee4-111">Appareil photo de photo/vidéo (PV) fixe le focus, en balance des blancs exposition auto et canal de traitement complet de l’image</span><span class="sxs-lookup"><span data-stu-id="c0ee4-111">Fixed focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="c0ee4-112">LED de confidentialité blanc accessible sur le monde s’allume chaque fois que l’appareil photo est active</span><span class="sxs-lookup"><span data-stu-id="c0ee4-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="c0ee4-113">L’appareil photo prend en charge les modes suivants (tous les modes sont proportions 16:9) à 30, 24, 20, 15 et 5 i/s :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="c0ee4-114">Vidéo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-114">Video</span></span>  |  <span data-ttu-id="c0ee4-115">Preview</span><span class="sxs-lookup"><span data-stu-id="c0ee4-115">Preview</span></span>  |  <span data-ttu-id="c0ee4-116">Toujours</span><span class="sxs-lookup"><span data-stu-id="c0ee4-116">Still</span></span>  |  <span data-ttu-id="c0ee4-117">Champ de vision horizontal (H-angle d’ouverture)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="c0ee4-118">Utilisation suggérée</span><span class="sxs-lookup"><span data-stu-id="c0ee4-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="c0ee4-119">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="c0ee4-119">1280x720</span></span> |  <span data-ttu-id="c0ee4-120">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="c0ee4-120">1280x720</span></span> |  <span data-ttu-id="c0ee4-121">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="c0ee4-121">1280x720</span></span> |  <span data-ttu-id="c0ee4-122">45deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-122">45deg</span></span>  |  <span data-ttu-id="c0ee4-123">(mode par défaut avec une stabilisation vidéo)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="c0ee4-124">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-124">N/A</span></span> |  <span data-ttu-id="c0ee4-125">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-125">N/A</span></span> |  <span data-ttu-id="c0ee4-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="c0ee4-126">2048x1152</span></span> |  <span data-ttu-id="c0ee4-127">67deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-127">67deg</span></span> |  <span data-ttu-id="c0ee4-128">Image toujours la résolution plus élevée</span><span class="sxs-lookup"><span data-stu-id="c0ee4-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="c0ee4-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="c0ee4-129">1408x792</span></span> |  <span data-ttu-id="c0ee4-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="c0ee4-130">1408x792</span></span> |  <span data-ttu-id="c0ee4-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="c0ee4-131">1408x792</span></span> |  <span data-ttu-id="c0ee4-132">48deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-132">48deg</span></span> |  <span data-ttu-id="c0ee4-133">Résolution de surbalayage (remplissage) avant une stabilisation vidéo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="c0ee4-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="c0ee4-134">1344x756</span></span> |  <span data-ttu-id="c0ee4-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="c0ee4-135">1344x756</span></span> |  <span data-ttu-id="c0ee4-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="c0ee4-136">1344x756</span></span> |  <span data-ttu-id="c0ee4-137">67deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-137">67deg</span></span> |  <span data-ttu-id="c0ee4-138">Mode vidéo de grand angle d’ouverture avec surbalayage</span><span class="sxs-lookup"><span data-stu-id="c0ee4-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="c0ee4-139">896x504</span><span class="sxs-lookup"><span data-stu-id="c0ee4-139">896x504</span></span> |  <span data-ttu-id="c0ee4-140">896x504</span><span class="sxs-lookup"><span data-stu-id="c0ee4-140">896x504</span></span> |  <span data-ttu-id="c0ee4-141">896x504</span><span class="sxs-lookup"><span data-stu-id="c0ee4-141">896x504</span></span> |  <span data-ttu-id="c0ee4-142">48deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-142">48deg</span></span> |  <span data-ttu-id="c0ee4-143">Basse consommation / tâches de traitement du mode de faible résolution d’image</span><span class="sxs-lookup"><span data-stu-id="c0ee4-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="c0ee4-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="c0ee4-144">HoloLens 2</span></span>

* <span data-ttu-id="c0ee4-145">Appareil photo de photo/vidéo (PV) autofocus, en balance des blancs exposition auto et canal de traitement complet de l’image</span><span class="sxs-lookup"><span data-stu-id="c0ee4-145">Auto-focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="c0ee4-146">LED de confidentialité blanc accessible sur le monde s’allume chaque fois que l’appareil photo est active</span><span class="sxs-lookup"><span data-stu-id="c0ee4-146">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="c0ee4-147">L’appareil photo prend en charge les modes suivants (tous les modes vidéo sont proportions 16:9) :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-147">The camera supports the following modes (all video modes are 16:9 aspect ratio):</span></span>

  >[!NOTE]
  ><span data-ttu-id="c0ee4-148">Ces modes sont susceptibles d’être modifiées avant la disponibilité générale de HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-148">These modes are subject to change prior to HoloLens 2 general availability.</span></span>

  |  <span data-ttu-id="c0ee4-149">Vidéo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-149">Video</span></span>  |  <span data-ttu-id="c0ee4-150">Preview</span><span class="sxs-lookup"><span data-stu-id="c0ee4-150">Preview</span></span>  |  <span data-ttu-id="c0ee4-151">Toujours</span><span class="sxs-lookup"><span data-stu-id="c0ee4-151">Still</span></span>  |  <span data-ttu-id="c0ee4-152">Fréquences d’images</span><span class="sxs-lookup"><span data-stu-id="c0ee4-152">Frame rates</span></span>  |  <span data-ttu-id="c0ee4-153">Champ de vision horizontal (H-angle d’ouverture)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-153">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="c0ee4-154">Utilisation suggérée</span><span class="sxs-lookup"><span data-stu-id="c0ee4-154">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|----------|
  |  <span data-ttu-id="c0ee4-155">1920x1080</span><span class="sxs-lookup"><span data-stu-id="c0ee4-155">1920x1080</span></span> |  <span data-ttu-id="c0ee4-156">1920x1080</span><span class="sxs-lookup"><span data-stu-id="c0ee4-156">1920x1080</span></span> |  <span data-ttu-id="c0ee4-157">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-157">N/A</span></span> |  <span data-ttu-id="c0ee4-158">30, 15 i/s</span><span class="sxs-lookup"><span data-stu-id="c0ee4-158">30, 15 fps</span></span>  |  <span data-ttu-id="c0ee4-159">54deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-159">54deg</span></span>  |  <span data-ttu-id="c0ee4-160">(mode par défaut avec une stabilisation vidéo)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-160">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="c0ee4-161">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-161">N/A</span></span> |  <span data-ttu-id="c0ee4-162">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-162">N/A</span></span> |  <span data-ttu-id="c0ee4-163">3904X2196</span><span class="sxs-lookup"><span data-stu-id="c0ee4-163">3904X2196</span></span> |  <span data-ttu-id="c0ee4-164">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-164">N/A</span></span>  |  <span data-ttu-id="c0ee4-165">64deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-165">64deg</span></span> |  <span data-ttu-id="c0ee4-166">Image toujours la résolution plus élevée</span><span class="sxs-lookup"><span data-stu-id="c0ee4-166">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="c0ee4-167">2272x1278</span><span class="sxs-lookup"><span data-stu-id="c0ee4-167">2272x1278</span></span> |  <span data-ttu-id="c0ee4-168">2272x1278</span><span class="sxs-lookup"><span data-stu-id="c0ee4-168">2272x1278</span></span> |  <span data-ttu-id="c0ee4-169">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-169">N/A</span></span> |  <span data-ttu-id="c0ee4-170">30, 15 i/s</span><span class="sxs-lookup"><span data-stu-id="c0ee4-170">30, 15 fps</span></span>  |  <span data-ttu-id="c0ee4-171">64deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-171">64deg</span></span> |  <span data-ttu-id="c0ee4-172">Résolution de surbalayage (remplissage) avant une stabilisation vidéo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-172">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="c0ee4-173">1952x1100</span><span class="sxs-lookup"><span data-stu-id="c0ee4-173">1952x1100</span></span> |  <span data-ttu-id="c0ee4-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="c0ee4-174">1952x1100</span></span> |  <span data-ttu-id="c0ee4-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="c0ee4-175">1952x1100</span></span>  |  <span data-ttu-id="c0ee4-176">30, 15 i/s</span><span class="sxs-lookup"><span data-stu-id="c0ee4-176">30, 15 fps</span></span>  |  <span data-ttu-id="c0ee4-177">64deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-177">64deg</span></span> |  <span data-ttu-id="c0ee4-178">Qualité de diffusion en continu</span><span class="sxs-lookup"><span data-stu-id="c0ee4-178">High-quality streaming</span></span> | 
  |  <span data-ttu-id="c0ee4-179">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="c0ee4-179">1280x720</span></span> |  <span data-ttu-id="c0ee4-180">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="c0ee4-180">1280x720</span></span> |  <span data-ttu-id="c0ee4-181">N/A</span><span class="sxs-lookup"><span data-stu-id="c0ee4-181">N/A</span></span> |  <span data-ttu-id="c0ee4-182">30, 15, 5 i/s</span><span class="sxs-lookup"><span data-stu-id="c0ee4-182">30, 15, 5 fps</span></span>  |  <span data-ttu-id="c0ee4-183">64deg</span><span class="sxs-lookup"><span data-stu-id="c0ee4-183">64deg</span></span> |  <span data-ttu-id="c0ee4-184">Mode alimentation basse/résolution pour la diffusion en continu et les tâches de traitement d’images</span><span class="sxs-lookup"><span data-stu-id="c0ee4-184">Low power/resolution mode for streaming and image processing tasks</span></span> | 

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="c0ee4-185">Localisation de l’appareil photo dans le monde</span><span class="sxs-lookup"><span data-stu-id="c0ee4-185">Locating the Device Camera in the World</span></span>

<span data-ttu-id="c0ee4-186">Quand HoloLens prend les photos et vidéos, les frames capturés incluent l’emplacement de l’appareil photo dans le monde, ainsi que le modèle d’objectif de l’appareil photo.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-186">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="c0ee4-187">Cela permet aux applications de raisonner à propos de la position de la caméra dans le monde réel pour les scénarios de création d’images augmentées.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-187">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="c0ee4-188">Les développeurs de manière créative peuvent avoir un impact leurs propres scénarios à l’aide de leur traitement d’image préféré ou des bibliothèques de vision par ordinateur personnalisé.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-188">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="c0ee4-189">« Photo » ailleurs dans la documentation de HoloLens peut-être faire référence à la « jeu caméra virtuelle » (le frustum l’application effectue le rendu à).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-189">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="c0ee4-190">À moins qu’indiqué dans le cas contraire, « photo » sur cette page fait référence à la caméra de couleur RVB réelles.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-190">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

<span data-ttu-id="c0ee4-191">Les détails sur ce garde de page à l’aide de la [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference) toutefois il existe également des API pour extraction caméra intrinsèques et les emplacements à l’aide de la classe [Media Foundation attributs](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-191">The details on this page cover using the [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference) class, however there are also APIs to pull camera intrinsics and locations using [Media Foundation Attributes](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx).</span></span> <span data-ttu-id="c0ee4-192">Reportez-vous à la [exemple de suivi de visage HOLOGRAPHIQUE](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) pour plus d’informations.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-192">Please refer to the [Holographic face tracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) for more information.</span></span>

### <a name="images-with-coordinate-systems"></a><span data-ttu-id="c0ee4-193">Images de systèmes de coordonnées</span><span class="sxs-lookup"><span data-stu-id="c0ee4-193">Images with Coordinate Systems</span></span>

<span data-ttu-id="c0ee4-194">Chaque trame d’image (si photo ou vidéo) inclut un [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) racine est à l’appareil photo au moment de la capture, qui est accessible à l’aide de la [CoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) propriété de votre [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-194">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture which can be accessed using the [CoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com/en-us/uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="c0ee4-195">En outre, chaque image contient une description du modèle d’objectif de caméra qui se trouve dans le [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) propriété.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-195">In addition, each frame contains a description of the camera lens model which can be found in the [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="c0ee4-196">Ensemble, ces transformations définissent pour chaque pixel un rayon dans l’espace 3D représentant le chemin emprunté par photons qui a généré le pixel.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-196">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="c0ee4-197">Ces rayons peuvent être associées à d’autres contenus dans l’application en obtenant la transformation à partir du système de coordonnées de l’image à un autre système de coordonnées (par exemple, à partir d’un [de référence stationnaire](coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-197">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="c0ee4-198">Pour résumer, chaque trame d’image offre les avantages suivants :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-198">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="c0ee4-199">Données de pixels (au format de RVB/NV12/JPEG/etc.)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-199">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="c0ee4-200">Un [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) à partir de l’emplacement de la capture</span><span class="sxs-lookup"><span data-stu-id="c0ee4-200">A [SpatialCoordinateSystem](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="c0ee4-201">Un [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) classe contenant le mode de filtre de l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-201">A [CameraIntrinsics](https://docs.microsoft.com/en-us/uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

### <a name="camera-to-application-specified-coordinate-system"></a><span data-ttu-id="c0ee4-202">Appareil photo pour le système de coordonnées spécifié par l’Application</span><span class="sxs-lookup"><span data-stu-id="c0ee4-202">Camera to Application-specified Coordinate System</span></span>

<span data-ttu-id="c0ee4-203">Pour accéder à partir de la « CameraIntrinsics » et « CameraCoordinateSystem » à votre système de coordonnées de monde d’application, vous devez les éléments suivants :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-203">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, you'll need the following:</span></span>

<span data-ttu-id="c0ee4-204">[Caméra localisable dans Unity](locatable-camera-in-unity.md): CameraToWorldMatrix est automatiquement fournie par PhotoCaptureFrame classe (de sorte que vous n’avez pas besoin de vous soucier de transformations CameraCoordinateSystem).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-204">[Locatable camera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class(so you don't need to worry about the CameraCoordinateSystem transforms).</span></span>

<span data-ttu-id="c0ee4-205">[Caméra localisable dans DirectX](locatable-camera-in-directx.md): Explique comment procéder à la requête pour la transformation entre le système de coordonnées de la caméra et votre propre coordinate system(s) application assez simple.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-205">[Locatable camera in DirectX](locatable-camera-in-directx.md): Shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate system(s).</span></span>

### <a name="distortion-error"></a><span data-ttu-id="c0ee4-206">Erreur de distorsion</span><span class="sxs-lookup"><span data-stu-id="c0ee4-206">Distortion Error</span></span>

<span data-ttu-id="c0ee4-207">Sur HoloLens, les flux de l’image vidéo et toujours sont sans distorsion dans le pipeline de traitement d’image du système avant que les trames sont rendus disponibles pour l’application (le flux d’aperçu contient les images déformées d’origine).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-207">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="c0ee4-208">Car uniquement les CameraIntrinsics sont mis à disposition, applications doivent supposer image frames représentent une caméra STÉNOPÉIQUE parfait, cependant l’undistortion fonctionne dans le processeur d’images peut toujours laisser une erreur de jusqu'à 10 pixels sur HoloLens (première génération) Lorsque vous utilisez le CameraIntrinsics dans les métadonnées de frame.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-208">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera, however the undistortion function in the image processor may still leave an error of up to 10 pixels on HoloLens (first-generation) when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="c0ee4-209">Dans de nombreux cas d’utilisation, cette erreur sera a pas d’importance, mais si vous alignez hologrammes au monde réel affiches/marqueurs, par exemple, et que vous remarquez une < 10px décalage (environ 11mm pour hologrammes positionné 2 mètres) cette altération peut être provoqué par erreur.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-209">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away) this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="c0ee4-210">Scénarios d’utilisation de caméra localisables</span><span class="sxs-lookup"><span data-stu-id="c0ee4-210">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="c0ee4-211">Afficher une photo ou une vidéo dans le monde dans lequel elle a été capturée</span><span class="sxs-lookup"><span data-stu-id="c0ee4-211">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="c0ee4-212">Les images de l’appareil photo sont fournis avec une transformation « Appareil photo pour World », qui peut être utilisée pour afficher exactement où l’appareil a ou non lorsque l’image a été effectuée.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-212">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="c0ee4-213">Par exemple, vous pouvez placer une petite icône HOLOGRAPHIQUE à cet emplacement (CameraToWorld.MultiplyPoint(Vector3.zero)) et même dessin une petite flèche située dans la direction que l’appareil photo a été confronté (CameraToWorld.MultiplyVector(Vector3.forward)).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-213">For example you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="c0ee4-214">Balise / modèle / Poster / suivi d’objet</span><span class="sxs-lookup"><span data-stu-id="c0ee4-214">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="c0ee4-215">De nombreuses applications de réalité mixte utilisent une image reconnaissable ou un modèle visual pour créer un point traçable dans l’espace.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-215">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="c0ee4-216">Cela permet ensuite de restituer les objets par rapport à qui pointent ou créer un emplacement connu.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-216">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="c0ee4-217">Certaines utilisations pour HoloLens incluent recherche un objet du monde réel balisé avec rétrospectif (par exemple, un téléviseur avec un code QR), plaçant hologrammes sur rétrospectif et visuellement un appariement avec les appareils non HoloLens tels que des tablettes qui ont été configuré pour communiquer avec HoloLens via Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-217">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="c0ee4-218">Pour reconnaître un modèle visual, puis placer cet objet dans l’espace universel des applications, vous aurez besoin de quelques éléments :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-218">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="c0ee4-219">Une image modèle reconnaissance boîte à outils, tels que le code QR, AR balises, visage, de traceurs du cercle, etc. de la reconnaissance optique de caractères.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-219">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="c0ee4-220">Collecter les trames d’images lors de l’exécution et les passer à la couche de reconnaissance</span><span class="sxs-lookup"><span data-stu-id="c0ee4-220">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="c0ee4-221">Unproject leurs emplacements d’image au monde, ou les positions des rayons world probable.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-221">Unproject their image locations back into world positions, or likely world rays.</span></span> <span data-ttu-id="c0ee4-222">Consultez l'article</span><span class="sxs-lookup"><span data-stu-id="c0ee4-222">See</span></span>
4. <span data-ttu-id="c0ee4-223">Placez vos modèles virtuels sur ces emplacements du monde</span><span class="sxs-lookup"><span data-stu-id="c0ee4-223">Position your virtual models over these world locations</span></span>

<span data-ttu-id="c0ee4-224">Certains liens de traitement important d’image :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-224">Some important image processing links:</span></span>
* [<span data-ttu-id="c0ee4-225">OpenCV</span><span class="sxs-lookup"><span data-stu-id="c0ee4-225">OpenCV</span></span>](http://opencv.org/)
* [<span data-ttu-id="c0ee4-226">QR balises</span><span class="sxs-lookup"><span data-stu-id="c0ee4-226">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="c0ee4-227">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="c0ee4-227">FaceSDK</span></span>](http://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="c0ee4-228">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="c0ee4-228">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="c0ee4-229">En conservant une fréquence d’images application interactive est cruciale, particulièrement lorsque vous traitez des algorithmes de reconnaissance d’image longs.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-229">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="c0ee4-230">Pour cette raison, nous utilisons généralement au format suivant :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-230">For this reason we commonly use the following pattern:</span></span>
1. <span data-ttu-id="c0ee4-231">Thread principal : gère l’objet caméra</span><span class="sxs-lookup"><span data-stu-id="c0ee4-231">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="c0ee4-232">Thread principal : demandes nouvelles images (asynchrone)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-232">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="c0ee4-233">Thread principal : passer des nouvelles images au thread de suivi</span><span class="sxs-lookup"><span data-stu-id="c0ee4-233">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="c0ee4-234">Suivi de Thread : image de processus pour collecter des points clés</span><span class="sxs-lookup"><span data-stu-id="c0ee4-234">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="c0ee4-235">Thread principal : déplace le modèle virtuel en fonction de trouvé les points clés</span><span class="sxs-lookup"><span data-stu-id="c0ee4-235">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="c0ee4-236">Thread principal : Répétez les étapes 2</span><span class="sxs-lookup"><span data-stu-id="c0ee4-236">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="c0ee4-237">Certains systèmes de marqueur d’image fournissent uniquement un emplacement de pixel unique (d’autres fournissent la transformation complet auquel cas cette section n’est pas nécessaire), ce qui équivaut à un rayon des emplacements possibles.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-237">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="c0ee4-238">Pour accéder à un seul emplacement 3d, nous pouvons ensuite tirer parti de plusieurs rayons et trouver le résultat final en leur intersection approximative.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-238">To get to a single 3d location we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="c0ee4-239">Pour ce faire, vous aurez besoin à :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-239">To do this you'll need to:</span></span>
1. <span data-ttu-id="c0ee4-240">Obtenir une boucle va collecter plusieurs images de l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-240">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="c0ee4-241">Rechercher les points de fonction associé et leurs rayons world</span><span class="sxs-lookup"><span data-stu-id="c0ee4-241">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="c0ee4-242">Lorsque vous disposez d’un dictionnaire des fonctionnalités, chacune avec plusieurs rayons de monde, vous pouvez utiliser le code suivant à l’intersection de ces rayons résoudre :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-242">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="c0ee4-243">Étant donné deux ou plusieurs emplacements de balise de suivi, vous pouvez positionner une scène modelled selon le scénario actuel d’utilisateurs.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-243">Given two or more tracked tag locations, you can position a modelled scene to fit the users current scenario.</span></span> <span data-ttu-id="c0ee4-244">Si vous ne pouvez pas supposer gravité, vous aurez besoin des trois emplacements de balise.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-244">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="c0ee4-245">Dans de nombreux cas, que nous utilisons un modèle de couleurs simple où sphères blanches représentent en temps réel suivies des emplacements de balise et sphères bleu représentent des emplacements de balise modélisées, cela permet à l’utilisateur à évaluer visuellement la qualité d’alignement.</span><span class="sxs-lookup"><span data-stu-id="c0ee4-245">In many cases we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations, this allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="c0ee4-246">Nous partons du principe dans toutes les applications de nos la configuration suivante :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-246">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="c0ee4-247">Deux ou plusieurs emplacements de balise modélisées</span><span class="sxs-lookup"><span data-stu-id="c0ee4-247">Two or more modelled tag locations</span></span>
* <span data-ttu-id="c0ee4-248">Un « espace d’étalonnage », qui est le parent des balises dans la scène</span><span class="sxs-lookup"><span data-stu-id="c0ee4-248">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="c0ee4-249">Identificateur de la fonctionnalité appareil photo</span><span class="sxs-lookup"><span data-stu-id="c0ee4-249">Camera feature identifier</span></span>
* <span data-ttu-id="c0ee4-250">Comportement qui déplace l’espace d’étalonnage pour aligner les balises modelled avec les balises en temps réel (nous sommes prudent déplacer l’espace de parent, pas les marqueurs modelled eux-mêmes, étant donné que les autres connect est les positions par rapport à leur).</span><span class="sxs-lookup"><span data-stu-id="c0ee4-250">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="c0ee4-251">Suivre ou identifier balisés stationnaire ou déplacement réel objets/des visages à l’aide des voyants ou autres bibliothèques de module de reconnaissance</span><span class="sxs-lookup"><span data-stu-id="c0ee4-251">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="c0ee4-252">Exemples :</span><span class="sxs-lookup"><span data-stu-id="c0ee4-252">Examples:</span></span>
* <span data-ttu-id="c0ee4-253">Les robots industriels avec voyants (ou les codes QR pour un déplacement plus lent des objets)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-253">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="c0ee4-254">Identifier et reconnaître les objets dans la salle</span><span class="sxs-lookup"><span data-stu-id="c0ee4-254">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="c0ee4-255">Identifier et reconnaître les personnes dans la salle (par exemple, place HOLOGRAPHIQUE cartes de contact sur les visages)</span><span class="sxs-lookup"><span data-stu-id="c0ee4-255">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="c0ee4-256">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="c0ee4-256">See also</span></span>
* [<span data-ttu-id="c0ee4-257">Appareil photo localisable dans DirectX</span><span class="sxs-lookup"><span data-stu-id="c0ee4-257">Locatable camera in DirectX</span></span>](locatable-camera-in-directx.md)
* [<span data-ttu-id="c0ee4-258">Appareil photo localisable dans Unity</span><span class="sxs-lookup"><span data-stu-id="c0ee4-258">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="c0ee4-259">Capture de Réalité Mixte</span><span class="sxs-lookup"><span data-stu-id="c0ee4-259">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="c0ee4-260">Capture de Réalité Mixte pour les développeurs</span><span class="sxs-lookup"><span data-stu-id="c0ee4-260">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="c0ee4-261">Présentation de capture de média</span><span class="sxs-lookup"><span data-stu-id="c0ee4-261">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="c0ee4-262">Exemple de suivi de visage HOLOGRAPHIQUE</span><span class="sxs-lookup"><span data-stu-id="c0ee4-262">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
