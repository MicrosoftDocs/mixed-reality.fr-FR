---
title: Appareil photo localisable
description: Informations générales sur le HoloLens accessible sur appareil photo.
author: wguyman
ms.author: wguyman
ms.date: 02/24/2019
ms.topic: article
keywords: appareil photo, hololens, appareil photo de couleur, accessible sur des serveurs frontaux
ms.openlocfilehash: ffcd6faf15dd8556db393237d468a3cdf60e4bdb
ms.sourcegitcommit: 384b0087899cd835a3a965f75c6f6c607c9edd1b
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 04/12/2019
ms.locfileid: "59596323"
---
# <a name="locatable-camera"></a><span data-ttu-id="ceae1-104">Appareil photo localisable</span><span class="sxs-lookup"><span data-stu-id="ceae1-104">Locatable camera</span></span>

<span data-ttu-id="ceae1-105">HoloLens inclut une caméra world à l’avant de l’appareil qui permet aux applications voir ce que voit l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="ceae1-105">HoloLens includes a world-facing camera mounted on the front of the device which enables apps to see what the user sees.</span></span> <span data-ttu-id="ceae1-106">Les développeurs ont accès et le contrôle de l’appareil photo comme ils le feraient pour des caméras de couleur sur les smartphones, les ordinateurs portables et postes de travail.</span><span class="sxs-lookup"><span data-stu-id="ceae1-106">Developers have access to and control of the camera just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="ceae1-107">Les mêmes fenêtres universelles [de capture de média](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) et windows media API qui fonctionnent sur desktop et mobile travaux sur HoloLens.</span><span class="sxs-lookup"><span data-stu-id="ceae1-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="ceae1-108">Unity [a encapsulé également ces API windows](locatable-camera-in-unity.md) d’abstraire la simple utilisation de la caméra sur HoloLens pour des tâches comme prenant régulières photos et vidéos (avec ou sans hologrammes) et de localisation du point de vue et la position de la caméra dans sur le scène.</span><span class="sxs-lookup"><span data-stu-id="ceae1-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="ceae1-109">Informations sur l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="ceae1-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="ceae1-110">HoloLens (première génération)</span><span class="sxs-lookup"><span data-stu-id="ceae1-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="ceae1-111">Appareil photo de photo/vidéo (PV) fixe le focus, en balance des blancs exposition auto et canal de traitement complet de l’image</span><span class="sxs-lookup"><span data-stu-id="ceae1-111">Fixed focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="ceae1-112">LED de confidentialité blanc accessible sur le monde s’allume chaque fois que l’appareil photo est active</span><span class="sxs-lookup"><span data-stu-id="ceae1-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="ceae1-113">L’appareil photo prend en charge les modes suivants (tous les modes sont proportions 16:9) à 30, 24, 20, 15 et 5 i/s :</span><span class="sxs-lookup"><span data-stu-id="ceae1-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="ceae1-114">Vidéo</span><span class="sxs-lookup"><span data-stu-id="ceae1-114">Video</span></span>  |  <span data-ttu-id="ceae1-115">Preview</span><span class="sxs-lookup"><span data-stu-id="ceae1-115">Preview</span></span>  |  <span data-ttu-id="ceae1-116">Toujours</span><span class="sxs-lookup"><span data-stu-id="ceae1-116">Still</span></span>  |  <span data-ttu-id="ceae1-117">Champ de vision horizontal (H-angle d’ouverture)</span><span class="sxs-lookup"><span data-stu-id="ceae1-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="ceae1-118">Utilisation suggérée</span><span class="sxs-lookup"><span data-stu-id="ceae1-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="ceae1-119">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="ceae1-119">1280x720</span></span> |  <span data-ttu-id="ceae1-120">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="ceae1-120">1280x720</span></span> |  <span data-ttu-id="ceae1-121">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="ceae1-121">1280x720</span></span> |  <span data-ttu-id="ceae1-122">45deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-122">45deg</span></span>  |  <span data-ttu-id="ceae1-123">(mode par défaut avec une stabilisation vidéo)</span><span class="sxs-lookup"><span data-stu-id="ceae1-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="ceae1-124">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-124">N/A</span></span> |  <span data-ttu-id="ceae1-125">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-125">N/A</span></span> |  <span data-ttu-id="ceae1-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="ceae1-126">2048x1152</span></span> |  <span data-ttu-id="ceae1-127">67deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-127">67deg</span></span> |  <span data-ttu-id="ceae1-128">Image toujours la résolution plus élevée</span><span class="sxs-lookup"><span data-stu-id="ceae1-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="ceae1-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="ceae1-129">1408x792</span></span> |  <span data-ttu-id="ceae1-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="ceae1-130">1408x792</span></span> |  <span data-ttu-id="ceae1-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="ceae1-131">1408x792</span></span> |  <span data-ttu-id="ceae1-132">48deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-132">48deg</span></span> |  <span data-ttu-id="ceae1-133">Résolution de surbalayage (remplissage) avant une stabilisation vidéo</span><span class="sxs-lookup"><span data-stu-id="ceae1-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="ceae1-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="ceae1-134">1344x756</span></span> |  <span data-ttu-id="ceae1-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="ceae1-135">1344x756</span></span> |  <span data-ttu-id="ceae1-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="ceae1-136">1344x756</span></span> |  <span data-ttu-id="ceae1-137">67deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-137">67deg</span></span> |  <span data-ttu-id="ceae1-138">Mode vidéo de grand angle d’ouverture avec surbalayage</span><span class="sxs-lookup"><span data-stu-id="ceae1-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="ceae1-139">896x504</span><span class="sxs-lookup"><span data-stu-id="ceae1-139">896x504</span></span> |  <span data-ttu-id="ceae1-140">896x504</span><span class="sxs-lookup"><span data-stu-id="ceae1-140">896x504</span></span> |  <span data-ttu-id="ceae1-141">896x504</span><span class="sxs-lookup"><span data-stu-id="ceae1-141">896x504</span></span> |  <span data-ttu-id="ceae1-142">48deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-142">48deg</span></span> |  <span data-ttu-id="ceae1-143">Basse consommation / tâches de traitement du mode de faible résolution d’image</span><span class="sxs-lookup"><span data-stu-id="ceae1-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="ceae1-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="ceae1-144">HoloLens 2</span></span>

* <span data-ttu-id="ceae1-145">Appareil photo de photo/vidéo (PV) autofocus, en balance des blancs exposition auto et canal de traitement complet de l’image</span><span class="sxs-lookup"><span data-stu-id="ceae1-145">Auto-focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="ceae1-146">LED de confidentialité blanc accessible sur le monde s’allume chaque fois que l’appareil photo est active</span><span class="sxs-lookup"><span data-stu-id="ceae1-146">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="ceae1-147">L’appareil photo prend en charge les modes suivants (tous les modes vidéo sont proportions 16:9) :</span><span class="sxs-lookup"><span data-stu-id="ceae1-147">The camera supports the following modes (all video modes are 16:9 aspect ratio):</span></span>

  >[!NOTE]
  ><span data-ttu-id="ceae1-148">Ces modes sont susceptibles d’être modifiées avant la disponibilité générale de HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="ceae1-148">These modes are subject to change prior to HoloLens 2 general availability.</span></span>

  |  <span data-ttu-id="ceae1-149">Vidéo</span><span class="sxs-lookup"><span data-stu-id="ceae1-149">Video</span></span>  |  <span data-ttu-id="ceae1-150">Preview</span><span class="sxs-lookup"><span data-stu-id="ceae1-150">Preview</span></span>  |  <span data-ttu-id="ceae1-151">Toujours</span><span class="sxs-lookup"><span data-stu-id="ceae1-151">Still</span></span>  |  <span data-ttu-id="ceae1-152">Fréquences d’images</span><span class="sxs-lookup"><span data-stu-id="ceae1-152">Frame rates</span></span>  |  <span data-ttu-id="ceae1-153">Champ de vision horizontal (H-angle d’ouverture)</span><span class="sxs-lookup"><span data-stu-id="ceae1-153">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="ceae1-154">Utilisation suggérée</span><span class="sxs-lookup"><span data-stu-id="ceae1-154">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|----------|
  |  <span data-ttu-id="ceae1-155">1920x1080</span><span class="sxs-lookup"><span data-stu-id="ceae1-155">1920x1080</span></span> |  <span data-ttu-id="ceae1-156">1920x1080</span><span class="sxs-lookup"><span data-stu-id="ceae1-156">1920x1080</span></span> |  <span data-ttu-id="ceae1-157">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-157">N/A</span></span> |  <span data-ttu-id="ceae1-158">30, 15 i/s</span><span class="sxs-lookup"><span data-stu-id="ceae1-158">30, 15 fps</span></span>  |  <span data-ttu-id="ceae1-159">54deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-159">54deg</span></span>  |  <span data-ttu-id="ceae1-160">(mode par défaut avec une stabilisation vidéo)</span><span class="sxs-lookup"><span data-stu-id="ceae1-160">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="ceae1-161">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-161">N/A</span></span> |  <span data-ttu-id="ceae1-162">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-162">N/A</span></span> |  <span data-ttu-id="ceae1-163">3904X2196</span><span class="sxs-lookup"><span data-stu-id="ceae1-163">3904X2196</span></span> |  <span data-ttu-id="ceae1-164">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-164">N/A</span></span>  |  <span data-ttu-id="ceae1-165">64deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-165">64deg</span></span> |  <span data-ttu-id="ceae1-166">Image toujours la résolution plus élevée</span><span class="sxs-lookup"><span data-stu-id="ceae1-166">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="ceae1-167">2272x1278</span><span class="sxs-lookup"><span data-stu-id="ceae1-167">2272x1278</span></span> |  <span data-ttu-id="ceae1-168">2272x1278</span><span class="sxs-lookup"><span data-stu-id="ceae1-168">2272x1278</span></span> |  <span data-ttu-id="ceae1-169">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-169">N/A</span></span> |  <span data-ttu-id="ceae1-170">30, 15 i/s</span><span class="sxs-lookup"><span data-stu-id="ceae1-170">30, 15 fps</span></span>  |  <span data-ttu-id="ceae1-171">64deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-171">64deg</span></span> |  <span data-ttu-id="ceae1-172">Résolution de surbalayage (remplissage) avant une stabilisation vidéo</span><span class="sxs-lookup"><span data-stu-id="ceae1-172">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="ceae1-173">1952x1100</span><span class="sxs-lookup"><span data-stu-id="ceae1-173">1952x1100</span></span> |  <span data-ttu-id="ceae1-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="ceae1-174">1952x1100</span></span> |  <span data-ttu-id="ceae1-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="ceae1-175">1952x1100</span></span>  |  <span data-ttu-id="ceae1-176">30, 15 i/s</span><span class="sxs-lookup"><span data-stu-id="ceae1-176">30, 15 fps</span></span>  |  <span data-ttu-id="ceae1-177">64deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-177">64deg</span></span> |  <span data-ttu-id="ceae1-178">Qualité de diffusion en continu</span><span class="sxs-lookup"><span data-stu-id="ceae1-178">High-quality streaming</span></span> | 
  |  <span data-ttu-id="ceae1-179">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="ceae1-179">1280x720</span></span> |  <span data-ttu-id="ceae1-180">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="ceae1-180">1280x720</span></span> |  <span data-ttu-id="ceae1-181">N/A</span><span class="sxs-lookup"><span data-stu-id="ceae1-181">N/A</span></span> |  <span data-ttu-id="ceae1-182">30, 15, 5 i/s</span><span class="sxs-lookup"><span data-stu-id="ceae1-182">30, 15, 5 fps</span></span>  |  <span data-ttu-id="ceae1-183">64deg</span><span class="sxs-lookup"><span data-stu-id="ceae1-183">64deg</span></span> |  <span data-ttu-id="ceae1-184">Mode alimentation basse/résolution pour la diffusion en continu et les tâches de traitement d’images</span><span class="sxs-lookup"><span data-stu-id="ceae1-184">Low power/resolution mode for streaming and image processing tasks</span></span> | 

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="ceae1-185">Localisation de l’appareil photo dans le monde</span><span class="sxs-lookup"><span data-stu-id="ceae1-185">Locating the Device Camera in the World</span></span>

<span data-ttu-id="ceae1-186">Quand HoloLens prend les photos et vidéos, les frames capturés incluent l’emplacement de l’appareil photo dans le monde, ainsi que la projection de perspective de l’appareil photo.</span><span class="sxs-lookup"><span data-stu-id="ceae1-186">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the perspective projection of the camera.</span></span> <span data-ttu-id="ceae1-187">Cela permet aux applications de raisonner à propos de la position de la caméra dans le monde réel pour les scénarios de création d’images augmentées.</span><span class="sxs-lookup"><span data-stu-id="ceae1-187">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="ceae1-188">Les développeurs de manière créative peuvent avoir un impact leurs propres scénarios à l’aide de leur traitement d’image préféré ou des bibliothèques de vision par ordinateur personnalisé.</span><span class="sxs-lookup"><span data-stu-id="ceae1-188">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="ceae1-189">« Photo » ailleurs dans la documentation de HoloLens peut-être faire référence à la « jeu caméra virtuelle » (le frustum l’application effectue le rendu à).</span><span class="sxs-lookup"><span data-stu-id="ceae1-189">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="ceae1-190">À moins qu’indiqué dans le cas contraire, « photo » sur cette page fait référence à la caméra de couleur RVB réelles.</span><span class="sxs-lookup"><span data-stu-id="ceae1-190">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

<span data-ttu-id="ceae1-191">Les détails sur cette traitent de la page [Media Foundation attributs](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), cependant, il existe également des API pour extraire la caméra à l’aide de fonctions intrinsèques [WinRT APIs](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span><span class="sxs-lookup"><span data-stu-id="ceae1-191">The details on this page cover [Media Foundation Attributes](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), however there are also APIs to pull camera intrinsics using [WinRT APIs](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span></span>  

### <a name="images-with-coordinate-systems"></a><span data-ttu-id="ceae1-192">Images de systèmes de coordonnées</span><span class="sxs-lookup"><span data-stu-id="ceae1-192">Images with Coordinate Systems</span></span>

<span data-ttu-id="ceae1-193">Chaque trame d’image (si photo ou vidéo) inclut un système de coordonnées, ainsi que les deux transformations importantes.</span><span class="sxs-lookup"><span data-stu-id="ceae1-193">Each image frame (whether photo or video) includes a coordinate system, as well as two important transforms.</span></span> <span data-ttu-id="ceae1-194">La « vue » transformer des mappages depuis le système de coordonnées fourni à l’appareil photo et « projection » est mappé à partir de l’appareil photo pixels dans l’image.</span><span class="sxs-lookup"><span data-stu-id="ceae1-194">The "view" transform maps from the provided coordinate system to the camera, and the "projection" maps from the camera to pixels in the image.</span></span> <span data-ttu-id="ceae1-195">Ensemble, ces transformations définissent pour chaque pixel un rayon dans l’espace 3D représentant le chemin emprunté par photons qui a généré le pixel.</span><span class="sxs-lookup"><span data-stu-id="ceae1-195">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="ceae1-196">Ces rayons peuvent être associées à d’autres contenus dans l’application en obtenant la transformation à partir du système de coordonnées de l’image à un autre système de coordonnées (par exemple, à partir d’un [de référence stationnaire](coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="ceae1-196">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="ceae1-197">Pour résumer, chaque trame d’image offre les avantages suivants :</span><span class="sxs-lookup"><span data-stu-id="ceae1-197">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="ceae1-198">Données de pixels (au format de RVB/NV12/JPEG/etc.)</span><span class="sxs-lookup"><span data-stu-id="ceae1-198">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="ceae1-199">3 éléments de métadonnées (stockées en tant que [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)) qui font de chaque image « localisables » :</span><span class="sxs-lookup"><span data-stu-id="ceae1-199">3 pieces of metadata (stored as [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)) that make each frame "locatable":</span></span>

|  <span data-ttu-id="ceae1-200">Nom d'attribut</span><span class="sxs-lookup"><span data-stu-id="ceae1-200">Attribute name</span></span>  |  <span data-ttu-id="ceae1-201">Type</span><span class="sxs-lookup"><span data-stu-id="ceae1-201">Type</span></span>  |  <span data-ttu-id="ceae1-202">GUID</span><span class="sxs-lookup"><span data-stu-id="ceae1-202">GUID</span></span>  |  <span data-ttu-id="ceae1-203">Description</span><span class="sxs-lookup"><span data-stu-id="ceae1-203">Description</span></span> | 
|----------|----------|----------|----------|
|  <span data-ttu-id="ceae1-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span><span class="sxs-lookup"><span data-stu-id="ceae1-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span></span>  |  <span data-ttu-id="ceae1-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span><span class="sxs-lookup"><span data-stu-id="ceae1-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span></span>  |  <span data-ttu-id="ceae1-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span><span class="sxs-lookup"><span data-stu-id="ceae1-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span></span>  |  <span data-ttu-id="ceae1-207">Stocke le [système de coordonnées](coordinate-systems-in-directx.md) de l’image capturée</span><span class="sxs-lookup"><span data-stu-id="ceae1-207">Stores the [coordinate system](coordinate-systems-in-directx.md) of the captured frame</span></span> | 
|  <span data-ttu-id="ceae1-208">MFSampleExtension_Spatial_CameraViewTransform</span><span class="sxs-lookup"><span data-stu-id="ceae1-208">MFSampleExtension_Spatial_CameraViewTransform</span></span>  |  <span data-ttu-id="ceae1-209">Objet BLOB ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="ceae1-209">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="ceae1-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span><span class="sxs-lookup"><span data-stu-id="ceae1-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span></span>  |  <span data-ttu-id="ceae1-211">Stocke la transformation extrinsèques de la caméra dans le système de coordonnées</span><span class="sxs-lookup"><span data-stu-id="ceae1-211">Stores the camera's extrinsic transform in the coordinate system</span></span> | 
|  <span data-ttu-id="ceae1-212">MFSampleExtension_Spatial_CameraProjectionTransform</span><span class="sxs-lookup"><span data-stu-id="ceae1-212">MFSampleExtension_Spatial_CameraProjectionTransform</span></span>  |  <span data-ttu-id="ceae1-213">Objet BLOB ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="ceae1-213">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="ceae1-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span><span class="sxs-lookup"><span data-stu-id="ceae1-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span></span>  |  <span data-ttu-id="ceae1-215">Stocke la transformation de projection de la caméra</span><span class="sxs-lookup"><span data-stu-id="ceae1-215">Stores the camera's projection transform</span></span> | 

<span data-ttu-id="ceae1-216">La transformation de projection représente les propriétés intrinsèques (focale, centre de projection, incliner) de la glace mappé sur un plan de l’image qui s’étend de -1 à + 1 dans l’axe X et Y.</span><span class="sxs-lookup"><span data-stu-id="ceae1-216">The projection transform represents the intrinsic properties (focal length, center of projection, skew) of the lens mapped onto an image plane that extends from -1 to +1 in both the X and Y axis.</span></span>

```
Matrix4x4 format          Terms
   m11 m12 m13 m14      fx    0   0   0
   m21 m22 m23 m24     skew  fy   0   0
   m31 m32 m33 m34      cx   cy   A  -1
   m41 m42 m43 m44       0    0   B   0
```

<span data-ttu-id="ceae1-217">Différentes applications auront des différents systèmes de coordonnées.</span><span class="sxs-lookup"><span data-stu-id="ceae1-217">Different applications will have different coordinate systems.</span></span> <span data-ttu-id="ceae1-218">Voici une vue d’ensemble du flux pour localiser un pixel d’appareil photo pour une seule application :</span><span class="sxs-lookup"><span data-stu-id="ceae1-218">Here's an overview of the flow to locate a camera pixel for a single application:</span></span>

![Transformations appliquées aux systèmes de coordonnées de caméra](images/pvcameratransform5-500px.png)

### <a name="camera-to-application-specified-coordinate-system"></a><span data-ttu-id="ceae1-220">Appareil photo pour le système de coordonnées spécifié par l’Application</span><span class="sxs-lookup"><span data-stu-id="ceae1-220">Camera to Application-specified Coordinate System</span></span>

<span data-ttu-id="ceae1-221">Pour accéder à partir de la « CameraView » et « CameraCoordinateSystem » à votre système de coordonnées de monde d’application, vous devez les éléments suivants :</span><span class="sxs-lookup"><span data-stu-id="ceae1-221">To go from the 'CameraView' and 'CameraCoordinateSystem' to your application/world coordinate system, you'll need the following:</span></span>

<span data-ttu-id="ceae1-222">[Caméra localisable dans Unity](locatable-camera-in-unity.md): CameraToWorldMatrix est automatiquement fournie par PhotoCaptureFrame classe (de sorte que vous n’avez pas besoin de vous soucier de transformations CameraCoordinateSystem).</span><span class="sxs-lookup"><span data-stu-id="ceae1-222">[Locatable camera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class(so you don't need to worry about the CameraCoordinateSystem transforms).</span></span>

<span data-ttu-id="ceae1-223">[Caméra localisable dans DirectX](locatable-camera-in-directx.md): Explique comment procéder à la requête pour la transformation entre le système de coordonnées de la caméra et votre propre coordinate system(s) application assez simple.</span><span class="sxs-lookup"><span data-stu-id="ceae1-223">[Locatable camera in DirectX](locatable-camera-in-directx.md): Shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate system(s).</span></span>

### <a name="application-specified-coordinate-system-to-pixel-coordinates"></a><span data-ttu-id="ceae1-224">Système de coordonnées spécifié par l’application en coordonnées de Pixel</span><span class="sxs-lookup"><span data-stu-id="ceae1-224">Application-specified Coordinate System to Pixel Coordinates</span></span>

<span data-ttu-id="ceae1-225">Supposons que vous souhaitiez trouver ou dessiner à un emplacement 3d spécifique sur une image de l’appareil photo :</span><span class="sxs-lookup"><span data-stu-id="ceae1-225">Let's say you wanted to find or draw at a specific 3d location on a camera image:</span></span>

<span data-ttu-id="ceae1-226">Les transformations de projection et d’affichage, pendant les deux 4x4 matrices, doivent servira légèrement différemment.</span><span class="sxs-lookup"><span data-stu-id="ceae1-226">The view and projection transforms, while both 4x4 matrices, need to be utilized slightly differently.</span></span> <span data-ttu-id="ceae1-227">À savoir une fois la Projection, un est « normaliser par w », cette étape supplémentaire dans la projection simule plusieurs emplacements 3d peuvent se retrouver en tant que le même emplacement 2d sur un écran (par exemple, tout le long d’un certain rayon s’affichera sur le même pixel).</span><span class="sxs-lookup"><span data-stu-id="ceae1-227">Namely after performing the Projection, one would 'normalize by w', this extra step in the projection simulates how multiple different 3d locations can end up as the same 2d location on a screen (i.e. anything along a certain ray will show up on the same pixel).</span></span> <span data-ttu-id="ceae1-228">Par conséquent, points clés (code de nuanceur) :</span><span class="sxs-lookup"><span data-stu-id="ceae1-228">So key points (in shader code):</span></span>

```
// Usual 3d math:
 float4x4 WorldToCamera = inverse( CameraToWorld );
 float4 CameraSpacePos = mul( WorldToCamera, float4( WorldSpacePos.xyz, 1 ) ); // use 1 as the W component
 // Projection math:
 float4 ImagePosUnnormalized = mul( CameraProjection, float4( CameraSpacePos.xyz, 1 ) ); // use 1 as the W component
 float2 ImagePosProjected = ImagePosUnnormalized.xy / ImagePosUnnormalized.w; // normalize by W, gives -1 to 1 space
 float2 ImagePosZeroToOne = ( ImagePosProjected * 0.5 ) + float2( 0.5, 0.5 ); // good for GPU textures
 int2 PixelPos = int2( ImagePosZeroToOne.x * ImageWidth, ( 1 - ImagePosZeroToOne.y ) * ImageHeight ); // good for CPU textures
```

### <a name="pixel-to-application-specified-coordinate-system"></a><span data-ttu-id="ceae1-229">Pixel spécifié par l’Application de système de coordonnées</span><span class="sxs-lookup"><span data-stu-id="ceae1-229">Pixel to Application-specified Coordinate System</span></span>

<span data-ttu-id="ceae1-230">La transition de pixel des coordonnées de monde est un peu plus compliquée :</span><span class="sxs-lookup"><span data-stu-id="ceae1-230">Going from pixel to world coordinates is a little trickier:</span></span>

```
float2 ImagePosZeroToOne = float2( PixelPos.x / ImageWidth, 1.0 - (PixelPos.y / ImageHeight ) );
 float2 ImagePosProjected = ( ( ImagePosZeroToOne * 2.0 ) - float2(1,1) ); // -1 to 1 space
 float3 CameraSpacePos = UnProjectVector( Projection, float3( ImagePosProjected, 1) );
 float3 WorldSpaceRayPoint1 = mul( CameraToWorld, float4(0,0,0,1) ); // camera location in world space
 float3 WorldSpaceRayPoint2 = mul( CameraToWorld, CameraSpacePos ); // ray point in world space
```

<span data-ttu-id="ceae1-231">Où nous définissons UnProject en tant que :</span><span class="sxs-lookup"><span data-stu-id="ceae1-231">Where we define UnProject as:</span></span>

```
public static Vector3 UnProjectVector(Matrix4x4 proj, Vector3 to)
 {
   Vector3 from = new Vector3(0, 0, 0);
   var axsX = proj.GetRow(0);
   var axsY = proj.GetRow(1);
   var axsZ = proj.GetRow(2);
   from.z = to.z / axsZ.z;
   from.y = (to.y - (from.z * axsY.z)) / axsY.y;
   from.x = (to.x - (from.z * axsX.z)) / axsX.x;
   return from;
 }
```

<span data-ttu-id="ceae1-232">Pour rechercher l’emplacement du monde réel d’un point, il vous faut : monde deux rayons et trouver leur intersection, ou une taille connue des points.</span><span class="sxs-lookup"><span data-stu-id="ceae1-232">To find the actual world location of a point, you'll need either: two world rays and find their intersection, or a known size of the points.</span></span>

### <a name="distortion-error"></a><span data-ttu-id="ceae1-233">Erreur de distorsion</span><span class="sxs-lookup"><span data-stu-id="ceae1-233">Distortion Error</span></span>

<span data-ttu-id="ceae1-234">Sur HoloLens, les flux de l’image vidéo et toujours sont sans distorsion dans le pipeline de traitement d’image du système avant que les trames sont rendus disponibles pour l’application (le flux d’aperçu contient les images déformées d’origine).</span><span class="sxs-lookup"><span data-stu-id="ceae1-234">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="ceae1-235">Étant donné qu’uniquement la matrice de projection est rendue disponible, applications doivent supposer image frames représentent une caméra STÉNOPÉIQUE parfait, cependant l’undistortion fonctionne dans le processeur d’images peut laisser toujours une erreur de jusqu'à 10 pixels lors de l’utilisation de la matrice de projection dans les métadonnées de frame.</span><span class="sxs-lookup"><span data-stu-id="ceae1-235">Because only the projection matrix is made available, applications must assume image frames represent a perfect pinhole camera, however the undistortion function in the image processor may still leave an error of up to 10 pixels when using the projection matrix in the frame metadata.</span></span> <span data-ttu-id="ceae1-236">Dans de nombreux cas d’utilisation, cette erreur sera a pas d’importance, mais si vous alignez hologrammes au monde réel affiches/marqueurs, par exemple, et que vous remarquez une < 10px décalage (environ 11mm pour hologrammes positionné 2 mètres) cette altération peut être provoqué par erreur.</span><span class="sxs-lookup"><span data-stu-id="ceae1-236">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away) this distortion error could be the cause.</span></span>

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="ceae1-237">Scénarios d’utilisation de caméra localisables</span><span class="sxs-lookup"><span data-stu-id="ceae1-237">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="ceae1-238">Afficher une photo ou une vidéo dans le monde dans lequel elle a été capturée</span><span class="sxs-lookup"><span data-stu-id="ceae1-238">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="ceae1-239">Les images de l’appareil photo sont fournis avec une transformation « Appareil photo pour World », qui peut être utilisée pour afficher exactement où l’appareil a ou non lorsque l’image a été effectuée.</span><span class="sxs-lookup"><span data-stu-id="ceae1-239">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="ceae1-240">Par exemple, vous pouvez placer une petite icône HOLOGRAPHIQUE à cet emplacement (CameraToWorld.MultiplyPoint(Vector3.zero)) et même dessin une petite flèche située dans la direction que l’appareil photo a été confronté (CameraToWorld.MultiplyVector(Vector3.forward)).</span><span class="sxs-lookup"><span data-stu-id="ceae1-240">For example you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="painting-the-world-using-a-camera-shader"></a><span data-ttu-id="ceae1-241">Peinture au monde à l’aide d’un nuanceur de caméra</span><span class="sxs-lookup"><span data-stu-id="ceae1-241">Painting the world using a camera shader</span></span>

<span data-ttu-id="ceae1-242">Dans cette section, nous allons créer un matériau 'nuanceur' ce couleurs le monde selon où il est apparu dans la vue de l’appareil photo un appareil.</span><span class="sxs-lookup"><span data-stu-id="ceae1-242">In this section we'll create a material 'shader' that colors the world based on where it showed up in a device camera's view.</span></span> <span data-ttu-id="ceae1-243">Nous allons faire est effectivement que chaque vertex sera déterminer son emplacement relatif à l’appareil photo, puis chaque pixel utilisera la matrice de projection à la figure hors de l’image texel, il est associé.</span><span class="sxs-lookup"><span data-stu-id="ceae1-243">Effectively what we'll do is that every vertex will figure out its location relative to the camera, and then every pixel will utilize the 'projection matrix' to figure out which image texel it is associated with.</span></span> <span data-ttu-id="ceae1-244">Enfin et si vous le souhaitez, nous allons fondu les angles de l’image pour la faire apparaître plus comme une mémoire de rêve de type :</span><span class="sxs-lookup"><span data-stu-id="ceae1-244">Lastly, and optionally, we'll fade out the corners of the image to make it appear more as a dream-like memory:</span></span>

```
// In the vertex shader:
 float4 worldSpace = mul( ObjectToWorld, float4( vertexPos.xyz, 1));
 float4 cameraSpace = mul( CameraWorldToLocal, float4(worldSpace.xyz, 1));

 // In the pixel shader:
 float4 unprojectedTex = mul( CameraProjection, float4( cameraSpace .xyz, 1));
 float2 projectedTex = (unprojectedTex.xy / unprojectedTex.w);
 float2 unitTexcoord = ((projectedTex * 0.5) + float4(0.5, 0.5, 0, 0));
 float4 cameraTextureColor = tex2D(_CameraTex, unitTexcoord);
 // Fade out edges for better look:
 float pctInView = saturate((1.0 - length(projectedTex.xy)) * 3.0);
 float4 finalColor = float4( cameraTextureColor.rgb, pctInView );
```

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="ceae1-245">Balise / modèle / Poster / suivi d’objet</span><span class="sxs-lookup"><span data-stu-id="ceae1-245">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="ceae1-246">De nombreuses applications de réalité mixte utilisent une image reconnaissable ou un modèle visual pour créer un point traçable dans l’espace.</span><span class="sxs-lookup"><span data-stu-id="ceae1-246">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="ceae1-247">Cela permet ensuite de restituer les objets par rapport à qui pointent ou créer un emplacement connu.</span><span class="sxs-lookup"><span data-stu-id="ceae1-247">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="ceae1-248">Certaines utilisations pour HoloLens incluent recherche un objet du monde réel balisé avec rétrospectif (par exemple, un téléviseur avec un code QR), plaçant hologrammes sur rétrospectif et visuellement un appariement avec les appareils non HoloLens tels que des tablettes qui ont été configuré pour communiquer avec HoloLens via Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="ceae1-248">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="ceae1-249">Pour reconnaître un modèle visual, puis placer cet objet dans l’espace universel des applications, vous aurez besoin de quelques éléments :</span><span class="sxs-lookup"><span data-stu-id="ceae1-249">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="ceae1-250">Une image modèle reconnaissance boîte à outils, tels que le code QR, AR balises, visage, de traceurs du cercle, etc. de la reconnaissance optique de caractères.</span><span class="sxs-lookup"><span data-stu-id="ceae1-250">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="ceae1-251">Collecter les trames d’images lors de l’exécution et les passer à la couche de reconnaissance</span><span class="sxs-lookup"><span data-stu-id="ceae1-251">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="ceae1-252">Unproject leurs emplacements d’image au monde, ou les positions des rayons world probable.</span><span class="sxs-lookup"><span data-stu-id="ceae1-252">Unproject their image locations back into world positions, or likely world rays.</span></span> <span data-ttu-id="ceae1-253">Consultez l'article</span><span class="sxs-lookup"><span data-stu-id="ceae1-253">See</span></span>
4. <span data-ttu-id="ceae1-254">Placez vos modèles virtuels sur ces emplacements du monde</span><span class="sxs-lookup"><span data-stu-id="ceae1-254">Position your virtual models over these world locations</span></span>

<span data-ttu-id="ceae1-255">Certains liens de traitement important d’image :</span><span class="sxs-lookup"><span data-stu-id="ceae1-255">Some important image processing links:</span></span>
* [<span data-ttu-id="ceae1-256">OpenCV</span><span class="sxs-lookup"><span data-stu-id="ceae1-256">OpenCV</span></span>](http://opencv.org/)
* [<span data-ttu-id="ceae1-257">QR balises</span><span class="sxs-lookup"><span data-stu-id="ceae1-257">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="ceae1-258">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="ceae1-258">FaceSDK</span></span>](http://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="ceae1-259">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="ceae1-259">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="ceae1-260">En conservant une fréquence d’images application interactive est cruciale, particulièrement lorsque vous traitez des algorithmes de reconnaissance d’image longs.</span><span class="sxs-lookup"><span data-stu-id="ceae1-260">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="ceae1-261">Pour cette raison, nous utilisons généralement au format suivant :</span><span class="sxs-lookup"><span data-stu-id="ceae1-261">For this reason we commonly use the following pattern:</span></span>
1. <span data-ttu-id="ceae1-262">Thread principal : gère l’objet caméra</span><span class="sxs-lookup"><span data-stu-id="ceae1-262">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="ceae1-263">Thread principal : demandes nouvelles images (asynchrone)</span><span class="sxs-lookup"><span data-stu-id="ceae1-263">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="ceae1-264">Thread principal : passer des nouvelles images au thread de suivi</span><span class="sxs-lookup"><span data-stu-id="ceae1-264">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="ceae1-265">Suivi de Thread : image de processus pour collecter des points clés</span><span class="sxs-lookup"><span data-stu-id="ceae1-265">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="ceae1-266">Thread principal : déplace le modèle virtuel en fonction de trouvé les points clés</span><span class="sxs-lookup"><span data-stu-id="ceae1-266">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="ceae1-267">Thread principal : Répétez les étapes 2</span><span class="sxs-lookup"><span data-stu-id="ceae1-267">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="ceae1-268">Certains systèmes de marqueur d’image fournissent uniquement un emplacement de pixel unique (d’autres fournissent la transformation complet auquel cas cette section n’est pas nécessaire), ce qui équivaut à un rayon des emplacements possibles.</span><span class="sxs-lookup"><span data-stu-id="ceae1-268">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="ceae1-269">Pour accéder à un seul emplacement 3d, nous pouvons ensuite tirer parti de plusieurs rayons et trouver le résultat final en leur intersection approximative.</span><span class="sxs-lookup"><span data-stu-id="ceae1-269">To get to a single 3d location we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="ceae1-270">Pour ce faire, vous aurez besoin à :</span><span class="sxs-lookup"><span data-stu-id="ceae1-270">To do this you'll need to:</span></span>
1. <span data-ttu-id="ceae1-271">Obtenir une boucle va collecter plusieurs images de l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="ceae1-271">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="ceae1-272">Rechercher la [fonctionnalité points associés](#pixel-to-application-specified-coordinate-system)et leurs rayons world</span><span class="sxs-lookup"><span data-stu-id="ceae1-272">Find the [associated feature points](#pixel-to-application-specified-coordinate-system), and their world rays</span></span>
3. <span data-ttu-id="ceae1-273">Lorsque vous disposez d’un dictionnaire des fonctionnalités, chacune avec plusieurs rayons de monde, vous pouvez utiliser le code suivant à l’intersection de ces rayons résoudre :</span><span class="sxs-lookup"><span data-stu-id="ceae1-273">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="ceae1-274">Étant donné deux ou plusieurs emplacements de balise de suivi, vous pouvez positionner une scène modelled selon le scénario actuel d’utilisateurs.</span><span class="sxs-lookup"><span data-stu-id="ceae1-274">Given two or more tracked tag locations, you can position a modelled scene to fit the users current scenario.</span></span> <span data-ttu-id="ceae1-275">Si vous ne pouvez pas supposer gravité, vous aurez besoin des trois emplacements de balise.</span><span class="sxs-lookup"><span data-stu-id="ceae1-275">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="ceae1-276">Dans de nombreux cas, que nous utilisons un modèle de couleurs simple où sphères blanches représentent en temps réel suivies des emplacements de balise et sphères bleu représentent des emplacements de balise modélisées, cela permet à l’utilisateur à évaluer visuellement la qualité d’alignement.</span><span class="sxs-lookup"><span data-stu-id="ceae1-276">In many cases we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations, this allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="ceae1-277">Nous partons du principe dans toutes les applications de nos la configuration suivante :</span><span class="sxs-lookup"><span data-stu-id="ceae1-277">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="ceae1-278">Deux ou plusieurs emplacements de balise modélisées</span><span class="sxs-lookup"><span data-stu-id="ceae1-278">Two or more modelled tag locations</span></span>
* <span data-ttu-id="ceae1-279">Un « espace d’étalonnage », qui est le parent des balises dans la scène</span><span class="sxs-lookup"><span data-stu-id="ceae1-279">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="ceae1-280">Identificateur de la fonctionnalité appareil photo</span><span class="sxs-lookup"><span data-stu-id="ceae1-280">Camera feature identifier</span></span>
* <span data-ttu-id="ceae1-281">Comportement qui déplace l’espace d’étalonnage pour aligner les balises modelled avec les balises en temps réel (nous sommes prudent déplacer l’espace de parent, pas les marqueurs modelled eux-mêmes, étant donné que les autres connect est les positions par rapport à leur).</span><span class="sxs-lookup"><span data-stu-id="ceae1-281">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="render-holograms-from-the-cameras-position"></a><span data-ttu-id="ceae1-282">Restituer hologrammes à partir de la position de la caméra</span><span class="sxs-lookup"><span data-stu-id="ceae1-282">Render holograms from the Camera's position</span></span>

<span data-ttu-id="ceae1-283">Remarque: Si vous essayez de créer votre propre [mixte capture réalité (MRC)](mixed-reality-capture.md), qui fusionne hologrammes avec le flux de l’appareil photo, vous pouvez utiliser la [des effets MRC](mixed-reality-capture-for-developers.md) ou activer la propriété showHolograms dans [ Caméra localisable dans Unity](locatable-camera-in-unity.md).</span><span class="sxs-lookup"><span data-stu-id="ceae1-283">Note: If you are trying to create your own [Mixed reality capture (MRC)](mixed-reality-capture.md), which blends holograms with the Camera stream, you can use the [MRC effects](mixed-reality-capture-for-developers.md) or enable the showHolograms property in [Locatable camera in Unity](locatable-camera-in-unity.md).</span></span>

<span data-ttu-id="ceae1-284">Si vous souhaitez effectuer un rendu spécial directement sur le flux de l’appareil photo RVB, il est possible rendre hologrammes dans l’espace à partir de la position de la caméra synchronisée avec un flux vidéo afin de fournir un aperçu de l’enregistrement/live hologramme personnalisé.</span><span class="sxs-lookup"><span data-stu-id="ceae1-284">If you'd like to do a special render directly on the RGB Camera stream, it's possible to render holograms in space from the Camera's position in sync with a video feed in order to provide a custom hologram recording/live preview.</span></span>

<span data-ttu-id="ceae1-285">Dans Skype, nous le faire pour afficher le client à distance à ce que voit l’utilisateur de HoloLens et leur permettre d’interagir avec les mêmes hologrammes.</span><span class="sxs-lookup"><span data-stu-id="ceae1-285">In Skype, we do this to show the remote client what the HoloLens user is seeing and allow them to interact with the same holograms.</span></span> <span data-ttu-id="ceae1-286">Avant d’envoyer sur chaque image vidéo via le service de Skype, nous extrayons les données de caméra correspondantes de chaque image.</span><span class="sxs-lookup"><span data-stu-id="ceae1-286">Before sending over each video frame through the Skype service, we grab each frame's corresponding camera data.</span></span> <span data-ttu-id="ceae1-287">Nous empaquetez ensuite les métadonnées d’extrinsèques et intrinsèque de la caméra avec l’image vidéo et puis l’envoyer sur le service de Skype.</span><span class="sxs-lookup"><span data-stu-id="ceae1-287">We then package the camera's extrinsic and intrinsic metadata with the video frame and then send it over the Skype service.</span></span>

<span data-ttu-id="ceae1-288">Côté réception, à l’aide de Unity, nous avons déjà synchronisées avec tous les hologrammes dans l’espace de l’utilisateur HoloLens en utilisant le même système de coordonnées.</span><span class="sxs-lookup"><span data-stu-id="ceae1-288">On the receiving side, using Unity, we've already synced all of the holograms in the HoloLens user's space using the same coordinate system.</span></span> <span data-ttu-id="ceae1-289">Cela nous permet à utiliser des métadonnées extrinsèques de la caméra pour placer la caméra de Unity dans l’emplacement exact dans le monde (par rapport à celui des hologrammes) l’utilisateur HoloLens a été permanent lors de cette image vidéo a été capturée, utilisez les informations intrinsèque de la caméra pour Vérifiez que la vue est le même.</span><span class="sxs-lookup"><span data-stu-id="ceae1-289">This allows us to use the camera's extrinsic metadata to place the Unity camera in the exact place in the world (relative to the rest of the holograms) that the HoloLens user was standing when that video frame was captured, and use the camera intrinsic information to ensure the view is the same.</span></span>

<span data-ttu-id="ceae1-290">Une fois l’appareil photo correctement configuré, nous avons combiné les hologrammes voit de l’appareil photo sur l’image que nous avons reçu de Skype, créez une vue de réalité mixte de ce que l’utilisateur HoloLens voit à l’aide de Graphics.Blit.</span><span class="sxs-lookup"><span data-stu-id="ceae1-290">Once we have the camera set up properly, we combine what holograms the camera sees onto the frame we received from Skype, creating a mixed reality view of what the HoloLens user sees using Graphics.Blit.</span></span>

```cs
private void OnFrameReceived(Texture frameTexture, Vector3 cameraPosition, Quaternion cameraRotation, Matrix4x4 cameraProjectionMatrix)
{
    //set material that will be blitted onto the RenderTexture
    this.compositeMaterial.SetTexture(CompositeRenderer.CameraTextureMaterialProperty, frameTexture);
    //set the camera to be that of the HoloLens's device camera
    this.Camera.transform.position = cameraPosition;
    this.Camera.transform.rotation = cameraRotation;
    this.Camera.projectionMatrix = cameraProjectionMatrix;
    //trigger the Graphics's Blit now that the frame and camera are set up
    this.TextureReady = false;
}
private void OnRenderImage(RenderTexture source, RenderTexture destination)
{
    if (!this.TextureReady)
    {
        Graphics.Blit(source, destination, this.compositeMaterial);
        this.TextureReady = true;
    }
}
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="ceae1-291">Suivre ou identifier balisés stationnaire ou déplacement réel objets/des visages à l’aide des voyants ou autres bibliothèques de module de reconnaissance</span><span class="sxs-lookup"><span data-stu-id="ceae1-291">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="ceae1-292">Exemples :</span><span class="sxs-lookup"><span data-stu-id="ceae1-292">Examples:</span></span>
* <span data-ttu-id="ceae1-293">Les robots industriels avec voyants (ou les codes QR pour un déplacement plus lent des objets)</span><span class="sxs-lookup"><span data-stu-id="ceae1-293">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="ceae1-294">Identifier et reconnaître les objets dans la salle</span><span class="sxs-lookup"><span data-stu-id="ceae1-294">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="ceae1-295">Identifier et reconnaître les personnes dans la salle (par exemple, place HOLOGRAPHIQUE cartes de contact sur les visages)</span><span class="sxs-lookup"><span data-stu-id="ceae1-295">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="ceae1-296">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="ceae1-296">See also</span></span>
* [<span data-ttu-id="ceae1-297">Caméra localisable dans DirectX</span><span class="sxs-lookup"><span data-stu-id="ceae1-297">Locatable camera in DirectX</span></span>](locatable-camera-in-directx.md)
* [<span data-ttu-id="ceae1-298">Caméra localisable dans Unity</span><span class="sxs-lookup"><span data-stu-id="ceae1-298">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="ceae1-299">Capture de réalité mixte</span><span class="sxs-lookup"><span data-stu-id="ceae1-299">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="ceae1-300">Mixte de capture de la réalité pour les développeurs</span><span class="sxs-lookup"><span data-stu-id="ceae1-300">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="ceae1-301">Présentation de capture de média</span><span class="sxs-lookup"><span data-stu-id="ceae1-301">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
